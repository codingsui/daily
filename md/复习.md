[TOC]

# 并发

## 基本概念

### java中>、>>、>>>的含义

 1.  '>',在数字间是判断大小的,结果是boolean
eg:
```
int a = 1;
int b = 2;
if(a > bw){
    ...
}
```

2. <<代表左移、>>代表右移,在数字中就是将整数变为二进制数，然后移位，在移位过程中是区分正负号的

3. '>>>'无符号移动

### ^、| 、&、~
1. ^ 异或运算
2. | 或晕眩
3. & 与运算
4. ~ 非运算

### 为什么要用到并发

充分利用cpu计算能力，提高程序运行速度

### 并发编程的缺点

	频繁的上下文切换
	线程安全

### 同步VS异步

同步，就是在发出一个*调用*时，在没有得到结果之前，该*调用*就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由*调用者*主动等待这个*调用*的结果。

异步则是相反，***调用\*在发出之后，这个调用就直接返回了，所以没有返回结果**。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在*调用*发出后，*被调用者*通过状态、通知来通知调用者，或通过回调函数处理这个调用。

### 并发与并行

并发是指在同一时刻有多个任务或者多个请求，比方说一个服务器在同一时刻有上百甚至上千的用户同时访问；并行指的是在同一时间段内有多个任务在运行，宏观上是同时运行，微观上由于只有一个CPU，所以还是串行的。

并发（concurrency）：把任务在不同的时间点交给处理器进行处理。在同一时间点，任务并不会同时运行。
并行（parallelism）：把每一个任务分配给每一个处理器独立完成。在同一时间点，任务一定是同时运行。

### 阻塞和非阻塞

阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。
非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。

### 临界区

每个进程中访问临界资源的那段代码称为临界区（criticalsection），每次只允许一个进程进入临界区，进入后，不允许其他进程进入。

### 线程不安全

多个线程操作同一个共享数据，造成结果与预期结果不一致

## Unsafe类的作用
- 是java提供操作操作系统的类，大部分方法通过JNI调用底层方法实现
- [详情](https://www.cnblogs.com/mickole/articles/3757278.html)

## 线程的状态和基本操作

### 如何实现线程

- 继承Thread重写run方法
- 实现Runnable重写run方法
- 实现Callable重写call方法

```java
class A implements Callable<String>{
        @Override
        public String call() throws Exception {
            return null;
        }
    }
```

### 线程状态的转换(流转图)

new、runnable(running,ready)、block、wait、time_wait、terminated

![image](https://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/721DEA7050EA417B8A07BD919EF841F1/17554)

### 线程的基本操作（Thread的基本方法）

> https://www.cnblogs.com/tutubaobao/p/10050169.html

	interrupted
	join
	sleep
		与Object类的wait方法的区别
	yield
		与sleep的区别
	start
	setprioity中的线程优先级的范围是1～10，默认的优先级是5。10极最高。
#### 	Thread.sleep与Object类的wait方法的区别

（1）原理不同。
sleep（）方法是Thread类的静态方法，是线程用来控制自身流程的，会使此线程暂停执行一段时间，把执行机会让给其他线程，等时间一到此线程会自动“苏醒”。
wait（）方法是Object（）类的方法，用于线程间的通信，这个方法会使当前拥有该对象锁的进程等待，直到其他线程调用notify（）方法（或notifyAll（）方法）才“苏醒”。
（2）对锁的处理机制不同
sleep（）方法的主要作用是让线程暂停执行一段时间，时间一到自动恢复，不涉及线程间的通信，因此调用sleep（）方法并不会释放锁。
调用wait（）方法后，线程会释放掉它所占用的锁，从而使线程所在对象中的其他synchronized数据可被别的线程使用。
（3）使用区域不同
sleep（）方法可以放在任何地方使用。
wait（）方法必须放在同步控制方法或同步语句块中使用。
（4）异常捕获
sleep方法必须捕获异常，在sleep过程中，有可能被其他对象调用它的interrupt（）产生InterruptException异常。
wait（）、notify（）、notifyAll（）不需要捕获异常

由于sleep不会释放“锁标志”，容易导致死锁。因此一般推荐使用wait（）方法

#### yield与sleep的区别

①sleep方法给其他线程运行机会时不考虑线程的优先级,因此会给低线程优先级运行的机会,而yield方法只会给相同优先级或者更高优先级线程运行的机会

②线程执行sleep()方法后转入阻塞状态,所以,执行sleep()方法的线程在指定的时间内不会被执行,而yield()方法只是使当前线程重新回到可执行状态,所以执行yield()方法的线程可能在进入可执行状态后马上又被执行

③sleep()方法声明抛出InterruptedException,而yield()方法没有声明任何异常

④sleep()方法比yield()方法(跟操作系统相关)有更好的可移植性

### 死锁是什么

> https://blog.csdn.net/zhang123bl/article/details/89850646

多个线程彼此等待彼此所持有的共享资源，而造成一直相互等待

#### 死锁产生的必要条件

- 互斥条件：即某个资源在一段时间内只能由一个进程占有，不能同时被两个或两个以上的进程占有
- 不可抢占条件：进程所获得的资源在未使用完毕之前，资源申请者不能强行的从资源占有者手中夺取资源，而只能由该资源的占有者进程自行释放
- 占有且等待条件：进程至少已经占有了一个资源，但又申请了一个新的被其他进程所占有的资源，此时处于等待状态
- 循环等待条件：若干个进程形成环形链，每个都占用对方申请的下一个资源

#### 如何解决死锁

(1) 死锁预防：破坏导致死锁必要条件中的任意一个就可以预防死锁。例如，要求用户申请资源时一次性申请所需要的全部资源，这就破坏了保持和等待条件；将资源分层，得到上一层资源后，才能够申请下一层资源，它破坏了环路等待条件。预防通常会降低系统的效率。

- 打破互斥条件：允许进程同时访问资源（有些资源就是不可以同时访问的，无实用价值）
- 打破不可抢占条件：比如给进程设置优先级，高优先级的可以抢占资源(实现困难，降低系统性能)
- 打破占有且等待条件：实行资源预分配策略，即进程在运行前一次性的向系统申请它所需要的全部资源(不可预测资源的使用，利用率低，降低并发性)
- 破坏循环等待条件：采用这种策略，即把资源事先分类编号，按号分配，使进程在申请，占用资源时不会形成环路。所有进程对资源的请求必须严格按资源序号递增的顺序提出（限制和编号实现困难，增加系统开销，有些资源暂时不用也需要先申请，增加了进程对资源的占用时间）

(2) 死锁避免：避免是指进程在每次申请资源时判断这些操作是否安全，例如，使用[银行家算法](https://zhuanlan.zhihu.com/p/59533950)。死锁避免算法的执行会增加系统的开销。

(3) 死锁检测：死锁预防和避免都是事前措施，而死锁的检测则是判断系统是否处于死锁状态，如果是，则执行死锁解除策略。

(4) 死锁解除：这是与死锁检测结合使用的，它使用的方式就是剥夺。即将某进程所拥有的资源强行收回，分配给其他的进程。

#### 死锁的java代码举例

#### 产生死锁主要的原因 

① 系统资源不足、② 进程运行顺序不合适、③ 资源分配不当 

#### 如何定位死锁

jps -l

jstack -l pid

## JMM

### jmm引出原因

内存数据不一致
指令重排序

### 什么是jmm

本质上是一种规则，用来约束程序中的共享变量的访问方式，为了屏蔽掉各种硬件和操作系统的内存访问差异，让Java程序在各个平台下都能达到一致访问内存的效果，规定所有变量都存储在主内存中，每个线程都有自己的工作内存，工作内存中存储了该线程使用到的变量的主内存副本的拷贝，线程对变量的操作全都是在工作内存中，无法直接对主内存和其他线程的工作内存的变量进行操作

### jmm结构图

### jmm相关的与内存交互的8个操作及流转图

![image](https://oscimg.oschina.net/oscnet/536c6dfd-305a-4b95-b12c-28ca5e8aa043.png)

- read:将主存中的一个变量传输到工作内存中
- load:在read后执行，将read得到的值放入工作内存的变量副本中
- use:把工作内存中的值传入到执行引擎
- assign:将执行引擎接收到的值赋给工作内存的变量
- store:将工作内存中的值传送到主存中
- wtite:在store之后，将store获得的值写入主存的变量中
- lock:作用于主存
- unlock:作用于主存

### 重排序类型3个

编译器优化的重排序
指令并行的重排序
内存系统的重排序

### 遵守 as-if-serial
不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被 编译器和处理器重排序。

### 什么是happen-before

通过这个概念来阐述操作之间的内存可见性

1. 如果一个操作happens-before(之前发生)另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。
2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。

#### happen-before基本规则

程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
线程启动（start()）规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。
线程中止join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。
线程中断规则：对线程interrupted()方法的调用先行于被中断线程的代码检测到中断时间的发生。
对象终结规则：一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始。

### DCL(Double Check Lock)产生和解决方式

> https://www.cnblogs.com/hexinwei1/p/9909555.html

```
 public class Singleton {
        private static Singleton singleton;
        Integer a;

        private Singleton(){}

        public static Singleton getInstance(){
            if(singleton == null){                              // 1 只有singleton==null时才加锁，性能好
                synchronized (Singleton.class){                 // 2
                    if(singleton == null){                      // 3
                        singleton = new Singleton();            // 4
                    }
                }
            }
            return singleton;
        }
    }
```

产生：

由于指令重排序，创建对象的过程中初始化对象和赋值操作可能发生重排序。A线程singleton = new Singleton()发生重排序，将分配的内存空间引用赋值给了静态属性singleton（即singleton != null），而对象还未初始化（即Integer a == null）；B线程此时调用getInstance()方法，因为singleton != null，直接返回singleton。当B线程使用singleton的a属性时就会空指针。

（1）分配内存空间

（2）初始化对象

（3）将内存空间的地址赋值给对应的引用

（2）（3）会被处理器优化，发生重排序

问题所在：

问题在于singleton = new Singleton()的重排序

解决：

1、利用volatile限制重排序

```
public class Singleton {
        private volatile static Singleton singleton;// 通过volatile关键字来确保安全

        private Singleton(){}

        public static Singleton getInstance(){
            if(singleton == null){
                synchronized (Singleton.class){
                    if(singleton == null){
                        singleton = new Singleton();
                    }
                }
            }
            return singleton;
        }
    }
```

  2、利用类初始化,静态内部类

利用类初始化，JVM在类的初始化阶段（即在Class被加载后，且被线程使用之前），会执行类的初始化。在执行类的初始化期间，JVM会去获取一个锁。这个锁可以同步多个线程对同一个类的初始化。基于这个特性，可以实现另一种线程安全的延迟初始化方案。 

​		public class Singleton {
​	        private static class SingletonHolder{
​	            public static Singleton singleton = new Singleton();
​	        }
​	        
​	        public static Singleton getInstance(){
​	            return SingletonHolder.singleton;
​	        }
​	    }

#### 各种单例模式的写法

https://blog.csdn.net/qq_38734403/article/details/106976266

### jmm的3大特性

原子性、可见性、有序性

原子性：指一个操作是不可中断的，即使是多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰，使用synchronize保证

可见性：指当一个线程修改了某一个共享变量的值，其他线程是否能够立即知道这个修改。显然，对于串行程序来说，可见性问题  是不存在。因为你在任何一个操作步骤中修改某个变量，那么在后续的步骤中，读取这个变量的值，一定是修改后的新值。但是这个问题在并行程序中就不见得了。如果一个线程修改了某一个全局变量，那么其他线程未必可以马上知道这个改动。volatile、 synchronized、ﬁnal三个关键字可以实现可见性

有序性：对于一个线程的执行代码而言，我们总是习惯地认为代码的执行时从先往后，依次执行的。这样的理解也不能说完全错误，因为就一个线程而言，确实会这样。但是在并发时，程序的执行可能就会出现乱序。给人直观的感觉就是：写在前面的代码，会在后面执行。有序性问题的原因是因为程序在执行时，可能会进行指令重排，重排后的指令与原指令的顺序未必一致。happen before原则保证

### MESI缓存一致性协议

> https://www.bilibili.com/video/av928976717/
>
> https://www.cnblogs.com/yanlong300/p/8986041.html

多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI。

解决现代处理器和内存处理速度不匹配的问题，CPU与内存在进行数据传输的时候需要与总线交互，同时会不断的监听和嗅探总线上发生的数据交换事件，跟踪一下其他缓存在做什么操作， 当一个缓存所代表的处理器进行读写操作时，其他缓存都会得到通知，以此使自己的缓存保证同步.

 在MESI协议中，每个缓存行有4个状态，可用2个bit表示，它们分别是： 

| 状态         | 描述                                                         |
| ------------ | ------------------------------------------------------------ |
| M(Modified)  | 这行数据有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。 |
| E(Exclusive) | 这行数据有效，数据和内存中的数据一致，数据只存在于本Cache中。 |
| S(Shared)    | 这行数据有效，数据和内存中的数据一致，数据存在于很多Cache中。 |
| I(Invalid)   | 这行数据无效。                                               |

## volatile

### volatile出现原因

现代CPU为了提高处理速度，在主存与CPU之间加了一层高速缓存，各个线程对与共享变量的读取也是会缓存到自己的线程工作内存中，而不是直接与主存进行数据的交互，当数据处理完毕后，才会将处理后的数据写回主存

多线程下，同时修改一个共享变量，其他线程不能立即看到该线程修改后的值

### 什么是volatile

volcatile是一种乐观锁机制，采用CAS算法实现对共享变量的同步，
对于volcatile变量，每个线程对于变量的读写操作都需要同步主存，不在自己的工作内存直接读取和操作

### volatile的三大特性

- 内存可见性：基于 CPU 的内存屏障指令, 抽象为 **happens-before** 原则，确保一个线程的修改能对其他线程是可见的。**及时通知其他线程，主物理内存的值已被修改**
- 不保证原子性：++被拆分3个指令，读，累加，写回
- 禁止指令重排序：***通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化\***。 内存屏障***另外一个作用是刷新出各种CPU的缓存数，因此任何CPU上的线程都能读取到这些数据的最新版本\***。（注，即可见性）

### 另一个线程改动了变量(volatile修饰的)，先写到工作内存还是主内存

- volatile修饰的变量在***被修改后会处理器直接将结果stroe和write进主内存，同时使得其他线程的工作内存缓存失效\***，实现可见性 
  https://www.sohu.com/a/399318783_120591934

### volatile作用

1. 可见性的保证是基于 CPU 的内存屏障指令,抽象为happens-before原则
2. volatile的一个重要作用就是和 CAS 结合，保证了原子性
3. Volatile的写和读的时候，加入屏障，防止出现指令重排

### volatile原理

　　为了实现volatile可见性和happen-befor的语义。JVM底层是通过一个叫做“内存屏障”的东西来完成。内存屏障，也叫做内存栅栏，是一组处理器指令，用于实现对内存操作的顺序限制。下面是完成上述规则所要求的内存屏障：

在每个volatile写操作的前面插入一个StoreStore屏障；
在每个volatile写操作的后面插入一个StoreLoad屏障；
在每个volatile读操作的后面插入一个LoadLoad屏障；
在每个volatile读操作的后面插入一个LoadStore屏障。

![1612250741659](C:\Users\suiyiliang\AppData\Roaming\Typora\typora-user-images\1612250741659.png)

### **共享变量 long a当两个线程来读a的时候会发生什么？**

- long存储的前32bit和后32bit可能不是同时更新
- volatile 除了保证可见性和有序性, 还解决了 long 类型和 double 类型数据的 8 字节赋值问题. 
  虚拟机规范中允许对 64 位数据类型, 分为 2 次 32 位的操作来处理, 当读取一个非 volatile 类型的 long 变量时,如果对该变量的读操作和写操作不在同一个线程中执行, 那么很有可能会读取到某个值得高 32 位和另一个值得低 32 位. 

## CAS

- CAS比较并交换算法，乐观锁策略，核心是以当前的内存地址V，旧的期望值A，与更新新值B，当满足当前A与V内的值相等时，在会将当前内存值A更改为B，否则不修改
- 缺点
  - 自旋时间过长，会给CPU带来很大开销
  - 只能维持一个共享的原子变量
  - ABA问题
- 与阻塞同同步机制的区别，无需切换线程上下文和唤醒操作，获取同一个锁的线程进入自旋进入非阻塞同步
- [面试必问的CAS](https://blog.csdn.net/v123411739/article/details/79561458)
- [什么是CAS机制？](https://blog.csdn.net/qq_32998153/article/details/79529704)

### CAS缺点

1.自旋时间过长，CPU开销比较大
2.只能维持一个共享的原子变量，不能保证操作的原子性
3.ABA问题

#### ABA问题

ABA问题
	产生
		线程ABC执行如下
A：获取对象锁要将A->B,CAS失败，自旋
B:  CAS成功，将A->B，END
C:  CAS成功，将B->A，END
A:	  CAS检测值没有变化，将A->B END
以上在某些转账，库存扣减时可能引发巨大的问题
	解决
		追加版本号，每次更新将版本号+1，那么就变成了1A->2B->3A了
	示例

#### 原子类Auticom类中的ABA问题

AtomicStampedReference

```
atomicStampedReference=new AtomicStampedReference<>(值，时间戳-版本号)
atomicStampedReference.compareAndSet(现值，期望值，期望版本号，新版本号)
```

#### 与synchronized区别
1. volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取； synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
2. volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的
3. volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性
4. volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。
5. volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化

### 手动一个CAS实现一个锁

```java
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicReference;
/**
* 题目：实现一个自旋锁
* 自旋锁好处：循环比较获取直至成功为止，没有类似wait的阻塞。
*
* 通过CAS操作完成自旋锁，A线程先进来调用myLock方法，自己持有5秒钟，
* B随后进来后发现，当前线程持有锁，不是null，
* 所以只能通过自旋等待，直到A释放锁后B随后抢到。
*/
public class SpinLockDemo {
// 原子引用线程
AtomicReference<Thread> atomicReference = new AtomicReference<>();
public void myLock(){
    Thread thread = Thread.currentThread(); // 当前进来的线程
    System.out.println(thread.getName() + "\t come in!");
    while(!atomicReference.compareAndSet(null,thread)){//期望值，现值为null，当前线程进去
    }
}
// 解锁
public void myUnlock(){
    Thread thread = Thread.currentThread();
    atomicReference.compareAndSet(thread,null); // 用完，设置为null
    System.out.println(thread.getName() + "\t invoked myUnlock()");
}
public static void main(String[] args) {
    SpinLockDemo spinLockDemo = new SpinLockDemo();
    new Thread(()->{
        spinLockDemo.myLock();
        // 暂停一会线程
        try {TimeUnit.SECONDS.sleep(5);} catch (InterruptedException e) {e.printStackTrace();}
        spinLockDemo.myUnlock();
    },"AA").start();
// 保证A先启动
try {TimeUnit.SECONDS.sleep(1);} catch (InterruptedException e) {e.printStackTrace();}
    new Thread(()->{
        spinLockDemo.myLock();
        spinLockDemo.myUnlock();
    },"BB").start();
}
}
```



## 对象头

### 对象头的结构

- 对象头
  - mark word标记字
  - class point类指针：指向方法区类对象的指针，表明该对象随时可以知道自己是哪一个类的实例
  - 数组长度
- 对象体（实例数据）
- 对齐子节（对齐填充）

### 标记字重要字段

- bised_lock：1:启用偏向锁，0：没有启用
- age：4位对象年龄，在GC中，如果对象在survivor区复制一次，那么age+1，当达到阈值时，将会晋升老年代。默认情况下并行的GC年龄时15，并发的GC年龄时5。age最大4位，即最大值是15。所以参数-XX:MaxTenuringThreshold为15的原
- identity_hashcode
  	31位的对象hashcode，采用延时加载技术，调用System.idtentityHashCode()计算，并将该结果写入到对象头里面。当对象锁升级为偏向、轻量级、重量级锁后，由于没有足够的存储空间，所以该值会被转移到管称monitor中
- thread
  	偏向锁ID
- epoch
  	偏向时间戳
- ptr_to_lock_record
  	指向锁记录的指针
- ptr_to_heavyweight_monitor
  	指向对象监视器的monitor指针

### 标记字中lock状态有哪些

- 01:无锁｜偏向锁
- 00:轻量级锁
- 10:重量级锁
- 11:GC标记

## synchronized

> https://blog.csdn.net/javazejian/article/details/72828483

### synchronized使用方式

1. 静态方法
2. 实例方法
3. 代码块

**1）修饰一个实例对象**，被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象； 
2）**修饰一个方法**，被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象； 
3）**修饰一个静态的方法**，其作用的范围是整个静态方法，作用的对象是这个类的所有对象； 
4）**修饰一个类**，其作用的范围是synchronized后面括号括起来的部分，作用主的对象是这个类的所有对象。

### synchronized实现原理

1. 代码块，在使用synchronized之后，底层会在执行代码块或者方法的之前添加moniterenter指令，去获取或者等待锁，一旦获取到锁，那么就会根据指令机制对当前对象的计数器+1，释放锁monitorexit-1。未获取到锁则进入同步队列中
2. 方法：如果synchronized在方法上，那就没有上面两个指令，取而代之的是有一个ACC_SYNCHRONIZED修饰，表示方法加锁了。然后可以在常量池中获取到锁对象，实际实现原理和同步块一致，后面也会验证这一点

### synchronized锁的重入性

锁的重入性:同一线程中，如果已经获取锁对象，再次获取锁对象时，不需要再次获取锁，而是在对象计数器机型累加，退出时累减

### 对象监视器monitor

> https://blog.csdn.net/javazejian/article/details/72828483

#### 什么是对象监视器

jvm中Hotspot关于synchronized锁的实现是靠ObjectMonitor（对象监视器）实现的，
当多个线程同时请求一个对象监视器（请求同一个锁）时，对象监视器将设置几个状态以用于区分调用线程：

每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现

#### 对象监视器结构

```c++
ObjectMonitor() {
    _header       = NULL;//displaced object header word - mark  markOop对象头
    _count        = 0;
    _waiters      = 0,//number of waiting threads 等待线程数
    _recursions   = 0;//recursion count, 0 for first entry  重入的次数
                      //我觉得，记录的是同一个线程获取锁的次数
    _object       = NULL;//backward object pointer - strong root 监视器锁关联的对象
    _owner        = NULL;//pointer to owning thread OR BasicLock 指向获取锁的线程
    _WaitSet      = NULL;//LL of threads wait()ing on the monitor
                         //我觉得意思是获得锁之后，调用wait()方法，然后被阻塞的队列
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;//recently-arrived threads blocked on entry
                          // The list is actually composed of WaitNodes, acting
                          // as proxies for Threads.
                          //我觉得意思是，就是最近的一端时间，尝试获取锁的时候，被阻塞的线程组成的队列
    FreeNext      = NULL ;
    _EntryList    = NULL ;//Threads blocked on entry or reentry.
                          //存放的是因为获取锁被阻塞的线程，或者是从_WaitSet中取出的准备再次获取锁的线程
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
    _previous_owner_tid = 0;//监视器的前一个拥有者线程的ID
  }
```

#### 对象监视器加锁解锁的过程

当多个线程同时访问一段同步代码时，多个线程会先被存放在 EntryList 集合中，处于block状态的线程，都会被加入到该列表。接下来当线程获取到对象的 Monitor 时，Monitor 是依靠底层操作系统的 Mutex Lock 来实现互斥的，线程申请 Mutex 成功，则持有该 Mutex，其它线程将无法获取到该 Mutex。如果线程调用 wait() 方法，就会释放当前持有的 Mutex，并且该线程会进入 WaitSet 集合中，等待下一次被唤醒。如果当前线程顺利执行完方法，也将释放 Mutex。 

获取锁
	ObjectMonitor::enter过程

```
1.通过CAS尝试把monitor的_owner设置为当前线程
2.如果设置之前的_owner指向自己，说明当前线程再次进入montior，即重入锁，则将_recursions++，记录重入的次数
3.查看当前线程的锁记录中的Displayed Mark Word，是否是改线程的轻量级锁持有者，如果是第一次加重量级锁，设置_recursions=1，_owner指向当前线程，该线程成功获取锁并返回
4.如果获取锁失败，则等待锁的释放
```

	ObjectMonitor::EnterI（竞争是失败的线程触发）

```
1.将当前线程包装成ObjectWait对象的node，设置状态为TS_CXQ
2.CAS自旋采用头插法将其插入cxq队列
3.如果node插入cxq失败，则再次尝试获取一次锁，如果还是没有获取到锁，则通过park将当前线程挂起，等待被唤醒
```

获取锁
	ObjectMonitor::enter过程

```
1.通过CAS尝试把monitor的_owner设置为当前线程
2.如果设置之前的_owner指向自己，说明当前线程再次进入montior，即重入锁，则将_recursions++，记录重入的次数
3.查看当前线程的锁记录中的Displayed Mark Word，是否是改线程的轻量级锁持有者，如果是第一次加重量级锁，设置_recursions=1，_owner指向当前线程，该线程成功获取锁并返回
4.如果获取锁失败，则等待锁的释放
```

	ObjectMonitor::EnterI（竞争是失败的线程触发）

```
1.将当前线程包装成ObjectWait对象的node，设置状态为TS_CXQ
2.CAS自旋采用头插法将其插入cxq队列
3.如果node插入cxq失败，则再次尝试获取一次锁，如果还是没有获取到锁，则通过park将当前线程挂起，等待被唤醒
```

### 1.6后的锁升级

![1612252498768](https://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/864E5868CA07408C9C41AD2FF6B5ECD1/17497)

#### 各级别锁的优点

| 锁       | 优点                                                         | 缺点                                                         | 适用场景                           |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------- |
| 偏向锁   | 加锁和解锁不会消耗额外的资源，和执行非同步方法只有纳秒级的差别 | 如果线程间存在锁的竞争回发生锁的竞争会带来额外撤销和升级锁的操作 | 单线程获取同步锁                   |
| 轻量级锁 | 竞争锁不会发生阻塞，提高程序的响应速度                       | 如果得不到锁的竞争，会导致自旋消耗cpu                        | 追求响应速度，同步块执行速度非常快 |
| 重量级锁 | 不会发生自旋，不会消耗cpu                                    | 线程阻塞和唤醒，频繁切换线程上下午带来额外的消耗，响应时间变长 | 追求吞吐量，同步块执行时间长       |



### synchronize与lock的区别

https://blog.csdn.net/e54332/article/details/86577071

## final原理

### final、finally、finalize用法和区别

https://www.cnblogs.com/smart-hwt/p/8257330.html

## 中断

*java*中的*中断*其实是一种协作的机制,让你可以更好的构造可取消任务。如果正在执行的任务强制结束,那么很可能会造成数据不一致的情况,而*中断*不要求立即返回,

```
	public static boolean interrupted()
    测试当前线程是否已经中断。线程的中断状态由该方法清除。
    public boolean isInterrupted()
    测试线程是否已经中断。线程的中断状态不受该方法的影响。
    public void interrupt()
    中断线程
```

## Unsafe

> https://www.jianshu.com/p/db8dce09232d

Java和C++语言的一个重要区别就是Java中我们无法直接操作一块内存区域，不能像C++中那样可以自己申请内存和释放内存。Java中的Unsafe类为我们提供了类似C++手动管理内存的能力。Unsafe类，全限定名是sun.misc.Unsafe，从名字中我们可以看出来这个类对普通程序员来说是“危险”的，一般应用开发者不会用到这个类。

Unsafe类是"final"的，不允许继承。且构造函数是private的,通过反射来获取Unsafe：

```
public Unsafe getUnsafe() throws IllegalAccessException {
    Field unsafeField = Unsafe.class.getDeclaredFields()[0];
    unsafeField.setAccessible(true);
    Unsafe unsafe = (Unsafe) unsafeField.get(null);
    return unsafe;
}
```

## LockSupport

基于unsafe封装的

> https://www.cnblogs.com/takumicx/p/9328459.html

## 并发包中的原子操作类(Atomic系列)

> https://blog.csdn.net/javazejian/article/details/72772470

从JDK 1.5开始提供了java.util.concurrent.atomic包，在该包中提供了许多基于CAS实现的原子操作类，用法方便，性能高效

## AQS

锁是多个线程访问共享资源的方式，一般来说锁能够防止多个线程同时访问一个共享资源。在Lock之前，java以synchronized关键字实现锁的功能，而在1.5后增加了lock接口，它提供了与synchronzed一样的锁功能，虽然没有隐式的加锁解锁的方便性，但是它却拥有了锁释放和获取的可操作性，可中断锁以及超时获取锁等多种synchronzed不具有的特性

AQS负责同步状态的管理，线程的排队，等待和唤醒这些底层操作，而Lock等同步组件主要专注于实现同步语义；
### AQS实现原理
基于FIFO的双向链表队列，对于volatile变量作为锁状态status，锁是循环+cas
### AQS队列实现

### AQS队列为什么采用了头结点呢？

> https://blog.csdn.net/qjh5606/article/details/85546870

头结点也叫哨兵节点，用来简化边界条件，其值域不存储任何东西，只是为了方便操作引入
### AQS可重写的方法
tryAcquire 

tryRelease

tryAcquireShared

tryReleaseShared
### AQS模板方法
accquire

accquireInterruptibly

tryaccquireNanos

accquireShared

accquireSharedInterruptibly

tryaccquireSharedNanos

```
private boolean doAcquireNanos(int arg, long nanosTimeout)
            throws InterruptedException {
        if (nanosTimeout <= 0L)
            return false;
        final long deadline = System.nanoTime() + nanosTimeout;
        final Node node = addWaiter(Node.EXCLUSIVE);
        boolean failed = true;
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head && tryAcquire(arg)) {
                    setHead(node);
                    p.next = null; // help GC
                    failed = false;
                    return true;
                }
                nanosTimeout = deadline - System.nanoTime();
                if (nanosTimeout <= 0L)
                    return false;
                if (shouldParkAfterFailedAcquire(p, node) &&
                    nanosTimeout > spinForTimeoutThreshold)
                    LockSupport.parkNanos(this, nanosTimeout);
                if (Thread.interrupted())
                    throw new InterruptedException();
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }

超时等待
```



release
relaseShared
### AQS公平和非公平锁原理区别
队列中有头尾指针不指向同一个节点，且头结点的下一个节点不为null或者头结点的后置节点不是当前线程节点才算当前需要排队

```
 public final boolean hasQueuedPredecessors() {
        // The correctness of this depends on head being initialized
        // before tail and on head.next being accurate if the current
        // thread is first in queue.
        Node t = tail; // Read fields in reverse initialization order
        Node h = head;
        Node s;
        return h != t &&
            ((s = h.next) == null || s.thread != Thread.currentThread());
    }
```

#### 为什么要区分公平和非公平呢

1. 恢复挂起的线程到真正锁的获取还是有时间差的，从人类的角度来看这个时间微乎其微，但是从CPU的角度来看，这个时间差存在的还是很明显的。所以非公平锁能更充分的利用 CPU 的时间片，尽量减少 CPU 空闲状态时间
2. 不知你是否还记得我在 [面试问，创建多少个线程合适？](https://dayarch.top/p/how-many-threads-should-be-created.html) 文章中反复提到过，使用多线程很重要的考量点是线程切换的开销，想象一下，如果采用非公平锁，当一个线程请求锁获取同步状态，然后释放同步状态，因为不需要考虑是否还有前驱节点，所以刚释放锁的线程在此刻再次获取同步状态的几率就变得非常大，所以就减少了线程的开销。

#### 非公平锁会带来饥饿

公平锁保证了排队的公平性，非公平锁霸气的忽视这个规则，所以就有可能导致排队的长时间在排队，也没有机会获取到锁，这就是传说中的 **“饥饿”**

### AQS独占式和共享式区别

### AQS的Node节点有哪些状态

| SIGNAL    | 值为-1，后继节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，那么就会通知后继节点，让后继节点的线程能够运行 |
| --------- | ------------------------------------------------------------ |
| CONDITION | 值为-2，节点在等待队列中，节点线程等待在Condition上，不过当其他的线程对Condition调用了signal()方法后，该节点就会从等待队列转移到同步队列中，然后开始尝试对同步状态的获取 |
| PROPAGATE | 值为-3，表示下一次的共享式同步状态获取将会无条件的被传播下去 |
| CANCELLED | 值为1，由于超时或中断，该节点被取消。 节点进入该状态将不再变化。特别是具有取消节点的线程永远不会再次阻塞 |
| INITIAL   | 值为0，初始状态                                              |

![image](https://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/A97B8E235DB24EA4A4F48BE03FFE561C/17500)

### 独占式

#### 独占式获取锁的过程

![image](https://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/6A8D6BD5A2F441C696EB230287E0C457/17507)
#### 什么时候会执行finally里面的cancelAcquire

如果要执行cancelAcquire的话 需要获取不到锁，在获取前置节点的时候如果前置节点为null会抛出异常（一般不会是这个），以ReentrantLock为例，那就是重写的tryAcquire()方法的时候会在重入判断的时候判断当前同步状态+acquires<0就抛出异常。其核心目的就是从等待队列中移除 CANCELLED 的节点，并重新拼接整个队列

#### 独占式解锁的过程
```
public final boolean release(int arg) {
        if (tryRelease(arg)) {
            Node h = head;
            //头结点存在并且头结点的后继节点存在唤醒后继节点
            if (h != null && h.waitStatus != 0)
                unparkSuccessor(h);
            return true;
        }
        return false;
    }
private void unparkSuccessor(Node node) {
        /*
         * If status is negative (i.e., possibly needing signal) try
         * to clear in anticipation of signalling.  It is OK if this
         * fails or if status is changed by waiting thread.
         */
        int ws = node.waitStatus;
        if (ws < 0)
            compareAndSetWaitStatus(node, ws, 0);

        /*
         * Thread to unpark is held in successor, which is normally
         * just the next node.  But if cancelled or apparently null,
         * traverse backwards from tail to find the actual
         * non-cancelled successor.
         */
        Node s = node.next;
        if (s == null || s.waitStatus > 0) {
            s = null;
            for (Node t = tail; t != null && t != node; t = t.prev)
                if (t.waitStatus <= 0)
                    s = t;
        }
        if (s != null)
            LockSupport.unpark(s.thread);
    }

```
#### 独占式中断获取锁

在自旋+case获取锁的时候再shouldParkAfterFailedAcquire获取成功和阻塞被环境返回的中断状态为true后，抛出中断异常

#### 独占式超时获取锁

​    static final long spinForTimeoutThreshold = 1000L;

如果差时小于1000L就不进行挂起和唤醒了，而是进行自旋

#### 为什么同步队列的遍历总是从后向前呢？

从尾插法看，在获取锁的时候是先添加前置指针，在cas设置尾结点成功后才设置next指针，从头结点的变动看，也是
### 共享式

#### 共享式加锁的过程
与独占式差不多，不过在自旋加锁的时候setHeadAndPropagate

```java
private void doAcquireShared(int arg) {
       // 创建共享节点「SHARED」，加到等待队列中
        final Node node = addWaiter(Node.SHARED);
        boolean failed = true;
        try {
            boolean interrupted = false;
           // 进入“自旋”，这里并不是纯粹意义上的死循环，在独占式已经说明过
            for (;;) {
               // 同样尝试获取当前节点的前驱节点
                final Node p = node.predecessor();
               // 如果前驱节点为头节点，尝试再次获取同步状态
                if (p == head) {
                   // 在此以非阻塞式获取同步状态
                    int r = tryAcquireShared(arg);
                   // 如果返回结果大于等于零，才能跳出外层循环返回
                    if (r >= 0) {
                       // 这里是和独占式的区别
                        setHeadAndPropagate(node, r);
                        p.next = null; // help GC
                        if (interrupted)
                            selfInterrupt();
                        failed = false;
                        return;
                    }
                }
                if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
 private void setHeadAndPropagate(Node node, int propagate) {
        Node h = head; // Record old head for check below
        setHead(node);
        /*
         * Try to signal next queued node if:
         *   Propagation was indicated by caller,
         *     or was recorded (as h.waitStatus either before
         *     or after setHead) by a previous operation
         *     (note: this uses sign-check of waitStatus because
         *      PROPAGATE status may transition to SIGNAL.)
         * and
         *   The next node is waiting in shared mode,
         *     or we don't know, because it appears null
         *
         * The conservatism in both of these checks may cause
         * unnecessary wake-ups, but only when there are multiple
         * racing acquires/releases, so most need signals now or soon
         * anyway.
         */
        if (propagate > 0 || h == null || h.waitStatus < 0 ||
            (h = head) == null || h.waitStatus < 0) {
            Node s = node.next;
            if (s == null || s.isShared())
                doReleaseShared();
        }
    }
```


#### 共享式解锁的过程
```
public final boolean releaseShared(int arg) {
        if (tryReleaseShared(arg)) {
            doReleaseShared();
            return true;
        }
        return false;
    }
 private void doReleaseShared() {
       
        for (;;) {
            Node h = head;
            if (h != null && h != tail) {
                int ws = h.waitStatus;
                if (ws == Node.SIGNAL) {
                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                        continue;            // loop to recheck cases
                    unparkSuccessor(h);
                }
                else if (ws == 0 &&
                         !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                    continue;                // loop on failed CAS
            }
            if (h == head)                   // loop if head changed
                break;
        }
    }

```
### Condition

#### condition的阻塞和唤醒与object的阻塞唤醒区别

为了实现lock体系下的等待/通知机制，推出Condition与Lock配合完成等待通知机制。Object与Sync是java底层级别的，而Condition是代码级别的，具有更高的扩展性和控制性。

#### 队列实现原理

等待队列数据机构采用AQS内的Node节点的数据结构，也是以尾插法入队，有头指针和尾指针管理队列，没有头节点，但是其结构是一个单项的链表

#### await实现原理

```
public final void await() throws InterruptedException {
    // 1.如果当前线程被中断，则抛出中断异常
    if (Thread.interrupted())
        throw new InterruptedException();
    // 2.将节点加入到Condition队列中去，这里如果lastWaiter是cancel状态，那么会把它踢出Condition队列。
    Node node = addConditionWaiter();
    // 3.调用tryRelease，释放当前线程的锁
    long savedState = fullyRelease(node);
    int interruptMode = 0;
    // 4.为什么会有在AQS的等待队列的判断？
    // 解答：signal操作会将Node从Condition队列中拿出并且放入到等待队列中去，在不在AQS等待队列就看signal是否执行了
    // 如果不在AQS等待队列中，就park当前线程，如果在，就退出循环，这个时候如果被中断，那么就退出循环
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    // 5.这个时候线程已经被signal()或者signalAll()操作给唤醒了，退出了4中的while循环
    // 自旋等待尝试再次获取锁，调用acquireQueued方法
    //被唤醒后尝试获取锁 参考获取锁的方式
    if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null)
        //清除不是CONDITION状态的节点
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);

```



#### signal/signalAll实现原理

```java
public final void signal() {
            if (!isHeldExclusively())
                throw new IllegalMonitorStateException();
            Node first = firstWaiter;
            if (first != null)
                doSignal(first);
        }
private void doSignal(Node first) {
            do {
                        	//改变头指针的位置，头指针的后继节点为null 将尾指针置为null
                if ( (firstWaiter = first.nextWaiter) == null)
                    lastWaiter = null;
                                        //原头节点断开链表
                first.nextWaiter = null;
            } while (!transferForSignal(first) &&
                     (first = firstWaiter) != null);
        }
final boolean transferForSignal(Node node) {
        // 节点状态没有取消那么就取消 进入自旋
        if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
            return false;

        //条件队列里面的节点 加入同步对了，让节点继续获取锁，
  			//设置前置节点状态为SINGAL 前置节点状态取消｜设置状态失败的话就唤醒前置节点的线程
        Node p = enq(node);
        int ws = p.waitStatus;
        if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
            LockSupport.unpark(node.thread);
        return true;
    }
//all的原理就是将所有的条件队列中的节点都放入同步队列
private void doSignalAll(Node first) {
            lastWaiter = firstWaiter = null;
            do {
                Node next = first.nextWaiter;
                first.nextWaiter = null;
                transferForSignal(first);
                first = next;
            } while (first != null);
        }
```

#### condition的原理大致流程

```html
而Condition自己也维护了一个队列，该队列的作用是维护一个等待signal信号的队列，两个队列的作用是不同，事实上，每个线程也仅仅会同时存在以上两个队列中的一个，流程是这样的：
1. 线程1调用reentrantLock.lock时，线程被加入到AQS的等待队列中。
2. 线程1调用await方法被调用时，该线程从AQS中移除，对应操作是锁的释放。
3. 接着马上被加入到Condition的等待队列中，以为着该线程需要signal信号。、
4. 线程2，因为线程1释放锁的关系，被唤醒，并判断可以获取锁，于是线程2获取锁，并被加入到AQS的等待队列中。
5.  线程2调用signal方法，这个时候Condition的等待队列中只有线程1一个节点，于是它被取出来，并被加入到AQS的等待队列中。  注意，这个时候，线程1 并没有被唤醒。
6. signal方法执行完毕，线程2调用reentrantLock.unLock()方法，释放锁。这个时候因为AQS中只有线程1，于是，AQS释放锁后按从头到尾的顺序唤醒线程时，线程1被唤醒，于是线程1回复执行。
```

## AQS的实现类

	ReentrantLock 
	ReentrantReadWriteLock 
	Semaphore
	CountDownLatch 

### 如何用AQS实现自己的互斥锁

自定义互斥锁实现lock，内部类sync继承AQS重写tryAcquire和tryRelease方法

![image](https://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/69C81A37BF8046228413740EE35C2A0B/17505)

## 并发工具

### CountDownLatch

> https://www.cnblogs.com/Lee_xy_z/p/10470181.html

CountDownLatch是一个同步工具类，用来协调多个线程之间的同步，或者说起到线程之间的通信（而不是用作互斥的作用）。犹如倒计时计数器，调用CountDownLatch对象的countDown方法将计数机减一，当计数到达0时，则所有等待者或单个等待者开始执行。这直接通过代码来说明CountDownLatch的作用，

#### **CountDownLatch的用法**

CountDownLatch典型用法：1、某一线程在开始运行前等待n个线程执行完毕。将CountDownLatch的计数器初始化为new CountDownLatch(n)，每当一个任务线程执行完毕，就将计数器减1 countdownLatch.countDown()，当计数器的值变为0时，在CountDownLatch上await()的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。

CountDownLatch典型用法：2、实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的CountDownLatch(1)，将其计算器初始化为1，多个线程在开始执行任务前首先countdownlatch.await()，当主线程调用countDown()时，计数器变为0，多个线程同时被唤醒。

#### 实现原理

内部Sync继承了AQS，在其构造器初始化的时候，通过传进来的status，对线程状态进行初始化，重写共享锁方法tryAcquireShared和tryReleaseShared，原理是获取锁的时候将线程状态检测线程状态是否为0，不为0则认为没有获取到锁，在countDown（计数）或者说释放说的时候对status--，直到0，最后一个线程将锁状态置为0后会唤醒同步队列中的节点线程。

```java
protected int tryAcquireShared(int acquires) {
            return (getState() == 0) ? 1 : -1;
        }

        protected boolean tryReleaseShared(int releases) {
            // Decrement count; signal when transition to zero
            for (;;) {
                int c = getState();
                if (c == 0)
                    return false;
                int nextc = c-1;
              	//最后一个将锁状态置为0的线程去唤醒同步队列中正在排队获取锁的线程
                if (compareAndSetState(c, nextc))
                    return nextc == 0;
            }
        }
```

#### **CountDownLatch的不足**

是一次性的，计数器只能在构造初始化一次，之后没有任何机制再次设置值，当使用完毕的时候不能再次使用



### CyclicBarrier

> https://blog.csdn.net/qq_39241239/article/details/87030142

表示打击彼此等待，大家集合好后才开始出发，分散活动后又在指定地点集合碰面，这就好比整个公司的人员利用周末时间集体郊游一样，先个子从家出发到公司集合后，再同时出发到公园游玩，在指定地点集合后在同时开始就餐

#### 实现原理

采用ReentrantLock重入锁的条件等待队列，对传入的栅栏值--，如果为0说明所有线程已经达到设定点了，此时检测有没有统一的执行Runnable command，如果有执行，通过锁的condition去唤醒所有正在等待点的线程，重新设置栅栏，并换代。如果不为0则阻塞线程或者超时阻塞后重新设置栅栏值，唤醒所有等待的condition

### Semaphore（ˈseməfɔː）

**根据一些阀值做访问控制。**可以维护当前访问自身的线程个数，并提供了同步机制。使用Semaphore可以控制同时访问资源的线程个数，
例如实现一个文件允许的并发访问数。允许同时访问的线程最大个数，相当于超市结账时，营业员的数目。

```
获取锁
protected int tryAcquireShared(int acquires) {
            for (;;) {
			//公平与非公平的区别 就是判断这个
                if (hasQueuedPredecessors())
                    return -1;
                int available = getState();
                int remaining = available - acquires;
                if (remaining < 0 ||
                    compareAndSetState(available, remaining))
                    return remaining;
            }
        }

释放锁
protected final boolean tryReleaseShared(int releases) {
            for (;;) {
                int current = getState();
                int next = current + releases;
                if (next < current) // overflow
                    throw new Error("Maximum permit count exceeded");
                if (compareAndSetState(current, next))
                    return true;
            }
        }
```



#### 实现原理

内部Sync实现AQS的共享锁方法，获取锁status--，没有获取到锁的线程就进入同步队列等待，释放锁status++，按照队列顺序唤醒排队的线程

### Exchanger

用于两个线程之中，原理就是一手交钱一手交货。

## 线程池

> # 美团：https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html

### 为什么要用线程池

- 降低资源消耗：通过复用已存在的线程和降低线程关闭的次数来尽可能降低系统性能损耗
- 提升系统响应速度：通过复用线程，省去创建线程的过程，因此整体上提升了系统的响应速度
- 提高线程的可管理性：线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，
  因此，需要使用线程池来管理线程。
- **提供更多更强大的功能**：线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池ScheduledThreadPoolExecutor，就允许任务延期执行或定期执行。

### 线程池主要参数

```java
ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler)

```



- corePoolSize 线程池基本大小：当向线程池提交一个任务时，若线程池已创建的线程数小于corePoolSize，即便此时存在空闲线程，也会通过创建一个新线程来执行该任务，直到已创建的线程数大于或等于corePoolSize时，（除了利用提交新任务来创建和启动线程（按需构造），也可以通过 prestartCoreThread() 或 prestartAllCoreThreads() 方法来提前启动线程池中的基本线程。）
- maximumPoolSize线程池最大大小：线程池所允许的最大线程个数。当队列满了，且已创建的线程数小于maximumPoolSize，则线程池会创建新的线程来执行任务。另外，对于无界队列，可忽略该参数。
- keepAliveTime线程存活时间：当线程池中线程数大于核心线程数时，线程的空闲时间如果超过线程存活时间，那么这个线程就会被销毁，直到线程池中的线程数小于等于核心线程数。
- unit时间单位
- workQueue任务队列：用于传输和保存等待执行任务的阻塞队列。
- threadFactory线程池：用于创建新线程。threadFactory创建的线程也是采用new Thread()方式，threadFactory创建的线程名都具有统一的风格：pool-m-thread-n（m为线程池的编号，n为线程池内的线程编号）。
  - 默认使用Executors.defaultThreadFactory() 来创建线程。使用默认的ThreadFactory来创建线程时，会使新创建的线程具有相同的NORM_PRIORITY优先级并且是非守护线程，同时也设置了线程的名称。
- handler线程饱和策略：当线程池和队列了，再加入线程会执行此策略。

### 线程池状态转换

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/975C8D9562F147428337539571D18C62/17662)

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/36D1399BD59A4DDC803D87303C160B29/17664)

### 线程池拒绝策略

- AbortPolicy（默认）：直接拒绝所提交的任务，并抛出RejectedExecutionException异常；
- CallerRunsPolicy：只用调用者所在的线程来执行任务
- DiscardPolicy：不处理直接丢弃掉任务
- DiscardOldestPolicy：丢弃掉阻塞队列中存放时间最久的任务，加入当前任务

### 线程池执行流程

![image](https://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/A434EB0F276D451FAA220FA1E6D64061/17539)

1. 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。
2. 如果workerCount < corePoolSize，则创建并启动一个线程来执行新提交的任务。
3. 如果workerCount >= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。
4. 如果workerCount >= corePoolSize && workerCount < maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。
5. 如果workerCount >= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。

### 线程池的工作队列有哪些

- SynchronousQueue(同步移交队列)：特殊的BlockingQueue，对其的操作必须是放和取交替完成。可以简单理解为队列长度为零

- LinkedBlockingQueue(无界队列)：若其构造时指定大小，生成的BlockingQueue有大小限制，不指定大小，其大小有Integer.MAX_VALUE来决定。其所含的对象是FIFO顺序排序的。当请求越来越多时(任务处理速度跟不上任务处理速度造成请求堆积)可能导致内存占用过多或OOM

  - 底层采用单向FIFO链表，最大数量是MAX_VALUE，采用两把重入锁，分别代表存和取，同时利用两把锁的条件等待实现阻塞，用原子类AutomicInterger实现数量判断

  - ```
      /** Lock held by take, poll, etc */
        private final ReentrantLock takeLock = new ReentrantLock();
      
        /** Wait queue for waiting takes */
        private final Condition notEmpty = takeLock.newCondition();
      
        /** Lock held by put, offer, etc */
        private final ReentrantLock putLock = new ReentrantLock();
      
        /** Wait queue for waiting puts */
        private final Condition notFull = putLock.newCondition();
      
    ```

- ArrayBlockintQueue(有界队列)：规定大小的BlockingQueue，其构造必须指定大小。其所含的对象是FIFO顺序排序的。队列长度受限，当队列满了就需要创建多余的线程来执行任务

  - 实现是利用ReentrantLock锁的条件等待，定义了两个`notEmpty = lock.newCondition();notFull =  lock.newCondition();`等待条件，不空和不满。基于数组。利用基本类int作为数量判断

- PriorityBlockingQueue：类似于LinkedBlockingQueue，但是其所含对象的排序不是FIFO，而是依据对象的自然顺序或者构造函数的Comparator决定。

- DelayQueue：PriorityBlockingQueue基础上实现延时获取的无界队列。在创建元素的时候，可以指定多久才能从队列中获取当前元素。

- LinkedBlockingDeque：由链表结构组成的双向阻塞队列，队尾和队头都可以添加元素，在

  

### 如何配置线程池

- CPU密集型任务：尽量使用较小的线程池，一般为CPU核心数+1。 因为CPU密集型任务使得CPU使用率很高，若开过多的线程数，会造成CPU过度切换
- IO密集型任务：可以使用稍大的线程池，一般为2*CPU核心数。 IO密集型任务CPU使用率并不高，因此可以让CPU在等待IO的时候有其他线程去处理别的任务，充分利用CPU时间
- 混合型任务：可以将任务分成IO密集型和CPU密集型任务，然后分别用不同的线程池去处理。 只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。
  因为如果划分之后两个任务执行时间有数据级的差距，那么拆分没有意义。
  因为先执行完的任务就要等后执行完的任务，最终的时间仍然取决于后执行完的任务，而且还要加上任务拆分与合并的开销，得不偿失



## ConcurrentHashMap

- [ConcurrentHashMap相关方法介绍](https://segmentfault.com/a/1190000015907000) 
- [ConcurrentHashMap1.7与1.8区别](https://blog.csdn.net/weixin_44460333/article/details/86770169) 

## ReetrantReadWtireLock
#### 为什么更改 state 有 setState() , compareAndSetState() 两种方式，感觉后者更安全，但是锁的视线中有好多地方都使用了 setState()，安全吗？
>https://blog.csdn.net/WalleIT/article/details/88542881

分析AQS和ReentrantLock的源码可知：

- compareAndSetState通常用于在获取到锁之前，尝试加锁时，对state进行修改，这种场景下，由于当前线程不是锁持有者，所以对state的修改是线程不安全的，也就是说可能存在多个线程都尝试修改state,所以需要保证对state修改的原子性操作，即使用了unsafe类的本地CAS方法；
- setState方法通常用于当前正持有锁的线程对state变量进行修改，不存在竞争，是线程安全的，所以此处没必要用CAS保证原子性，修改的性能更重要。