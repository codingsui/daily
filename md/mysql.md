[TOC]
# 基本概念
## 什么事范式
范式本质上是一种规范，符合一种级别的关系模式集合，数据库范式分为1NF，2NF，3NF，BCNF，4NF，5NF（级别递增）。范式级别之间的关系也是层层递进的，符合高级别的范式必然符合低一级别的范式，一般我们设计关系型数据库的时候只用考虑BCNF范式即可。
### XX范式的含义
>https://blog.csdn.net/u013164931/article/details/79692402?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control&dist_request_id=5d4b3817-679f-47a3-9725-4cd3a675c3a7&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control
- 1NF：所有属性不可再分，即数据项不可再分
- 2NF：在第一范式的基础上，消除了非主属性对码的部分函数依赖
- 3NF：在第二范式的基础上，消除了非主属性对码的传递函数依赖
- BCNF：消除主属性之间的部分依赖于传递依赖
- 4NF：
- 5NF：
## DDL和DML的区别
- ML(Data Manipulation Language)数据操纵语言：对数据库中的数据进行一些简单操作，如insert,delete,update,select等。
- DDL(Data Definition Language)数据定义语言：对数据库中的某些对象(例如，database,table)进行管理，如create、alter、drop、TRUNCATE、show等

区别：

1.DML操作是可以手动控制事务的开启、提交和回滚的。

2.DDL操作是隐性提交的，不能rollback！
## delete，drop，truncate 都有删除表的作用，区别？
 1、delete 和 truncate 仅仅删除表数据，drop 连表数据和表结构一起删除，打个比方，delete 是单杀，truncate 是团灭，drop 是把电脑摔了
 2、delete 是 DML 语句，操作完以后如果没有不想提交事务还可以回滚，truncate 和 drop 是 DDL 语句，操作完马上生效，不能回滚，打个比方，delete 是发微信说分手，后悔还可以撤回，truncate 和 drop 是直接扇耳光说滚，不能反悔
 3、执行的速度上，drop>truncate>delete，打个比方，drop 是神舟火箭，truncate 是和谐号动车，delete 是自行车
 ## UNION使用
- UNION 语句：用于将不同表中相同列中查询的数据展示出来；（不包括重复数据）
- UNION ALL 语句：用于将不同表中相同列中查询的数据展示出来；（包括重复数据）
```
SELECT 列名称 FROM 表名称 UNION SELECT 列名称 FROM 表名称 ORDER BY 列名称；
SELECT 列名称 FROM 表名称 UNION ALL SELECT 列名称 FROM 表名称 ORDER BY 列名称；
```
# 基本信息查看（linux）
### 最大连接数

```sql
mysql> show variables like 'max_connections';
+-----------------+-------+
| Variable_name | Value |
+-----------------+-------+
| max_connections | 151 |
+-----------------+-------+
1 row in set (0.01 sec)
```

### 存储引擎

```
mysql> show engines
```

### 查看当前数据库中的日志使用信息：

```
mysql> show variables like 'log_%';
```
# mysql详解
## mysql数据文件构成
查看MySQL数据文件：

`SHOW VARIABLES LIKE '%datadir%';`

1）**InnoDB数据文件**

**.frm**文件：**主要存放与表相关的数据信息,主要包括**表结构的定义信息**

**.ibd**：**使用**独享表空间**存储**表数据和索引**信息，一张表对应一个ibd文件。

**ibdata**文件：**使用**共享表空间**存储**表数据和索引信息，所有表共同使用一个或者多个ibdata文

件。

**2**）**MyIsam数据文件**

**.frm**文件：**主要存放与表相关的数据信息,主要包括**表结构的定义信息

**.myd**文件：**主要用来存储**表数据信息**。

**.myi**文件：**主要用来存储**表数据文件中任何索引的数据树。

## mysql基础架构由什么组成？
大体上mysql可以分为两层，server层和存储引擎层，所有的存储引擎公用Server层。
Server层负责内置函数转换，存储过程，触发器，视图等工作。存储引擎层负责数据的存储和提取。
## mysql server层组成
![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/B68819B6621D4C0884C9CC82AD17A388/17062)
- 连接器： 与客户端建立连接，身份认证和权限相关(登录 MySQL 的时候)。
  
- 主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。
  
- 查询缓存: 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。

  - 查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集。

    连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。

    MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。

- **分析器:** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。

  - MySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步：

    **第一步，词法分析**，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。

    **第二步，语法分析**，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。（经常我们写sql报错就在这层），如果语法正确就会根据Mysql定义的语法规则，根据sql语句生成一个数据结构，这个数据结构叫做解析树。

    第三步，预处理器，会进一步检查解析树是否合法，比如表名是否存在，列是否存在等。会校验用户是否有表权限。预处理后会得到一个新的解析树。
    
    完成这 3步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。

- **优化器：** 按照 MySQL 认为最优的方案去执行。

  - 优化器的作用就是它认为的最优的执行方案去执行（有时候可能也不是最优，这篇文章涉及对这部分知识的深入讲解），比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序以哪个表为基准表等。

- **执行器:** 执行语句，然后从存储引擎返回数据。

  - 当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。

# 常见问题
## 一条sql语句是怎样在mysql中执行的？

其实我们的 sql 可以分为两种，一种是查询，一种是更新（增加，更新，删除）。我们先分析下查询语句，语句如下：
### 查询语句
> https://blog.csdn.net/xcy1193068639/article/details/84673840

```sql
select * from tb_student  A where A.age='18' and A.name=' 张三 ';
```
- 连接器建立连接，查看是否有权限
- 查询缓存（8.0后移除）
- 分析器，词法分析，语法分析，预处理器
- 优化器，确定执行方案
- 执行器，判断表执行权限，调用引擎接口查取数据

```
 a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。 
 b.先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。
```

- 进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/A2029997BC1643819A5BC683682E1D2B/17068)


### 更新语句
> https://blog.csdn.net/xcy1193068639/article/details/84922580

```update tb_student A set A.age='19' where A.name=' 张三 ```

![60f7485e69463a7bfbc19705b2e59f65.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p36)
![2fbceb495e286454c3e29a1ed75ee31b.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p37)

前面有介绍过SQL语句基本的执行链路，查询语句走的这一流程，更新语句也会走一遍。
- 连接器校验权限
- 查询缓存，是否有涉及表的缓存数据，如果有就清空该表的所有缓存数据
- 分析器，词法分析、语法分析、预处理器
- 优化器
- 执行器
    - 执行器线找到引擎取 name='张三'这一行，如果改行所在的数据页本身就在内存中，就直接返回给执行器，否则先从磁盘读区到内存，然后再返回。
    - 执行器拿到引擎数据将进行更新操作，此时将age更新为19，得到新一行数据，然后再调用引擎接口写入这行新数据
    - 引擎将这行数据更新到内存中，同时将跟新操作记录到redo log里面，状态为prepare（预提交）状态，然后告诉执行器执行完成，可以提交事务了
    - 执行器生成这个操作的binlog，并把binlog写入磁盘
    - 执行器调用引擎的提交事务接口，引擎将刚刚写入的redo log改为commit（提交）状态，更新完成

### 为什么更新的时候要两阶段提交？

> https://www.jianshu.com/p/0924ad31966d

用反证法来进行解释。由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log再写 binlog，或者采用反过来的顺序
- **先写redo log再写binlog**，假设redolog写完，binlog未写完，mysql异常重启了。我们知道redolog写完即使系统崩溃，仍然能把数据恢复回来，所以此时当前机器存在最新的数据修改操作，但是binlog少了一条记录，其他利用binlog进行数据同步的从库或者备份的数据就缺少一个数据，与原库不同了，产生 数据不一致问题。
- **先写binlog，再写redo log**，假设binlog写完后crash，redolog没写，回复崩溃之后这个事务无效，所以当前的数据没有不是最新的修改，但是 binlog里面已经记录了最新的股改，此时其他利用binlog进行数据同步的从库或者备份的数据就多了一个数据，与原库不同了，产生 数据不一致问题。

 如果采用 redo log 两阶段提交的方式就不一样了，写完 binglog 后，然后再提交 redo log 就会防止出现上述的问题，从而保证了数据的一致性。那么问题来了，有没有一个极端的情况呢？假设 redo log 处于预提交状态，binglog 也已经写完了，这个时候发生了异常重启会怎么样呢？ 这个就要依赖于 MySQL 的处理机制了，MySQL 的处理过程如下：
- 判断 redo log 是否完整，如果判断是完整的，就立即提交。
- 如果 redo log 只是预提交但不是 commit 状态，这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。

这样就解决了数据一致性的问题。
## 怎么让数据库恢复到半个月内任意一秒的状态？
binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份，这里的“定期”取决于系统的重要性。可以一天一备或者一周一备。
当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点又一次误删表，需要找回数据，那你可以这么做：
- 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库。
- 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。
- 最后，临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。


## innodb_flush_log_at_trx_commit和sync_binlog参数详解

| innodb_flush_log_at_trx_commit |                                                              |
| ------------------------------ | ------------------------------------------------------------ |
| 0                              | 每秒将日志缓冲区写入log file，并同时flush到磁盘。跟事务提交无关。在机器crash并重启后，会丢失一秒的事务日志数据（并不一定是1s，也许会有延迟，跟操作系统调度有关）,在这种情况下，MySQL性能最好 |
| 1(默认)                        | 每次事务提交将日志缓冲区写入log file(os cache)，并同时flush到磁盘。（crash不会丢失事务日志） |
| 2                              | 每次事务提交将日志缓冲区写入log file(os cache)，每秒flush一次到磁盘。（crash有可能丢失数据） |

当设置为0，该模式速度最快，但不太安全，mysqld进程的崩溃会导致上一秒钟所有事务数据的丢失。

当设置为1，该模式是最安全的， 但也是最慢的一种方式。在mysqld 服务崩溃或者服务器主机crash的情况下，binary log 只有可能丢失最多一个语句或者一个事务。。 
当设置为2，该模式速度较快，也比0安全，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失。 **

| sync_binlog |                                                              |
| ----------- | ------------------------------------------------------------ |
| 0           | （mysql默认值 ）不主动刷新二进制日志文件的数据到磁盘上，而是由操作系统决定 |
| 1           | 每提交一次事务，写一次binlog，并使用fdatasync()同步到硬盘    |
| > 1         | 每提交一次事务，写一次binlog，达到sync_binlog 设定的值后，调用fdatasync()同步到硬盘 |

一般sync_binlog设置500，1000

# 引擎

## mysql相关的引擎介绍
| 存储引擎            | **说明**                                                     |
| ------------------- | ------------------------------------------------------------ |
| **MyISAM**          | 高速引擎，拥有较高的插入，查询速度，**但不支持事务**         |
| **InnoDB**          | 5.5版本后MySQL的默认数据库，支持事务和行级锁定，比MyISAM处理速度稍慢 |
| ISAM                | MyISAM的前身，MySQL5.0以后不再默认安装                       |
| MRG_MyISAM（MERGE） | 将多个表联合成一个表使用，在超大规模数据存储时很有用         |
| **Memory**          | **内存存储引擎，拥有极高的插入，更新和查询效率。**但是会占用和数据量成正比的内存空间。只在内存上保存数据，意味着数据可能会丢失 |
| Falcon              | 一种新的存储引擎，支持事物处理，传言可能是InnoDB的替代者     |
| Archive             | 将数据压缩后进行存储，非常适合存储大量的独立的，作为历史记录的数据，但是只能进行插入和查询操作 |
| CSV                 | CSV 存储引擎是基于 CSV 格式文件存储数据(应用于跨平台的数据交换) |
- Innodb引擎：MySQL默认事务型引擎,提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。它的设计的目标就是处理大数据容量的数据库系统。InnoDB 是 MySQL 默认的事务型存储引擎，只要在需要它不支持的特性时，才考虑使用其他存储引擎。 InnoDB 采用 MVCC 来支持高并发，并且实现了四个标准隔离级别(未提交读、提交读、可重复读、可串行化)。其默认级别时可重复读（REPEATABLE READ），在可重复读级别下，通过 MVCC + Next-Key Locking 防止幻读。 
    - 主索引时聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对主键查询有很高的性能。 
    - InnoDB 内部做了很多优化，包括从磁盘读取数据时采用的可预测性读，能够自动在内存中创建 hash 索引以加速读操作的自适应哈希索引，以及能够加速插入操作的插入缓冲区等。 
    - InnoDB 支持真正的在线热备份，MySQL 其他的存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合的场景中，停止写入可能也意味着停止读取。 
    - 提供了具有提交、回滚和崩溃恢复能力的事务安全。 
    - 对比MyISAM引擎，写的处理效率会差一些，并且会占用更多的磁盘空间以保留数据和索引。 
    - InnoDB存储引擎的特点：支持自动增长列，支持外键约束 
- ② MyIASM引擎：mysql5.1及之前版本，为Mysql的默认引擎，不支持事务，也不支持行级锁和外键。优势是访问速度快，对事务完整性没有要求或者以select，insert为主的应用基本上可以用这个引擎来创建表；设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。 
    - 提供了大量的特性，包括压缩表、空间数据索引等。 
    - 不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。 
    - 可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。 
- ③ MEMORY引擎：所有的数据都在内存中，数据的处理速度快，但是安全性不高。 
    - Memory存储引擎使用存在于内存中的内容来创建表。每个memory表只实际对应一个磁盘文件，格式是.frm。memory类型的表访问非常的快，因为它的数据是放在内存中的，并且默认使用HASH索引，但是一旦服务关闭，表中的数据就会丢失掉。 
    - MEMORY存储引擎的表可以选择使用BTREE索引或者HASH索引，两种不同类型的索引有其不同的使用范围 
    - Memory类型的存储引擎主要用于哪些内容变化不频繁的代码表，或者作为统计操作的中间结果表，便于高效地对中间结果进行分析并得到最终的统计结果，。对存储引擎为memory的表进行更新操作要谨慎，因为数据并没有实际写入到磁盘中，所以一定要对下次重新启动服务后如何获得这些修改后的数据有所考虑。 
- ④ MERGE存储引擎：Merge存储引擎是一组MyISAM表的组合，这些MyISAM表必须结构完全相同，merge表本身并没有数据，对merge类型的表可以进行查询，更新，删除操作，这些操作实际上是对内部的MyISAM表进行的。

## innodb和MyISAM区别？
![73a64616a4525c7e3167b865d2062cab.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p39)
## MyISAM索引与InnoDB索引的区别？

1）InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。 
2）InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。 
3）MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。 
4）InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。

## InnoDB整体结构（存储+内存）

5.5以后版本默认存储引擎

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/6A2D9DEFB604441C9CDB3E769E4E4D6E/17081)

### innoDb存储结构

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/E4FA4819678245548BA889674501C340/17083)

- 表空间：从InnoDB存储引擎的逻辑存储结构看，所有数据都被逻辑地存放在一个空间中，称之为表空间(tablespace)。从功能上来看，InnoDB存储引擎的表空间分为系统表空间，独占表空间，通用表空间，临时表空间，Undo表空间。
  - 如果开启了独立表空间innodb_file_per_table=1，每张表的数据都会存储到一个独立的表空间，即一个单独的.ibd文件。
  - InnoDB 存储引擎有一个共享表空间，叫做系统表空间，对一个磁盘上的文件名为ibdata1。如果设置了参数innodb_file_per_table=0，关闭了独占表空间，则所有基于InnoDB存储引擎的表数据都会记录到系统表空间。
- 段：表空间是由各个段组成的，常见的段有数据段、索引段、回滚段等。如果开启了独立表空间innodb_file_per_table=1，每张表的数据都会存储到一个独立的表空间，即一个单独的.ibd文件。一个用户表空间里面由很多个段组成，创建一个索引时会创建两个段：数据段和索引段。
  - 数据段存储着索引树中叶子节点的数据。
  - 索引段存储着索引树中非叶子节点的数据。
  - 一个段的空间大小是随着表的大小自动扩展的：表有多大，段就有多大。
  - 一个段会包含多个区，至少会有一个区，段扩展的最小单位是区。
- 区：一个区由64个连续的页组成，一个区的大小=1M=64个页(16K)。为了保证区中页的连续性，区扩展时InnoDB 存储引擎会一次性从磁盘申请4 ~ 5个区。
- 页：InnoDB 每个页默认大小时是 16KB，页是 InnoDB管理磁盘的最小单位，也InnoDB中磁盘和内存交互的最小单位。`show global variables like 'innodb_page_size';`索引树上一个节点就是一个页，MySQL规定一个页上最少存储2个数据项。如果向一个页插入数据时，这个页已将满了，就会从区中分配一个新页。如果向索引树叶子节点中间的一个页中插入数据，如果这个页是满的，就会发生页分裂。操作系统管理磁盘的最小单位也是页，是操作系统读写磁盘最小单位，Linux中页一般是4K，可以通过命令查看。`#默认 4096 4K getconf PAGE_SIZE`'，所以InnoDB从磁盘中读取一个数据页时，操作系统会分4次从磁盘文件中读取数据到内存。写入也是一样的，需要分4次从内存写入到磁盘中。
- 行：InnoDB的数据是以行为单位存储的，1个页中包含多个行。在MySQL5.7中，InnoDB提供了4种行格式：Compact、Redundant、Dynamic和Compressed行格式，Dynamic为MySQL5.7默认的行格式。

创建表时可以指定行格式：

```CREATE TABLE t1 (c1 INT) ROW_FORMAT=DYNAMIC; 
CREATE TABLE t1 (c1 INT) ROW_FORMAT=DYNAMIC; 
ALTER TABLE tablename ROW_FORMAT=行格式名称; 
#修改默认行格式
SET GLOBAL innodb_default_row_format=DYNAMIC; 
#查看表行格式
SHOW TABLE STATUS LIKE 'student'\G;
```

### innoDb内存结构

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/B7DE2DCF87104776B2F1A16649F8FAAE/17085)

- Buffer Pool缓冲池：InnoDB存储引擎是基于磁盘存储的，将其中的记录按照页的方式管理，但是CPU速度和磁盘速度差距过大，基于磁盘系统的数据通常使用缓冲池记录来提高数据库的性能。
  - 缓冲池中缓存的数据页类型有：索引页、数据页、undo页、插入缓冲(insertbuffer)、自适应哈希索引(adaptive hash index)、InnoDB存储的锁信息(lock info)和数据字典信息(data dictionary)。
  - 除了有缓冲池之外，还有重做日志缓冲和额外内存池。InnoDB存储引擎首先将重做日志信息先放到这个缓冲区中，然后按照一定频率将其刷新到重做日志文件中。重做日志缓冲一般不需要设置的很大，该值可由配置参数 innodb_log_buffer_size控制。
  - **数据页和索引页**：InnoDB存储引擎工作时，需要以**Page**页为最小单位去将磁盘中的数据加载到内存中，与数据库相关的所有内容都存储在Page结构里。Page分为几种类型，数据页和索引页就是其中最为重要的两种类型。
  - insert buffer page（change buffer）：把用户修改的数据暂时插入到修改缓冲区，不是实时落盘。减少磁盘io提高性能，方便回滚。由redo log保证数据完整（机器挂）
  - adaptive hash index（自适应hash索引）：InnoDB会根据访问的频率和模式，为热点页建立哈希索引，来提高查询效率。时间复杂度为O(1),即一般仅需要一次查找就能定位数据。而B+树的查找次数,取决于B+树的高度,在生产环境中,B+树的高度一般为3~4层,故需要3~4次的查询。
    - 要求1.sql不行是等值查询where a = 123；2.以该模式访问100次；3:或者页通过该模式访问了N次，N=页中记录/16，则该数据是热点数据，可以加入hash索引
  - lock info：锁信息
  - 数据字典：InnoDB有自己的表缓存，可以称为表定义缓存或者数据字典(Data Dictionary)。当InnoDB打开一张表，就增加一个对应的对象到数据字典。
  
- 额外内存池（Addtional memory poll）：存房数据字典信息以及内部数据结构的内存空间，5.7.4中移除。

- redo log buffer重做日志缓冲区：当对数据进行增删改操作后，事务提交后，数据依然是在缓冲区中，并没有及时落盘。为了保证数据的持久化（不丢失），需要在每次事务提交时写redolog。
  
  - 写入顺序：1.插入数据时先写入change buffer ，然后写redolog buffer；2.事务提交时redolog buffer需要落盘；3.redolog写入成功，事务提交成功，否则事务提交失败
  - 写入changebuffer后，事务提交之前会修改内存数据页。查询时，刚修改的内容就可以到内存中的数据页中查询。由于内存中的数据页和磁盘上的内部不一致，此数据页就变成了“脏页”，后面checkpoint，把脏页落盘。
  
- double wite（双写缓冲区）：给innoDB存储引擎保证数据页的可靠性，Double Write由两部分组成，一部分是内存中的double write buffer，大小为2MB，另一部分是物理磁盘上共享表空间连续的128个页，大小也为2MB

  - 在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是通过memcpy函数将脏页先复制到内存中的

    double write buffer区域，之后通过double write buffer再分两次，每次1MB顺序地写入共享表空间的

    物理磁盘上，然后马上调用fsync函数，同步磁盘，避免操作系统缓冲写带来的问题。在完成double

    write页的写入后，再讲double wirite buffer中的页写入各个表空间文件中。

  - 为什么要双写？因为假设不双写，内存脏页落盘时，发生故障导致只写了一半，另外一半没有写完，重启恢复数据时由于磁盘数据页只写了一半导致数据坏了，redlog只是记录哪些页的数据修改，并不是记录页的完整数据，所以磁盘数据页就坏掉，不可用。而双写，就是将落盘的数据写入共享表空间内，假设说写共享表空间出问题，那么可以磁盘数据时完好的，如果写磁盘数据出问题，那么可以通过共享表空间的数据进行恢复，再应用redolog日志恢复数据。双写的本质就是在脏页落盘过程中做一个缓冲

  - ![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/D215F2EC3FC940C68362A9F2A2E4E462/17088)

#### 什么是脏页？

内存中的数据页和磁盘的数据页不一致，内存中的数据页就叫做脏页，实质是在更新数据的时候先更新的是内存中的数据页，此时磁盘上的数据页还未更新。

####   内存数据落盘

内存数据落盘主要是通过两个流程完成的

1. 脏页落盘
2. 预写redolog

当缓存中的页比磁盘要新时，需要讲新页刷新到磁盘。如果每一个页发生变化就刷新性能开销时很大的，索引innodb采用了

**Write Ahead Log（WAL）**和**Force log at commit**机实现事务级别的数据持久化。

wal：数据落盘前，必须讲内存中的日志落盘

flac：当一个事务提交时，所有产生的日志都必须落盘



![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/5404E91A0DBF437F9FBDE8723D086F03/17092)

#### **CheckPoint**检查点机制

对于数据库中页的**修改操作**，则首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上。页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种称为**CheckPoint**的**机制**刷新回磁盘。

目的是解决以下几个问题：1、缩短数据库的恢复时间；2、缓冲池不够用时，将脏页刷新到磁盘；3、重做日志不可用时，刷新脏页。

在InnoDB存储引擎内部，有两种Checkpoint，分别为：Sharp Checkpoint、Fuzzy Checkpoint

sharp checkpoint完全检查点：在关闭数据库的时候，将buffer pool中的脏页全部刷新到磁盘中。

fuzzy checkpoint模糊检查点：数据库正常运行时，在不同的时机，将部分脏页写入磁盘。仅刷新部分脏页到磁盘，也是为了避免一次刷新全部的脏页造成的性能问题。

#### **Fuzzy Checkpoint**刷新设置
>https://blog.csdn.net/qq_24432315/article/details/108162809
1. Master Thread Checkpoint；异步的定期落盘会以每秒或者每10秒一次的频率

2. FLUSH_LRU_LIST Checkpoint：通过lru算法淘汰内存的数据页，如果数据页是脏页就需要落盘。

3. Async/Sync Flush Checkpoint： 发生在重做日志不可用的时候，将buffer pool中的一部分脏页刷新到磁盘中，在脏页写入磁盘之后，事务对应的重做日志也就可以释放了

   1. ```
      ##即checkpoint_age等于最新的lsn减去已经刷新到磁盘的lsn的值 
      checkpoint_age = redo_lsn-checkpoint_lsn 
      async_water_mark = 75%*innodb_log_file_size 
      sync_water_mark = 90%*innodb_log_file_size
      ```

   2. 在redolog满了的情况。需要把redolog对于的脏页落盘，redolog就可以覆盖了。

      1. 如果没有落盘的内容小于redolog的75%不执行落盘操作
      2. 如果大于75%小于90%执行异步落盘
      3. 如果大于90%会执行同步落盘。
在mysql 5.6之后，不管是Async Flush checkpoint还是Sync Flush 都不会阻塞用户的查询进程。当这个事件中的任何一个发生的时候，都会记录到errlog 中，一旦errlog出现这种日志提示，一定需要加大logfile的组数。



4. **Dirty Page too much**：内存中的脏页太多了会执行落盘操作。新版本中脏页达到75%会执行落盘操作，旧版本中90%会落盘
# 分库分表
## 什么是分库分表？
将大量数据分散到多个数据库中，是每个数据库中数据量小响应速度快，以此提高数据库整体性能，核心就是对数据进行切分，以及切分后如何对数据的快速定位和整合。针对数据切分类型可以分为：垂直（纵向）切分和水平（横向）切分。
### 什么是垂直切分
- 垂直分库：将各个业务模块分成不同的库，比如订单库，支付库，商品库等。
- 垂直分表：基于数据表切分，将长度较大且访问不频繁的字段，拆分为单独的扩展表进行存储
### 什么是水平切分

- 库内分表：子表还是在同一个数据库实例中，只是解决了单一表数据量过大的问题，并没有将表分布到不同的机器上
- 分库分表：将切分出来的子表分散到不同的数据库中，从而使单个表的数据量变小达到分布式的效果。
## 分库分表工具

- sharding-jdbc当当
- TSharding蘑菇街
- Atlas奇虎360
- Cobar阿里巴巴
- MyCat基于Cobar
- Oceanus 58
- Vitess 谷歌

## 分库分表后出现问题，该往哪里取和存？

# 什么是索引
> https://blog.csdn.net/u012954706/article/details/81241049?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase
> https://blog.csdn.net/b_x_p/article/details/86434387
> https://www.cnblogs.com/xiaosongJiang/p/13538795.html
索引是表的目录，是数据库中专门用于帮助用户快速查询数据的一种数据结构。类似于字典中的目录，查找字典内容时可以根据目录查找到数据的存放位置，以此快速定位查询数据。对于索引，会保存在额外的文件中。索引是存储在磁盘上的。一般是B+树的数据结构。
## 索引的优缺点
索引可以提高查询速度，但是会减慢写入速度，缺点是创建和维护索引也需要消耗时间和资源
## 索引采用什么数据结构
>https://www.cnblogs.com/xiaosongJiang/p/13538795.html
Hash索引和B+ Tree索引，我们使用的是InnoDB引擎，默认的是B+树
## 各种树介绍
>https://blog.csdn.net/Haskei/article/details/106849383

| 树 | 特点 |  |缺点  |
| --- | --- | --- | --- |
| 二叉树 | 节点只能有左右两个孩子 |  |  |
|满二叉树  | 只有度为0和2的节点，所有叶子在同一层 |  |  |
| 完全二叉树 | 每个节点编号和满二叉树一致，仅有0｜1个度为1的节点 |  |  |
| 哈夫曼树 | 哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近 |  |  |
| 二叉搜索（查找）树（BST） | 节点值大于小于左子节点，大于右子节点，中序遍历是一个有序数组 |  | 如果根节点选择的不合适，会退化成链表。 |
| 平衡二叉树（AVL） | 自平衡二叉搜索树，在AVL中任何节点的两个儿子子树的高度最大差别为1 |  | 1.数据量大的时候树高度会变高，增加磁盘的IO；2.需要不停维持树的平衡。 |
| 红黑树 | 解决AVL频繁调整出现，① 每个节点或者是黑色，或者是红色。 ② 根节点是黑色。 ③ 每个叶子节点(NIL)是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点] ④ 如果一个节点是红色的，则它的子节点必须是黑色的。 ⑤ 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。[这里指到叶子节点的路径]  |  |  |
| B树 | B树（Balance Tree）也称B-树,它是一颗多路平衡查找树。我们描述一颗B树时需要指定它的阶数，阶数表示了一个结点最多有多少个孩子结点，一般用字母m表示阶数。当m取2时，就是我们常见的二叉搜索树 | 1）每个结点最多有m-1个关键字。 2）根结点最少可以只有1个关键字。 3）非根结点至少有Math.ceil(m/2)-1个关键字。 4）每个结点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。 5）所有叶子结点都位于同一层，或者说根结点到每个叶子结点的长度都相同。 |  1.范围查询效率低，如果每个节点都保存记录行，导致索引变大，每页保存的索引节点就变少，数据量大的时候高度变高，增加磁盘IO。|
| B+树 |B树升级，只有叶子节点才会存储数据，非叶子节点只存储键值。叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表。   |  |  |
|  |  |  |  |

## b+树特点？ 
① B+树的层级更少： 
相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快。 
② B+树查询速度更稳定： 
B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定。 
③ B+树天然具备排序功能： 
B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。 
④ B+树全节点遍历更快： 
B+树遍历整棵树只需要遍历所有的叶子节点即可，而不需要像B树对每一层进行遍历，这有利于数据库做全表扫描。 
⑤ B树相对于B+树的优点是， 
如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。
## 为什么使用B+树做为索引的数据机构？（不用其他的树形结构）
B-tree：因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低；

Hash：虽然可以快速定位，但是没有顺序，IO复杂度高。

二叉树：树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。

红黑树：树的高度随着数据量增加而增加，IO代价高。
## Hash索引和B+树有什么区别或者说优劣呢?
① hash索引进行等值查询更快(一般情况下)，但是却无法进行范围查询。 
因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。 
② hash索引不支持使用索引进行排序，原理同上。 
hash索引不支持模糊查询以及多列索引的最左前缀匹配。原理也是因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。 
③ hash索引任何时候都避免不了回表查询数据，而B+树在符合某些条件(聚簇索引，覆盖索引等)的时候可以只通过索引完成查询。 
④ hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。 

Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。**所以，哈希索引只适用于等值查询的场景。**而B+ 树是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描。哈希索引适合等值查询，但是无法进行范围查询 
哈希索引没办法利用索引完成排序 
哈希索引不支持多列联合索引的最左匹配规则 
如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题
## MyISAM和Innodb对于B+树的不同实现？
MyISAM中需要先找到B+树的叶子节点，叶子阶段存储了真实数据的物理地址，然后再通过物理地址去定位真正的存储数据。如果是多个索引，则索引之间互不干扰，主键索引和辅助索引是同级别的，没有主次之分。
![235b649aef4db7b3bf969d9b91e62af2.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p51)
Innodb中叶子节点保存的数据就是真是的数据，通过索引命中叶子节点的时候，直接可以从叶子节点去除数据。如果是多索引，那么主键索引叶子节点保存的是真实的数据，而辅助索引叶子节点保存的是主键索引关键字的值。
![872c393bd9ee365dbc73f9caf6b0823f.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p52)
![2a3cdfeeff7dab3865d95c8b120b4860.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p53)
之所以这样设计，一个原因就是：如果和MyISAM一样在主键索引和辅助索引的叶子节点中都存放数据行指针，一旦数据发生迁移，则需要去重新组织维护所有的索引。

## 什么是覆盖索引？
如果查询的列，通过索引项的信息可直接返回，则该索引称之为查询SQL的覆盖索引。覆盖索引可以提高查询的效率。Mysql 可以使用索引来直接获取列的数据，这样就不需要查到索引后，然后通过叶子节点的指针回表读取数据行，如果索引的叶子节点中已经包含了或者说覆盖 所有需要查询的字段的值，那么就没有必要再回表查询了，这种称之为“覆盖索引”
```sql
//如主键id，辅助索引name，
//此时需要先检索name对应的id，然后通过主键索引返回真实的数据
select * from user where name = ?
//因为只需要id的值，通过name查询的时候，扫描完name索引，我们就能够获得id的值了，所以就不需要再去扫面id索引，就会直接返回。
select id from user where name = ?
```
## 什么是聚簇索引？
数据库表行中数据的物理顺序和键值的逻辑顺序相同。Innodb以主键索引来聚集组织数据的存储。当表中有聚簇索引时，它的数据实际上存储在索引的叶子页中（叶子页中包含了行的全部数据）。而没有聚簇索引时B+Tree叶子页存放的是指向数据的指针。（页是mysql存储引擎最小的存储单元，InnoDB每个页默认大小为16k）可以理解为 有聚簇索引时，数据和对应的叶子页在同一页中，没有聚簇索引时，叶子页和对应的数据不在同一页中。
### 聚簇索引和非聚簇索引的区别？
- 聚簇索引，索引的顺序就是数据存放的顺序（物理顺序），只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。一张数据表只能有一个聚簇索引。（一个数据页中数据物理存储是有序的）
- 非聚簇索引通过叶子节点指针找到数据页中的数据，所以非聚簇索引是逻辑顺序。
### 如果没有定义主键会产生聚簇索引么？没有定义任何索引的时候呢？
InnoDB存储引擎通过主键聚集数据(聚簇索引)，如果没有定义主键，InnoDB会选择一个唯一的非空索引代替。如果没有唯一索引，InnoDB会隐式定义一个主键来作为聚簇索引。
### 聚簇索引的优点？
1.数据存放的顺序和索引顺序一致,可以把相关数据保存在一起。查询相同数据时减少磁盘 I/O。
2.数据访问更快，聚簇索引将索引和数据保存在同一个B-Tree中，因此从举措索引中获取数据通常比非聚簇索引查找更快。
3.使用覆盖索引扫描的查询可以直接使用页节点中的主键值（二级索引(非聚簇索引) 的叶子节点保存的不是指向行的物理位置的指针，而是行的主键值）。

### 聚簇索引的缺点
1. 聚簇数据提高了IO性能，如果数据全部放在内存中，则访问的顺序就没那么重要了
2. 插入速度严重依赖插入顺序。按主键的顺序插入是速度最快的。但如果不是按照主键顺序加载数据，则需在加载完成后最好使用optimize table重新组织一下表
3. 更新聚簇索引列的代价很高。因为会强制innod将每个被更新的行移动到新的位置
4. 基于聚簇索引的表在插入新行，或主键被更新导致需要移动行的时候，可能面临页分裂的问题。页分裂会导致表占用更多的磁盘空间。
5. 聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或由于页分裂导致数据存储不连续的时
6. 非聚集索引比想象的更大，因为二级索引的叶子节点包含了引用行的主键列
7. 非聚集索引访问需要两次索引查找(非聚集索引中叶子节点保存的行指针指向的是行的主键值)，对于innodb自适应哈希索引可以减少这样的重复工作
## 什么是回表？
查询辅助索引后找到记录的主键（id）再跟进主键查询聚集索引找到这条数据。这个过程就叫做回表。

## 索引分类？
- 普通索引 

  - 仅加速查询 最基本的索引，没有任何限制，是我们大多数情况下使用到的索引。
  - ALTER TABLE table_name ADD INDEX index_name (column_name) ;

- 唯一索引

  - 与普通索引类型，不同的是：加速查询 + 列值唯一（可以有null）
  - CREATE UNIQUE INDEX index_name ON table(column_name) ;

- 全文索引

  - 全文索引（fulltext）仅可以适用于MyISAM引擎的数据表；作用于CHAR、VARCHAR、TEXT数据类型的列。基于倒排索引实现

- 前缀索引：在文本类型如CHAR,VARCHAR,TEXT类列上创建索引时，可以指定索引列的长度，但是数值类型不

  能指定

  - ALTER TABLE table_name ADD INDEX index_name (column1(length));

- 组合索引（联合索引）

  - 将几个列作为一条索引进行检索，使用最左匹配原则。
  - ALTER TABLE table_name ADD INDEX index_name (column1,column2); 
  
## 什么是最左匹配原则？
> https://www.cnblogs.com/ljl150/p/12934071.html

在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。
例如建立一个联合索引(a,b,c)，那么就相当于建立了(a,b,c),(a,b),(a,c)索引,那么查询条件(a,b)(a,b,c)(a,c)都会经过联合索引，但是查询条件(b,c)不会经过。联合索引最多16列
## **MySQL 5.6中，对索引做了哪些优化吗？(索引下推ICP)**
>https://blog.csdn.net/qq_34162294/article/details/105260154

MySQL 5.6引入了索引下推优化，默认开启，使用`SET optimizer_switch = 'index_condition_pushdown=off';`可以将其关闭。
索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。 

在不使用ICP的情况下，在使用非主键索引（又叫普通索引或者二级索引）进行查询时，存储引擎通过索引检索到数据，然后返回给MySQL服务器，服务器然后判断数据是否符合条件 。

在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。
## 索引失效
1. 最左匹配时，没有加组合索引的第一个
2. 在索引上做计算、函数、自动/手动类型转换
3. **范围条件右边的列失效**，不能继续使用索引中范围条件（bettween、<、>、in等）右边的列 
4. **索引字段上使用不等**
5. **索引字段上判断**null
6. **索引字段使用**like不以通配符开头，%字符串
7. 索引字段使用or

## 索引创建意见
1. 表记录很少不需创建索引 （索引是要有存储的开销）. 

2. 一个表的索引个数不能过多。

（1）空间：浪费空间。每个索引都是一个索引树，占据大量的磁盘空间。

（2）时间：

更新（插入/Delete/Update）变慢。需要更新所有的索引树。

太多的索引也会增加优化器的选择时间。

所以索引虽然能够提高查询效率，索引并不是越多越好，应该只为需要的列创建索引。

3. 频繁更新的字段不建议作为索引。

频繁更新的字段引发频繁的页分裂和页合并，性能消耗比较高。

4. 区分度低的字段，不要建索引。

比如性别，男，女；比如状态。区分度太低时，会导致扫描行数过多，再加上回表查询的消

耗。如果使用索引，比全表扫描的性能还要差。这些字段一般会用在组合索引中。

姓名，手机号就非常适合建索引。

5. 在InnoDB存储引擎中，主键索引建议使用自增的长整型，避免使用很长的字段。

主键索引树一个页节点是16K，主键字段越长，一个页可存储的数据量就会越少，比较臃肿，查

询时尤其是区间查询时磁盘IO次数会增多。辅助索引树上叶子节点存储的数据是主键值，主键值

越长，一个页可存储的数据量就会越少，查询时磁盘IO次数会增多，查询效率会降低。

6. 不建议用无序的值作为索引。例如身份证、UUID

更新数据时会发生频繁的页分裂，页内数据不紧凑，浪费磁盘空间。

7. 尽量创建组合索引，而不是单列索引。

优点：

（1）1个组合索引等同于多个索引效果，节省空间。

（2）可以使用覆盖索引

创建原则：组合索引应该把把频繁的列，区分度高的值放在前面。频繁使用代表索引的利用率高，

区分度高代表筛选粒度大，可以尽量缩小筛选范围。

8. 字符串太长时，如何创建索引？

在保证区分度的情况下，被索引的字段不要太长，可以使用前缀索引。怎么选择长度。
## 百万级别或以上的数据如何删除 
1) 所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟） 
2) 然后删除其中无用数据（此过程需要不到两分钟） 
3) 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。 
4) 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。

# 什么是事务
事务常说一系列操作作为一个整体要么都成功要么都失败，主要特性acid，事务的的实现主要依赖两个log redo-log,undo-log,每次事务都会记录数据修改前的数据undo-log，修改后的数据放入redo-log,提出成功则使用redo-log 更新到磁盘，失败则使用undo-log将数据恢复到事务之前的数据
## 事务的基本特性
1. 原子性**Atomicity**

   一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样

2. 一致性**Consistency**

   执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的

3. 隔离性**Isolation**

   数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致

4. 持久性**Durability**

   一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。
   
 ## 事务时如何实现的？
 1. MVCC，MVCC依赖版本链和ReadView
2. 锁机制，锁机制依赖行锁和表锁

## 并发事务会带来哪些问题？
- 脏读（Dirty read）
  - 指在一个事务处理过程里读取了另一个未提交的事务中的数据。 
- 丢失修改（Lost to modify）
  - A事务和B事务同时修改同一行数据，出现A事务修改内容丢失，修改内容变成B事务修改内容； 
- 不可重复读（Unrepeatableread）
  - 指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。 
- 幻读（Phantom read）
  - 幻读和不可重复读类似，事务1多次读取同一个数据时，事务2并发的插入了几条数据，此时事务1在重复读的过程中发现多了一些原本不存在的记录，像幻觉一样
  
### 不可重复读和幻读的区别？
不可重复度的重点是读取的数据某些列值被修改，幻读的重点是读取的数据多了或者少了

## mysql事务隔离级别?
`show VARIABLES like 'tx_isolation'`

>https://www.jianshu.com/p/4e3edbedb9a8

- 读未提交READ UNCOMMITTED
  - 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读
- 读提交READ COMMITTED
  - 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生
- 可重复读REPEATABLE READ（mysql**默认隔离级别**，mysql间隙锁可以防止插入情况下的幻读）
  - 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
- 串行化SERIALIZABLE
  - 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执InnoDB 存储引擎在 **REPEATABLE-READ（可重读）** 事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 **SERIALIZABLE(可串行化)** 隔离级别。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 **READ-COMMITTED(读取提交内容)** 行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读
  ![05ec5f19e559abe1518e8d7cc980bb7e.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p59)
### 事务的实现
 事务的原子性是通过 undo log 来实现的

事务的持久性性是通过 redo log 来实现的

事务的隔离性是通过 (读写锁+MVCC)来实现的

而事务的终极大 boss 一致性是通过原子性，持久性，隔离性来实现的！！！


### 为什么InnoDB默认是可重复读呢？
  InnoDB 存储引擎在 **REPEATABLE-READ（可重读）** 事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 **SERIALIZABLE(可串行化)** 隔离级别。因为隔离级别越低，事务请求的锁越少。
## 数据库隔离级别，哪个更好，性能比较？
- 读未提交：会造成太多的脏数据
- 读已提交：是大部分数据库的隔离级别比如oracle、sqlserver
- 可重复读：由于innodb实现原因，采用next-key lock算法，使得已经避免了幻读的产生，保证了事务隔离性要求
- 串行化：处理能力过低

## 丢失修改的解决方案？
- LBCC（ Lock-Based Concurrency Control 基于锁的并发控制）：就是一个事务去读取一条数据的时候，就上锁，不允许其他事务来操作。串行化就是利用LBCC实现的。
- MVCC（多版本的并发控制）：**MVCC**使得数据库读不会对数据加锁，普通的**SELECT**请求不会加锁，提高了数据库的并发处理能力。借MVCC，数据库可以实现READ COMMITTED，REPEATABLE READ等隔离级别，用户可以查看当数据的前一个或者前几个历史版本，保证了ACID中的I特性（隔离性)。 

## 什么是MVCC
> https://www.cnblogs.com/hirampeng/p/9944200.html

基于多版本的并发控制协议，只有在InnoDB引擎下存在。MVCC是为了实现事务的隔离性，通过版本号，避免同一数据在不同事务间的竞争，你可以把它当成基于多版本号的一种乐观锁。当然，这种乐观锁只在事务级别可重复读和读提交时才会生效。MVCC最大的好处，相信也是耳熟能详：读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能。

### MVCC的实现机制
- 隐藏列：事务ID，回滚指针，行ID（只有没有建立主键的时候存在）
- undo log：事务对数据更新操作，会把旧数据行记录在undo log的记录中，在undo log记录数据行、生成这行数据的事务id。 在undo log中和之前的数据行形成一条链表，链表头就是最新的数据，这条链表就叫做版本链. 
- read view：当前活跃事务列表、最小版本号、最大版本号、当前创建事务的版本号。核心问题就是需要判断一下版本链中的哪个版本是当前事务可见的。所以设计 InnoDB 的设计者提出了一个**ReadView**的概念，这个 ReadView 中主要包含当前系统中还有哪些活跃的读写事务，把它们的事务id放到一个列表中，我们把这个列表命名为为**m_ids**。https://www.cnblogs.com/jmliao/p/13204946.html


nnoDB在每行数据都增加3个隐藏字段，事务Id（DB_TRX_ID）、回滚段或回滚指针（DB_ROLL_PTR）、行ID（如果有主键的时候就不会生产，没有主键才会添加）。在多版本并发控制中实现依赖的是 undo log 与 read view，为了保证并发过程的事务隔离机制，降低锁竞争的压力，保证较高的并发量。在每开启一个事务时，会生成一个事务的版本号，被操作的数据会生成一条新的数据行（临时），但是在提交前对其他事务是不可见的，对于数据的更新（包括增删改）操作成功，会将这个版本号更新到数据的行中，事务提交成功，将新的版本号更新到此数据行中，这样保证了每个事务操作的数据，都是互不影响的，也不存在锁的问题。
### 那又是如何实现读已提交和可重复读呢？
其实很简单，就是生成ReadView的时机不同。 
- 读提交：每次读操作都会生成一个 ReadView
- 可重复读：第一次读操作生成ReadView

### 快照读和当前读
- 快照读：简单的select操作是快照读，不加锁，读取历史版本。（当然有例外）
- 当前读：特殊读操作，增删改，属于当前读，需要加锁读取最新的数据

在进行 SELECT 操作时，可以强制指定进行加锁操作。以下第一个语句需要加 S 锁，第二个需要加 X 锁。
```
select * from table where ? lock in share mode;
select * from table where ? for update;
```
### **一致性非锁定读**
一致性非锁定读(consistent nonlocking read)是指InnoDB存储引擎通过多版本控制(MVCC)读取当前数据库中行数据的方式。如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB会去读取行的一个最新可见快照。

### 版本链产生过程
![0ae51f6dc5ad77c4d1be630bc5af87d5.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p63)
## 事务回滚和数据恢复
事务回滚和数据恢复事务的隔离性由多版本控制机制和锁实现，而原子性，持久性和一致性主要是通过redo log、undo log、和Force Log at Commit机制机制来完成的。redo log用于在崩溃时恢复数据，undo log用于对事务的影响进行撤销，也可以用于多版本控制。而Force Log at Commit机制保证事务提交后redo log日志都已经持久化。事务进行过程中，每次DML sql语句执行，都会记录undo log和redo log，然后更新数据形成脏页，然后redo log按照时间或者空间等条件进行落盘，undo log和脏页按照checkpoint进行落盘，落盘后相应的redo log就可以删除了。此时，事务还未COMMIT，如果发生崩溃，则首先检查checkpoint记录，使用相应的redo log进行数据和undo log的恢复，然后查看undo log的状态发现事务尚未提交，然后就使用undo log进行事务回滚。事务执行COMMIT操作时，会将本事务相关的所有redo log都进行落盘，只有所有redo log落盘成功，才算COMMIT成功。然后内存中的数据脏页继续按照checkpoint进行落盘。如果此时发生了崩溃，则只使用redo log恢复数据。![0c803a37609a6c60a3aa73f4d02357af.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p67)


# 锁
## MyISAM和INNODB存储引擎使用的锁是什么？
- MyISAM采用表级锁(table-level locking)。
- InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁
## 什么是行锁
MySQL中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。
### 行锁的类别具体有哪些？
- 记录锁Record Lock: 对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项
- 间隙锁Gap Lock: 对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行只在RR情况下生效 
- 临间锁Next-key Lock： 锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合。可解决幻读问题![d730baeb123344f066d6f3a6b12568ac.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p69)
- 插入意向锁Insert Intention Locks：insert操作时添加的对记录id的锁。是一种Gap锁，不是意向锁
![1cb19b3941b23ac9eeba568b042d56f9.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p71)
在 InnoDB 存储引擎中，SELECT 操作的不可重复读问题通过 MVCC 得到了解决，而 UPDATE、DELETE 的不可重复读问题通过 Record Lock 解决，INSERT的不可重复读问题是通过 Next-Key Lock（Record Lock + Gap Lock）解决的。
### 行锁的原理是什么？
**InnoDB的行级锁是基于索引实现的，如果查询语句为没有命中任何索引，那么InnoDB会使用表级锁.** 此外，InnoDB的行级锁是针对索引加的锁，不针对数据记录，因此即使访问不同行的记录，如果使用了相同的索引键仍然会出现锁冲突
### 如果没有定义任何索引，那么此时会发生什么？
如果表没有定义任何索引，那么InnoDB会创建一个隐藏的聚簇索引并使用这个索引来加记录锁
### 行锁怎么使用？
```sql
SELECT ...LOCK IN SHARE MODE;#S
SELECT ...FOR UPDATE;#X
```
### 常用的增删改会加锁么？

**对于UPDATE**、**DELETE**和**INSERT**语句，**InnoDB**会自动给涉及数据集加排他锁（**X)**；对于普通SELECT语句，**InnoDB**不会加任何锁
### 行锁加锁规则
|          | 等值查询                                                     | 范围查询                                                     |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 主键索引 | 命中记录：加记录锁<br />加未命中：加间隙锁                   | 命中1｜多记录：临建锁<br />未命中：间隙锁                    |
| 辅助索引 | 命中记录：命中记录的辅助索引项+主键索引项加记录锁，辅助索引两侧加间隙锁<br />未命中：加间隙锁 | 命中1｜多记录：加临建锁，命中记录的id索引项加记录锁<br />未命中：间隙锁 |
### Innodb所使用的**行级锁定**争用状态查看？
\- Innodb_row_lock_current_waits：当前正在等待锁定的数量； 

\- Innodb_row_lock_time：从系统启动到现在锁定总时间长度； 

\- Innodb_row_lock_time_avg：每次等待所花平均时间； 

\- Innodb_row_lock_time_max：从系统启动到现在等待最常的一次所花的时间； 

\- Innodb_row_lock_waits：系统启动后到现在总共等待的次数；
## 表级锁 
表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。 

## 什么是意向锁？

> https://juejin.cn/post/6844903666332368909

意向锁是表锁的一种，它是为了解决行级锁和表级锁的冲突的一种标示，事务在对某些行加锁的时候，此时另一事物需要对表进行加锁，这两个锁是互斥的所以如果么有意向锁，那么需要对表中的所有行尽心校验是否内部已经有加锁了，但是意向锁让表锁无需扫描全表。事务在获取行锁的时候便会在表上加意向锁，代表当前表上已经有行级锁了。



## 死锁问题产生

两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/86568C0D6B1D425F951CD226185115AA/17119)

### 死锁问题解决

1）如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。 
2）在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率； 
3）对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率； 
如果业务处理不好可以用分布式事务锁或者使用乐观锁



## 一个简单sql的加锁分析

`select * from t1 where id = 10;`

`delete from t1 where id = 10;`

问题：这个sql是否加锁？如果加锁加了什么锁呢？

其实分析的时候应该考虑

- **前提一：**id列是不是主键？
- **前提二：**当前系统的隔离级别是什么？
- **前提三：**id列如果不是主键，那么id列上有索引吗？
- **前提四：**id列上如果有二级索引，那么这个索引是唯一索引吗？
- **前提五：**两个SQL的执行计划是什么？索引扫描？全表扫描？

RC，RR隔离级别下SQL1：select操作均不加锁，采用的是快照读，因此在下面的讨论中就忽略了，主要讨论SQL2：delete操作的加锁

- 组合一：id列是主键，RC隔离级别 

  - id是主键时，此SQL只需要在id=10这条记录上加X锁即可。 在id=10行上加X锁

- 组合二：id列是二级唯一索引，RC隔离级别

  - 若id列是unique列，其上有unique索引。那么SQL需要加两个X锁，一个对应于id unique索引上的id = 

    10的记录，另一把锁对应于聚簇索引上的【name=’d’,id=10】的记录

- 组合三：id列是二级非唯一索引，RC隔离级别 

  - 同组合二，但是会将所有查到的行加锁

- 组合四：id列上没有索引，RC隔离级别 

  - 若id列上没有索引，SQL会走聚簇索引的全扫描进行过滤，由于过滤是由MySQL Server层面进行的。因此每 条记录，无论是否满足条件，都会被加上X锁。但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后放锁，最终持有的，是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不 会省略。同时，优化也违背了2PL的约束。 

- 组合五：id列是主键，RR隔离级别 

  - id是主键时，此SQL只需要在id=10这条记录上加X锁即可。 在id=10行上加X锁

- 组合六：id列是二级唯一索引，RR隔离级别 

  - 若id列是unique列，其上有unique索引。那么SQL需要加两个X锁，一个对应于id unique索引上的id = 

    10的记录，另一把锁对应于聚簇索引上的【name=’d’,id=10】的记录

- 组合七：id列是二级非唯一索引，RR隔离级别 

  - Repeatable Read隔离级别下，id列上有一个非唯一索引，对应SQL：delete from t1 where id = 10; 首先，通过id索引定位到第一条满足查询条件的记录，加记录上的X锁，加GAP上的GAP锁，然后加主键聚簇索引上的记录X锁，然后返回；然后读取下一条，重复进行。直至进行到第一条不满足条件的记录[11,f]，此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。
  - ![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/69C8E48C00F94C2EBB4E1C28DF25738C/17123)

- 组合八：id列上没有索引，RR隔离级别 

  - 在Repeatable Read隔离级别下，如果进行全表扫描的当前读，那么会锁上表中的所有记录，同时会锁上聚 

    簇索引内的所有GAP，杜绝所有的并发 更新/删除/插入 操作。当然，也可以通过触发semi-consistent 

    read，来缓解加锁开销与并发影响，但是semi-consistent read本身也会带来其他问题，不建议使用。

  - ![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/4C714FC4BAE04355867295BF1C53832A/17126)

- 组合九：Serializable隔离级别:在Serializable隔离级别，SQL1会加读锁，也就是说快照读不复存在，MVCC并发控制降级为Lock-Based CC

# 什么是sql注入？

> https://www.cnblogs.com/jiaoxiaohui/p/10760763.html

sql注入是攻击者通过sql注入漏洞绕过应用程序安全措施，检索整个sql数据库内容，甚至进行插入删除修改操作。简而言之，就是攻击者用拼接sql语句可以直接对sql进行增删改查。

## Statement与PreparedStatement的区别

1、PreparedStatement支持动态设置参数，Statement不支持。

2、PreparedStatement可避免如类似单引号的编码麻烦。

3、PreparedStatement支持预编译，Statement不支持。

4、在sql语句出错时PreparedStatement不易检查，而Statement则更便于查错。

## 如何防止sql注入？

1.尽量少使用或者不使用动态sql，这样可以减少用户提供的sql直接放入语句。即使用PreparedStatement原理是，内置sql处理能力，使用setXX设置传入参数，会将传入参数当作字符串处理

2.对数据库一些敏感内容进行加密存储，比如密码，电话等。

3.限制数据库权限。

4.不要直接向用户显示数据库错误，因为攻击者可以通过错误信息获取一定的有用信息。

5.对访问数据库的Web应用程序使用Web应用程序防火墙（WAF），这个比较直接，防火墙通过设置，进行判断，如果是sql注入，直接给你拦外边了，不会继续提交请求。

6.更新数据库，减少漏洞

# 日志

> https://blog.csdn.net/ab1024249403/article/details/110099571

## mysql日志类型有哪些？

MySQL通过日志记录了数据库操作信息和错误信息。常用的日志文件包括**错误日志error log、二进制日志bin log、查询**

**日志、慢查询日志和事务**Redo **日志、中继日志**等。

`mysql> show variables like 'log_%'; `

- redo log：物理日志，又叫做重做（写）日志，存储了数据被修改的值，inndb存储引擎管理，用于记录事物操作的变化，记录的是数据修改之后的值，不管事物是否提交都会记录下来。

  - 循环写入，默认有mysql两个ib_logfile0和ib_logfile1，在日志组中每个重做日志文件的大小一致，擎先写入重做日志文件1，当文件被写满时，会切换到重做日志文件2，再当重做日志文件2也被写满时，再切换到重做日志文件1。
  - 两种状态：prepare（预提交）、commit（提交）
  - `innodb_log_file_size`：文件大小
    - 如果重做日志文件设置的太大，数据丢失时，恢复时可能需要很长的时间；另一方面，如果设置的太小，重做日志文件太小会导致依据checkpoint的检查需要频繁刷新脏页

- binlog：逻辑日志，也叫二进制日志，mysql server层维护，存储了逻辑SQL修改语句，默认关闭，记录了数据库所有的DDL和DML（除了select语句）内容，DDL直接记录，**DML必须通过事务提交才能记录到binlog中**

  -  `log-bin=mysql-bin`开启
  -  主要用于mysql主从复制，数据备份，数据恢复。

- Error Log：错误日志，记录mysqld的一些错误，默认开启，5.5.7后无法关闭错误日志

  - ```log_error=/var/log/mysqld.log 
    #可以直接定义为文件路径，也可以为ON|OFF 
    log_error=/var/log/mysqld.log 
    #只能使用1|0来定义开关启动，默认是启动的 
    log_warings=1
    ```

- General Query Log，通用查询日志，默认是关闭的，它会记录用户所有操作，包括增删改查，客户端的连接和断开，可以准确知道客户端传递给服务端的数据，在并发操作的环境会产生大量的信息而导致不必要的磁盘io，影响mysql的性能

  - ```\#启动开关 
    #启动开关 
    general_log={ON|OFF} 
    #日志文件变量，而general_log_file如果没有指定，默认名是host_name.log general_log_file=/PATH/TO/file 
    #记录类型 
    log_output={TABLE|FILE|NONE}
    ```

- Slow Query Log：慢查询日志，默认关闭，记录一些超过设定阈值的sql

  - 查询多少SQL超过了慢查询时间的阀值: `SHOW GLOBAL STATUS LIKE '%Slow_queries%';`

  - ```
    #开启慢查询日志 
    slow_query_log=ON 
    #慢查询的阈值 
    long_query_time=10 
    #日志记录文件如果没有给出file_name值， 默认为主机名，后缀为-slow.log。如果给出了文件名，但不 是绝对路径名，文件则写入数据目录。 
    slow_query_log_file= file_name
    ```


## 什么是binLog

binlog 是 MySQL 层的逻辑日志，也叫二进制日志、归档日志，由 MySQL Server 来记录。用于记录用户对数据库操作的SQL语句（DDL和DDM除了查询语句）信息，以二进制的形式保存在磁盘中。默认关闭

### 如何开启binlog？

通过配置/etc/my.cnf配置文件的log-bin选项：

```
[mysqld]
#启用二进制日志 文件mysql-bin.001
log-bin=mysql-bin
#服务器唯一ID，一般取ip最后一段，主从复制使用
server-id=123
```

这个需要重启MySQL服务。
可以使用SET SQL_LOG_BIN=0命令停止使用日志文件，然后可以通过SET SQL_LOG_BIN=1命令来启用。

### 常用的binlog命令？

```mysql
# 是否启用binlog日志
show variables like 'log_bin';
# 查看详细的日志配置信息
show global variables like '%log%';
# mysql数据存储目录
show variables like '%dir%';
# 查看binlog的目录
show global variables like "%log_bin%";
# 查看当前服务器使用的biglog文件及大小
show binary logs;
# 查看主服务器使用的biglog文件及大小
# 查看最新一个binlog日志文件名称和Position
show master status;
# 事件查询命令
# IN 'log_name' ：指定要查询的binlog文件名(不指定就是第一个binlog文件)
# FROM pos ：指定从哪个pos起始点开始查起(不指定就是从整个文件首个pos点开始算)
# LIMIT [offset,] ：偏移量(不指定就是0)
# row_count ：查询总条数(不指定就是所有行)
show binlog events [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count];
# 查看 binlog 内容
show binlog events;
# 查看具体一个binlog文件的内容 （in 后面为binlog的文件名）
show binlog events in 'master.000003';
# 设置binlog文件保存事件，过期删除，单位天
set global expire_log_days=3; 
# 删除当前的binlog文件
reset master; 
# 删除slave的中继日志
reset slave;
# 删除指定日期前的日志索引中binlog日志文件
purge master logs before '2019-03-09 14:00:00';
# 删除指定日志文件
purge master logs to 'master.000003';

```



### binlog作用？

备份环境和主从环境必须依赖二进制日志

### binlog写入的时机？

必须要提交了事务才会记录binlog。binlog 什么时候刷新到磁盘跟参数 sync_binlog 相关。

- 如果设置为0，则表示MySQL不控制binlog的刷新，由文件系统去控制它缓存的刷新；
- 如果设置为不为0的值，则表示每 `sync_binlog` 次事务，MySQL调用文件系统的刷新操作刷新binlog到磁盘中。
- 设为1是最安全的，在系统故障时最多丢失一个事务的更新，但是会对性能有所影响。

如果 `sync_binlog=0` 或 `sync_binlog大于1`，当发生电源故障或操作系统崩溃时，可能有一部分已提交但其binlog未被同步到磁盘的事务会被丢失，恢复程序将无法恢复这部分事务。

### 为什么不直接写入到mysql中，而是写入到redo log中呢？（为什么mysql由cash-safe能力？）

因为数据在写入mysql时，需要找到磁盘mysql所对应的页，涉及磁盘的随机IO访问，涉及磁盘IO访问是非常消耗时间的过程，相比这个时间先预写redo log，后续再找到合适的时间刷盘，能大大提升效率。如果mysql异常重启了，那么系统会自行检查redo log，将未写入mysql中的数据从redo log中恢复到mysql中。

### binlog日志格式（工作模式）有哪几种？

> https://zhuanlan.zhihu.com/p/26977878

Note:
MySQL 5.7.7 之前，默认的格式是 statement-based，5.7.7及以后的版本，row-based 是默认的日志格式。

`show variables like 'binlog_format'`

|                                 | 说明                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| STATMENT基于sql语句复制（默认） | 每条被修改的数据sql都会被记录到binlog中，slave在复制的时候sql进程会解析成和原来master端执行过的相同的sql再次执行。主从同步中一般不建议使用，因为有些语句不支持，比如语句中包含UUID函数，已经LOAD DATA IN FILE等。不需要记录每行的数据变化，减少binlog日志量，节约磁盘io但是容易出现主从复制不一致 |
| ROW基于行的复制                 | 日志中会记录每一行数据被修改的情况，然后在slave端对相同的数据进行修改。能清除的记录每一行数据修改的细节，但是数据量太大，类似于快照 |
| MIXED混合模式复制               | 结合了row和statment的优点但是也更复杂                        |

### STATNEBT、ROW区别

|      | **STATMENT**                                                 | ROW                                                          |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 说明 | 基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。是bin log的默认格式。 | 基于行的复制(row-based replication, RBR)：不记录每一条SQL语句的上下文信息，仅保存哪条记录被修改。 |
| 优点 | 不需要记录每一条SQL语句与每行的数据变化，减少了bin log的日志量，节约了磁盘IO，提高性能。 | 会非常清楚的记录下每一行数据修改的细节，不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。 |
| 缺点 | 在某些情况下会导致master-slave中的数据不一致，如sleep()函数， last_insert_id()，以及user-defined functions(udf)等会出现问题。 | 会产生大量的日志，尤其是alter table的时候会让日志暴涨。      |

### 企业场景如何选择binlog的模式

1、 如果生产中使用MySQL的特殊功能相对少（存储过程、触发器、函数）。选择默认的语句模式，Statement Level。

2、 如果生产中使用MySQL的特殊功能较多的，可以选择Mixed模式。

3、 如果生产中使用MySQL的特殊功能较多，又希望数据最大化一致，此时最好Row level模式；但是要注意，该模式的binlog非常“沉重”。

### binlog由什么组成？

binlog是一个二进制文件集合，每个binlog文件以一个4字节的魔数开头，接着是一组Events:

- 魔数：0xfe62696e对应的是0xfebin；
- Event：每个Event包含header和data两个部分；header提供了Event的创建时间，哪个服务器等信息，data部分提供的是针对该Event的具体信息，如具体数据的修改；
- 第一个Event用于描述binlog文件的格式版本，这个格式就是event写入binlog文件的格式；
- 其余的Event按照第一个Event的格式版本写入；
- 最后一个Event用于说明下一个binlog文件；
- binlog的索引文件是一个文本文件，其中内容为当前的binlog文件列表

### binlog日志格式分析

- position: 位于文件中的位置，即第一行的（# at 21019）,说明该事件记录从文件第21019个字节开始
- timestamp: 事件发生的时间戳，即第二行的（#190308 10:10:09）
- server id: 服务器标识（1）
- end_log_pos 表示下一个事件开始的位置（即当前事件的结束位置+1）
- thread_id: 执行该事件的线程id （thread_id=113）
- exec_time: 事件执行的花费时间
- error_code: 错误码，0意味着没有发生错误
- type:事件类型Query

### 什么情况下mysql会重新生成binlog文件，文件需要递增？

- MySQL服务器停止或重启时
- 使用 `flush logs` 命令；
- 当 binlog 文件大小超过 `max_binlog_size` 变量的值时；

> binlog文件的最大值和默认值是1GB，该设置并不能严格控制binlog的大小，尤其是binlog比较靠近最大值而又遇到一个比较大事务时，为了保证事务的完整性，不可能做切换日志的动作，只能将该事务的所有SQL都记录到当前日志，直到事务结束。

### 主从复制原理

1. 主库记录binlog日志
2. 从库开启一个I/O线程与主库建立连接
3. 连接建立完成后，会在主库上启动一个特殊的堆转储（binlog dump）线程，用来读取主库上binlog文件，然后将读取到的binlog的event（事件）发送给从库的I/O线程，
4. 从库I/O线程接受binlog事件并将其写入relay log
5. SQL thread会读取relay log，并顺序执行日志中的SQL事件，从而与主库中的数据保持一致

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/8057A6F9B9ED41DF86C22AD12979D321/16355)

#### Binlog Dump线程的工作原理

- MySQL主从同步的实现中，从库连接到主库，并向主库发送一个COM_BINLOG_DUMP命令，主库会启动一个专门的线程为其服务，也就是Binglog Dump线程。该过程和一个用户访问MySQL的过程类似，主库中的Binglog Dump线程和用户线程都是由统一的连接管理机制管理，属于同一个线程池；不同的是Binglog Dump线程会一直存活。
- Binglog Dump线程按照从库请求的binlog名字和pos找到对应的binlog文件，然后读取binlog的envent不断的发往从库，当主库处于空闲状态时或者读取进度追赶上了主库，binlog dump线程会在一个信号量（update_cond即主库的binlog更新状态）上等待。
- 在主库端一旦有新的日志产生后，立刻会发送一次广播，Binglog Dump线程在收到广播后，则会读取二进制日志并通过网络向备库传输日志，所以这是一个主库向备库不断推送的过程。

## 什么是redo log ？

>https://blog.csdn.net/u010002184/article/details/88526708?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param

> https://www.jianshu.com/p/4bcfffb27ed5

> https://www.cnblogs.com/liuhao/p/3714012.html

redolog是InnoDB存储引擎层的日志，又称为重做日志文件，用于记录事物操作的变化，记录的是数据修改之后的值，不管事物是否提交都会记录下来。是物理日志，记录的是数据页的物理修改。在数据库突然掉电的时候，InnoDB存储引擎会使用redo log恢复到掉电前的时刻，一次保证数据的完整性。

### redo log作用？

**当数据库发生宕机重启后，可通过redo log将未落盘的数据恢复，即保证已经提交的事务记录不会丢失。**

### redolog写入有什么规则？

循环写的方式记录，当到结尾的时候，就会回到开头循环写。日志大小时固定的，记录满之后就从头开始循环写。在mysql中可以通过修改配置参数innodb_log_files_in_group和innodb_log_file_size配置日志文件数量和每个日志文件大小



![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/B987BF2F8DA449A29E845187716F95CF/16358)

- write pos：表示日志当前记录的位置
- check point：checkpoint之前表示擦除完了的，即可以进行写的，擦除之前会更新到磁盘中，write pos是指写的位置，当write pos和checkpoint相遇的时候表明redo log已经满了，这个时候数据库停止进行数据库更新语句的执行，转而进行redo log日志同步到磁盘中
- write pos->checkpoint：之间的部分是redo log空着的部分，用于记录新的记录
- checkpoint->write pos：之间是redo log待落盘的数据修改记录
- writepos=checkpoint：表明redo log已经满了，这个时候数据库停止进行数据库更新语句的执行，转而进行redo log日志同步到磁盘中。 s

### 为什么要记录redo log？

InnoDB有buffer poll（简称bp）。bp是数据库页面的缓存，对于InDB的任何修改操作都会在bp的page上进行，然后这样的页面将被标记为dirty page并放到专门的flush list上，后续由，master thread或专门的刷脏线程阶段性的将这些页面写入到disk（checkpoint机制）。这样的好处是避免每次写操作都操作磁盘导致大量IO，阶段性的刷脏可以将多次对页面的修改merge成一次IO，同时异步写入也降低了访问的时延。然而，如果在dirty page还未刷入磁盘时，server异常关闭，这些操作将会丢失，如果写入操作正在进行，甚至会损坏数据文件导致数据库不可以使用，为了避免以上问题的发生，InnDB将所有对页面修改操作放入一个专门的文件，并在数据库启动时从此文件新型恢复操作。这样的技术推迟bp页面的刷新，提高数据库吞吐，有效降低了访问时延。

#### 有没有一种情况就是写这个redolog日志，写到一半，数据库服务器挂了。此时redolog日志会变成怎样？

如果redolog没有写完，事务提交失败，只有redolog成功写入，事务才算提交成功。

### redolog落盘的方式由哪些？

| innodb_flush_log_at_trx_commit |                                                              |
| ------------------------------ | ------------------------------------------------------------ |
| 0                              | 每秒将日志缓冲区写入log file，并同时flush到磁盘。跟事务提交无关。在机器crash并重启后，会丢失一秒的事务日志数据（并不一定是1s，也许会有延迟，跟操作系统调度有关）,在这种情况下，MySQL性能最好 |
| 1                              | 默认1，每次事务提交将日志缓冲区写入log file(os cache)，并同时flush到磁盘。（crash不会丢失事务日志） |
| 2                              | 每次事务提交将日志缓冲区写入log file(os cache)，每秒flush一次到磁盘。（crash有可能丢失数据） |

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/649CB578C5BC4155BD3D3E31F0599F79/17090)

### 有了redo log为什么还要binlog？

1. redo log的大小是固定的，日志上的记录修改落盘后，日志会被覆盖掉，无法用于数据回滚/数据恢复等操作。
2. redo log是innodb引擎层实现的，并不是所有引擎都有。
3. 如果只从崩溃恢复的角度来讲是可以的。可以把binlog关掉，但系统依然是crash-safe的；
4. 但是binlog有着redo log无法替代的功能，binlog的主要作用是归档，redo log是循环写，写到末尾是要回到开头继续写的。
5. MySQL系统依赖于binlog，mysql系统高可用的基础就是依赖于binlog复制；

 ### binlog和redo log的区别？

- redo log是属于innoDB层面，binlog属于MySQL Server层面的，这样在数据库用别的存储引擎时可以达到一致性的要求。
- redo log是物理日志，记录该数据页更新的内容；binlog是逻辑日志，记录的是这个更新语句的原始逻辑
- redo log是循环写，日志空间大小固定；binlog是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。
- binlog可以作为恢复数据使用，主从复制搭建，redo log作为异常宕机或者介质故障后的数据恢复使用

### 两阶段提交中，MySQL异常重启（crash），是如何保证数据完整性的？
![cb1aa1250e24fa6ba5ddd6dd6ed4ec2b.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p74)

1. 在上图时刻A中，也就是写入redo log处于prepare阶段以后、写binlog之前，发生了崩溃（crash）：由于此时binlog还没写，redo log也还没提交（commit），所以崩溃恢复的时候，这个事务会回滚。这时候，binlog还没写，所以也不会传到备库，数据一致；
2. 在上图时刻B中，也就是写完binlog之后，发生crash：如果redo log里面的事务有commit标识（事务是完整的）则直接提交；如果redo log里面的事务只有prepare没有commit，则判断对应的事务在binlog是否存在并完整，完整则提交事务，否则回滚事务；
3. MySQL怎么知道binlog是完整的：一个事务的binlog是有完整格式的，statement格式（记录sql语句），最后会有个COMMIT; row格式（记录行的内容，记两条，更新前和更新后都有），最后会有个XID event
4. redo log和binlog是怎么关联起来的：他们有一个共同的数据字段XID。崩溃恢复的时候，会按顺序扫描redo log；上述第二点中的崩溃恢复场景（redo log里面的事务只有完整的prepare而没有commit），那么mysql就会拿着XID去binlog找是否存在对应的完整事务；
XC
## 什么是undo log？

主要存储的逻辑日志，又称重做日志，记录了事务的行为，可以很好地通过其对页进行重做操作。

### undo log的作用？

- 提供回滚
- 多个行版本控制（MVCC）

保存了事物发生之前的数据的一个版本，可以用来回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读

### undo log存放在哪里，什么时候会被释放？

在MYSQL 5.6 之后，可以为undo log 分配独立的表空间。默认表空间的数量为2个，可以设置innodb_undo_tablespaces 来增加数量。每个表空间又被分为多个回滚段（rollback segment），回滚段的数量可以查看innodb_undo_logs。每个回滚段就存放了undo log 页。如果undo log 对应的事务都已经是执行完毕，或者回滚结束的。那么对应的undo log 空间就可以被回收了。

注意：假设有一个长事务，迟迟未被提交，或回滚，那么undo log 会越来越大。严重的会直接导致服务器磁盘空间爆满。所以如果突然服务器磁盘空间使用量快速上升，也可以查看下是否有长事务没有提交，导致undo log占用很大磁盘空间。

### undo log根据行为分为insert和update

- insert undo log是指在insert操作中产生的undo log。由于insert操作的记录，只是对本事务可见，其他事务不可见，所以undo log可以在事务提交后直接删除，而不需要purge操作。
- update undo log是指在delete和update操作中产生的undo log。该undo log会被后续用于MVCC当中，因此不能提交的时候删除。提交后会放入undo log的链表，等待purge线程进行最后的删除。

# sql优化

> https://segmentfault.com/a/1190000021458117?utm_source=tag-newest

