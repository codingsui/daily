[TOC]

# 基本概念

## 什么是缓存？

利用空间换时

## 缓存为系统带来了什么问题？

1. **系统复杂性增加** ：引入缓存之后，你要维护缓存和数据库的数据一致性、维护热点缓存等等。
2. **系统开发成本往往会增加** ：引入缓存意味着系统需要一个单独的缓存服务，这是需要花费相应的成本的，并且这个成本还是很贵的，毕竟耗费的是宝贵的内存。但是，如果你只是简单的使用一下本地缓存存储一下简单的数据，并且数据量不大的话，那么就不需要单独去弄一个缓存服务。

具体的有

- [缓存与数据库双写不一致](https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md)
- [缓存雪崩、缓存穿透、缓存击穿](https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-caching-avalanche-and-caching-penetration.md)
- [缓存并发竞争](https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-cas.md)

## 为什么会有分布式缓存？

1. **本地缓存对分布式架构支持不友好**，比如同一个相同的服务部署在多台机器上的时候，各个服务之间的缓存是无法共享的，因为本地缓存只在当前机器上有。
2. **本地缓存容量受服务部署所在的机器限制明显。** 如果当前系统服务所耗费的内存多，那么本地缓存可用的容量就很少。

使用分布式缓存之后，缓存部署在一台单独的服务器上，即使同一个相同的服务部署在再多机器上，也是使用的同一份缓存。 并且，单独的分布式缓存服务的性能、容量和提供的功能都要更加强大。

使用分布式缓存的缺点呢，也很显而易见，那就是你需要为分布式缓存引入额外的服务比如 Redis 或 Memcached，你需要单独保证 Redis 或 Memcached 服务的高可用。

## 你所了解的缓存读写模式/更新策略有哪些？

### Cache Aside Pattern（旁路缓存模式）

1. 写：删除cache，更新DB，
2. 读：从cache中读取数据，读取到就直接返回，读取不到的话就从DB中取数据返回，然后再把数据放到cache中

Cache Aside Pattern 中服务端需要同时维系 DB 和 cache，并且是以 DB 的结果为准。另外，Cache Aside Pattern 有首次请求数据一定不在 cache 的问题，对于热点数据可以提前放入缓存中。

**Cache Aside Pattern 是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。**

#### 为什么是删除缓存，而不是更新缓存呢？

很多时候，复杂点的缓存的场景，因为缓存有的时候，不简单是数据库中直接取出来的值，商品详情页的系统，修改库存，只是修改了某个表的某些字段，但是要真正把这个影响的最终的库存计算出来，可能还需要从其他表查询一些数据，然后进行一些复杂的运算，才能最终计算出现在最新的库存是多少，然后才能将库存更新到缓存中去

#### 为什么不先修改数据库再删除缓存呢

先修改数据库，再删除缓存，如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据出现不一致

#### 旁路缓存模式还是出现了缓存不一致问题怎么办？

更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部的队列中，读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个jvm内部的队列中，一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行，这样的话，一个数据变更的操作，先执行，删除缓存，然后再去更新数据库，但是还没完成更新，此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成

##### 这里有一个优化点

一个队列中，其实多个读缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个读缓存的请求了，那么就不用再放个读请求操作进去了，直接等待前面的读操作请求完成即可

读请求长时阻塞，由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回

 

由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回

### Read/Write Through Pattern（读写穿透）

1. 写：先查cache，cache中不存在，直接更新DB。cache中存在则先更新cache，然后cache服务自己更新DB
2. 读：从cache中读取数据，读取到就直接返回。读取不到，先从DB加载，写入到cache后返回响应

Read/Write Through 套路是：服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 DB，从而减轻了应用程序的职责。和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中。

### Write Behind Pattern（异步缓存写入）

Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 DB 的读写。

但是，两个又有很大的不同：**Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。**

**Write Behind Pattern 下 DB 的写性能非常高，尤其适合一些数据经常变化的业务场景比如说一篇文章的点赞数量、阅读数量。** 往常一篇文章被点赞 500 次的话，需要重复修改 500 次 DB，但是在 Write Behind Pattern 下可能只需要修改一次 DB 就可以了。

但是，这种模式同样也给 DB 和 Cache 一致性带来了新的考验，很多时候如果数据还没异步更新到 DB 的话，Cache 服务宕机就 gg 了。

## 缓存数据的处理流程？
![5f2f70988d64b52f7bdf7baf94654d8d.png](evernotecid://AFE78BA2-7240-4F53-A10F-425044D23A61/appyinxiangcom/16174389/ENResource/p80)


## redis lua 中keys[1] 和argv[1] 的理解
KEYS[1] 用来表示在redis 中用作键值的参数占位，主要用來传递在redis 中用作keyz值的参数。

ARGV[1] 用来表示在redis 中用作参数的占位，主要用来传递在redis中用做 value值的参数。

## 常见的IO模型有四种

（1）BIO同步阻塞IO（Blocking IO）：即传统的IO模型。

（2）同步非阻塞IO（Non-blocking IO）：默认创建的socket都是阻塞的，非阻塞IO要求socket被设置为NONBLOCK。注意这里所说的NIO并非Java的NIO（New IO）库。

（3）IO多路复用（IO Multiplexing）：即经典的Reactor设计模式，有时也称为异步阻塞IO，Java中的Selector和Linux中的epoll都是这种模型。

（4）异步IO（Asynchronous IO）：即经典的Proactor设计模式，也称为异步非阻塞IO。

## 什么是IO多路复用

> https://zhuanlan.zhihu.com/p/150972878

一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；没有文件句柄就绪时会阻塞应用程序，交出cpu，io多路复用解决的本质问题是在**用更少的资源完成更多的事**。

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/FC36F1E1D55E4BB1B2BB2AAEBA0C8683/17576)

### IO多路复用包含的功能函数

- select
- epoll
- evport
- kqueue

#### **select**结构

```cpp
// 数据结构 (bitmap)
typedef struct {
    unsigned long fds_bits[__FDSET_LONGS];
} fd_set;

// API
int select(
    int max_fd, 
    fd_set *readset, 
    fd_set *writeset, 
    fd_set *exceptset, 
    struct timeval *timeout
)                              // 返回值就绪描述符的数目

FD_ZERO(int fd, fd_set* fds)   // 清空集合
FD_SET(int fd, fd_set* fds)    // 将给定的描述符加入集合
FD_ISSET(int fd, fd_set* fds)  // 判断指定描述符是否在集合中 
FD_CLR(int fd, fd_set* fds)    // 将给定的描述符从文件中删除  
```

#### select处理流程

1. 每次需要将fd从用户态拷贝到内核态
2. 每次便利所有的fd，判断有无读写事件发生
3. 如何当前事件就绪，将客户端soceket加入集合中
4. 处理相关的读事件和写事件

#### select缺点

- 单个进程所打开的FD是有限制的，通过FD_SETSIZE设置，默认1024
- 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
- 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时）

#### poll结构

```cpp
// 数据结构
struct pollfd {
    int fd;                         // 需要监视的文件描述符
    short events;                   // 需要内核监视的事件
    short revents;                  // 实际发生的事件
};

// API
int poll(struct pollfd fds[], nfds_t nfds, int timeout);
```

#### poll与select相比

只是没有fd大小的限制，其它基本一样

#### poll处理流程

1. 需要将fd从用户态拷贝到内核态
2. 每次需要遍历所有fd，判断有无读写事件发生

#### **poll缺点**

- 每次调用poll，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
- 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时）

#### **epoll**结构

> https://www.cnblogs.com/shijingxiang/articles/5387109.html

```cpp
// 数据结构
// 每一个epoll对象都有一个独立的eventpoll结构体
// 用于存放通过epoll_ctl方法向epoll对象中添加进来的事件
// epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可
struct eventpoll {
    /*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/
    struct rb_root  rbr;
    /*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/
    struct list_head rdlist;
};

// API

int epoll_create(int size); //创建一个epoll的句柄 内核中间加一个 ep 对象，把所有需要监听的 socket 都放到 ep 对象中
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // epoll_ctl 负责把 socket 增加、删除到内核红黑树
epoll的事件注册函数，它不同于select()是在监听事件时告诉内核要监听什么类型的事件，而是在这里先注册要监听的事件类型。

第一个参数是epoll_create()的返回值。
第二个参数表示动作，用三个宏来表示：
EPOLL_CTL_ADD：注册新的fd到epfd中；
EPOLL_CTL_MOD：修改已经注册的fd的监听事件；
EPOLL_CTL_DEL：从epfd中删除一个fd；
第三个参数是需要监听的fd。
第四个参数是告诉内核需要监听什么事

int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);// epoll_wait 负责检测可读队列，没有可读 socket 则阻塞进程 收集在epoll监控的事件中已经发送的事件
```

#### **epoll缺点**

epoll只能工作在linux下

#### **epoll LT 与 ET模式的区别**

- epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。
- LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作
- ET模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读完，或者遇到EAGAIN错误

### redis所用的I/O多路复用函数是什么

Redis在I/O多路复用程序的实现源码中定义了相应的规则，程序会在编译时自动选择系统中性能最高的I/O多路复用函数库来作为Redis的I/O多路复用程序的底层实现。

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/D769769E02014C86B1BD97737BD3A629/17578)

## 文件事件处理器

Redis基于Reactor模式开发了自己的网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。使用I/O多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。虽然文件事件处理器以单线程方式运行，但通过使用I/O多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与Redis服务器中其他同样以单线程方式运行的模块进行对接，这保持了Redis内部单线程设计的简单性。

### 文件事件处理器的构成

套接字、I/O多路复用程序、文件事件分派器（dispatcher），以及事件处理器。

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/7AE9F7CD08F1473FB433CD57EA67B62C/17574)

### 文件事件处理器的执行流程

尽管多个文件事件可能会并发地出现，但I/O多路复用程序总是会将所有产生事件的套接字都放到一个队列里面，然后通过这个队列，以有序（sequentially）、同步（synchronously）、每次一个套接字的方式向文件事件分派器传送套接字。当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕），I/O多路复用程序才会继续向文件事件分派器传送下一个套接字。

### 文件事件处理大致有哪些

- 为了对连接服务器的各个客户端进行应答，服务器要为监听套接字关联连接应答处理器。
- 为了接收客户端传来的命令请求，服务器要为客户端套接字关联命令请求处理器。
- 为了向客户端返回命令的执行结果，服务器要为客户端套接字关联命令回复处理器。
- 当主服务器和从服务器进行复制操作时，主从服务器都需要关联特别为复制功能编写的复制处理器。

### 一次完整的客户端与服务器连接事件示例

1. 客户端与服务器发起连接，建立连接应答处理器，该处理器会对连接请求进行应答，之后创建客户端套接字和状态，并将客户端套接字的AE_READABLE事件和命令请求处理器进行关联，使得客户端可以向主服务器发送命令请求。
2. 客户端向主服务发送命令请求，那么主服务器执行命令请求处理器，读区客户端的命令内容，然后传给相关程序执行
3. 执行命令将产生相应回复，主服务器会创建命令回复处理器，将命令回写到套接字

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/AEF656DE415346DCAA742323CB2182C9/17580)

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/9FA80DD55DF34A5BAFC5833A55421EA5/17592)

### 时间事件serverCron

持续运行的Redis服务器需要定期对自身的资源和状态进行检查和调整，从而确保服务器可以长期、稳定地运行。

- 更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。
- 清理数据库中的过期键值对。
- 关闭和清理连接失效的客户端。
- 尝试进行AOF或RDB持久化操作。
- 如果服务器是主服务器，那么对从服务器进行定期同步。
- 如果处于集群模式，对集群进行定期同步和连接测试。

## 布隆过滤器

> https://github.com/Snailclimb/JavaGuide/blob/master/docs/dataStructures-algorithms/data-structure/bloom-filter.md

可以把它看作由二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在**

# 什么是redis？简单介绍一下redis

> https://www.cnblogs.com/kismetv/p/9236731.html

简单来说 **Redis 就是一个使用 C 语言开发的数据库**，不过与传统数据库不同的是 **Redis 的数据是存在内存中的** ，也就是它是内存数据库，所以读写速度非常快，因此 Redis 被广泛应用于缓存方向。另外，**Redis 除了做缓存之外，Redis 也经常用来做分布式锁，甚至是消息队列。****Redis 提供了多种数据类型来支持不同的业务场景。Redis 还支持事务 、持久化、Lua 脚本、多种集群方案。

## redis底层

### sds

SDS实现了空间预分配和惰性空间释放两种优化策略避免每次重新分配内存空间

- 空间预分配：先检查未使用空间是否足够，如果足够的话，API就会直接使用未使用空间，而无须执行内存重分配。不足够整体大小<1M 分配1倍 >1M 分配1M，Redis可以减少连续执行字符串增长操作所需的内存重分配次数。
- 惰性空间释放：用于优化SDS的字符串缩短操作：当SDS的API需要缩短SDS保存的字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录起来，并等待将来使用。

优点：

1）常数复杂度获取字符串长度。2）杜绝缓冲区溢出。3）减少修改字符串长度时所需的内存重分配次数。4）二进制安全。5）兼容部分C字符串函数。
![d709192ef631dbc4c379a7e9d826945c.png](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/AC9740F7FEB24738B5AD4361AEE94E62/17603)

### 链表

列表键的底层实现之一就是链表，双向链表节点，又二次封装为带头尾节点的list,被广泛用于实现Redis的各种功能，比如列表键、发布与订阅、慢查询、监视器等。

双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的复杂度都是O（1）。

❑无环：表头节点的prev指针和表尾节点的next指针都指向NULL，对链表的访问以NULL为终点。

❑带表头指针和表尾指针：通过list结构的head指针和tail指针，程序获取链表的表头节点和表尾节点的复杂度为O（1）。

❑带链表长度计数器：程序使用list结构的len属性来对list持有的链表节点进行计数，程序获取链表中节点数量的复杂度为O（1）。

❑多态：链表节点使用void指针来保存节点值，并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。

### 字典

字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构。Redis的字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，类似于1.7的hashmap，拉链法。散列函数采用非加密散列函数MurmurHash。链表插入是头插法
数据库和hash建（特定情况下实现）
字典中ht保存了两个哈希表,一般情况下,字典使用ht[0]哈希表,h[1]哈希表只有在对ht[0]rehash时使用.rehashidx通常为-1,如果正在进行rehash，则值大于-1.

#### 字典结构

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/872526AE754E43768EFD1C9DC01C2B1B/17582)

#### rehash
1）为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量（也即是ht[0].used属性的值）：
❑如果执行的是扩展操作，那么ht[1]的大小为第一个大于等于ht[0].used*2的2 n（2的n次方幂）；
❑如果执行的是收缩操作，那么ht[1]的大小为第一个大于等于ht[0].used的2n。
2）将保存在ht[0]中的所有键值对rehash到ht[1]上面：rehash指的是重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上。
3）当ht[0]包含的所有键值对都迁移到了ht[1]之后（ht[0]变为空表），释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表，为下一次rehash做准备。

#### 渐进式rehash：

1）为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。

2）在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。

3）在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增一。

4）随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。渐进式rehash的好处在于它采取分而治之的方式，将rehash键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量。

字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行。例如，要在字典里面查找一个键的话，程序会先在ht[0]里面进行查找，如果没找到的话，就会继续到ht[1]里面进行查找，诸如此类。另外，在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作，这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表。
#### 负载因子计算
```
# 负载因子 = 哈希表已保存节点数量 / 哈希表大小
load_factor = ht[0].used / ht[0].size
```
#### 何时开始rehash操作

　　字典中的哈希表随着保存元素越来越多，当负载因子load_factor = ht[0].used / ht[0].size 满足某些值时,开始对哈希表执行扩展操作

　　具体情况如下：

　　　　a.redis服务器目前正在进行BGSAVE 或BGREWRITEAOF命令,则load_factor的负载因子大于等于5，则开始扩展

　　　　b.redis服务器没有进行BGSAVE 或BGREWRITEAOF命令,则load_factor的负载因子大于等于1,则开始扩展

　　服务器进行BGSAVE或BGREWRITEAOF命令时，创建子进程执行命令，此时采用写时复制技术优化子进程效率，所以此时负载因子调大，避免执行扩展操作，节约内存。
#### 何时进行收缩操作
当哈希表的负载因子小于 0.1 时， 程序自动开始对哈希表执行收缩操作
### 什么是跳跃表

> https://www.pianshen.com/article/858450914/

跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。本质是链表加多级索引的结构，就是跳跃表。
Redis每个跳跃表节点的层高都是1至32之间的随机。
![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/7FE76B5198654B80B42A50B869CA6002/17586)

#### 跳跃表优点

跳跃表在链表的基础上增加了多级索引以提升查找的效率，但其是一个空间换时间的方案，必然会带来一个问题——索引是占内存的。原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值值和几个指针，并不需要存储对象，因此当节点本身比较大或者元素数量比较多的时候，其优势必然会被放大，而缺点则可以忽略。

#### redis中跳跃表的结构（实现）
Redis的跳跃表由zskiplistNode和skiplist两个结构定义,其中 zskiplistNode结构用于表示跳跃表节点,而 zskiplist结构则用于保存跳跃表节点的相关信息,比如节点的数量,以及指向表头节点和表尾节点的指针等等。
![519f1adade5c58ba4b08c6545710e56d.png](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/3C6E61D81B14465BA084F61334D3473F/17588)
header:指向跳跃表的表头节点，通过这个指针程序定位表头节点的时间复杂度就为O(1)

tail:指向跳跃表的表尾节点,通过这个指针程序定位表尾节点的时间复杂度就为O(1)

level:记录目前跳跃表内,层数最大的那个节点的层数(表头节点的层数不计算在内)，通过这个属性可以再O(1)的时间复杂度内获取层高最好的节点的层数。

length:记录跳跃表的长度,也即是,跳跃表目前包含节点的数量(表头节点不计算在内)，通过这个属性，程序可以再O(1)的时间复杂度内返回跳跃表的长度。

结构右方的是四个 zskiplistNode结构,该结构包含以下属性
![68d9b44f913f2cfbe6d088ac58a93517.png](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/D7FF08A5198E463ABD43B8D624BAD9F2/17590)

层(level):

    节点中用1、2、L3等字样标记节点的各个层,L1代表第一层,L代表第二层,以此类推。
    
    每个层都带有两个属性:前进指针和跨度。前进指针用于访问位于表尾方向的其他节点,而跨度则记录了前进指针所指向节点和当前节点的距离(跨度越大、距离越远)。在上图中,连线上带有数字的箭头就代表前进指针,而那个数字就是跨度。当程序从表头向表尾进行遍历时,访问会沿着层的前进指针进行。
    
    每次创建一个新跳跃表节点的时候,程序都根据幂次定律(powerlaw,越大的数出现的概率越小)随机生成一个介于1和32之间的值作为level数组的大小,这个大小就是层的“高度”。

后退(backward)指针：

    节点中用BW字样标记节点的后退指针,它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。与前进指针所不同的是每个节点只有一个后退指针，因此每次只能后退一个节点。

分值(score):

    各个节点中的1.0、2.0和3.0是节点所保存的分值。在跳跃表中,节点按各自所保存的分值从小到大排列。

成员对象(oj):

    各个节点中的o1、o2和o3是节点所保存的成员对象。在同一个跳跃表中,各个节点保存的成员对象必须是唯一的,但是多个节点保存的分值却可以是相同的:分值相同的节点将按照成员对象在字典序中的大小来进行排序,成员对象较小的节点会排在前面(靠近表头的方向),而成员对象较大的节点则会排在后面(靠近表尾的方向)。
#### 跳跃表删除元素

 1. 找到对象元素
  2. 自上而下，查找第一次出现节点的索引，并逐层找到每一层对应的节点，保存到数组中。O(logN)
 3. 删除每一层查找到的节点，如果该层只剩下1个节点，删除整个一层（原链表除外）,修正相关信息（节点跨度，指针等）。O(logN)
 4. 释放删除节点

#### 跳跃表增加元素

1. 新节点和各层索引节点逐一比较（遍历当前层的每一个元素，先根据分值比较，如果分值相同，再比较字符串长度，长度相同再比较内容），确定原链表的插入位置。O（logN）
2. 计算层数，创建节点。如果k层的结点数是x，那么k+1层就是0.25*x了。这就是所谓的幂次定律（powerlaw）
3. 把新节点插入到原链表，修正每层指针及跨度，更新最大层数。O（1）

#### 怎么从新节点当中选取一部分提到上一层（抛硬币法）？

 当大量的新节点通过逐层比较，最终插入到原链表之后，上层的索引节点会渐渐变得不够用。
       这时候需要从新节点当中选取一部分提到上一层。

```
   使用【**抛硬币**】。

     **也就是随机决定新节点是否提拔，每次向上提拔一层的几率是50%**
```

### 整数集合

如果集合的元素不太多并且都是整数的时候就会采用intset整数集合的方式实现，其中整数集合的大小是可以升级的，如编码int16，int32，int64等

#### 升级后不会被降级

 整数集合不支持降级操作,一旦对数组进行了升级,编码就会一直保持升级后的状态。也就是说一旦我们向一个int16_t的整数集合内添加了一个int32_t的元素后，整数集合将升级到int32_t类型。即使后续的操作中我们删除了这个元素，整数集合还是会保持int32_t类型的状态。

#### 升级的好处

整数集合的升级策略有两个好处，一个是提升整数集合的灵活性，另一个是尽可能地节约内存。

#### 升级`intset`并添加新元素的过程分为以下三步

1. 根据新元素的类型扩展数组的空间
2. 将其他的数据类型转化为与新元素的数据类型相同
3. 将新元素插入到数据的合适位置，并更新`encoding`属性的值

### 压缩列表

压缩列表（ziplist）是列表键和哈希键的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么Redis就会使用压缩列表来做列表键的底层实现。有点儿类似数组，通过一片连续的内存空间，来存储数据。不过，它跟数组不同的一点是，它允许存储的数据大小不同。

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/97D42D19CC0D40D7A7926F602414C1E7/17562)

#### 压缩列表节点构成

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/2790B9B925EE4C9FB7159C142CA06096/17571)

- previous_entry_length属性以字节为单位,记录了压缩列表中前一个节点的长度。 previous_entry_length属性的长度可以是1字节或者5字节。
  - 如果前一节点的长度小于254字节,那么 previous_entry_length属性的长度为1字节，前一节点的长度就保存在这一个字节里面。
  - 如果前一节点的长度大于等于254字节,那么 previous_entry_length属性的长度为5字节:其中属性的第一字节会被设置为0xFE(十进制值254),而之后的四个字节则用于保存前一节点的长度.
- encoding属性记录了节点的content属性所保存数据的类型以及长度
- content保存节点的内容

#### 连锁更新

在一个压缩列表中，有多个连续的、长度介于250字节到253字节之间的节点e1至eN，因为e1至eN的所有节点的长度都小于254字节，所以记录这些节点的长度只需要1字节长的previous_entry_length属性，如果我们将一个长度大于等于254字节的新节点new设置为压缩列表的表头节点，那么new将成为e1的前置节点，此时e1的previous_entry_length属性新增四个字节的空间之后，e1的长度就变成了介于254字节至257字节之间，而这种长度使用1字节长的previous_entry_length属性是没办法保存的。为了让e2的previous_entry_length属性可以记录下e1的长度，程序需要再次对压缩列表执行空间重分配操作，并将e2节点的previous_entry_length属性从原来的1字节长扩展为5字节长。正如扩展e1引发了对e2的扩展一样，扩展e2也会引发对e3的扩展，而扩展e3又会引发对e4的扩展。

## 说一下 Redis 和 Memcached 的区别和共同点

共同点：

1. 都是基于内存的数据库，一般都用来当做缓存使用。
2. 都有过期策略。
3. 两者的性能都非常高。

区别：

1. **Redis 支持更丰富的数据类型（支持更复杂的应用场景）**。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
2. **Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中。**
3. **Redis 有灾难恢复机制。** 因为可以把缓存中的数据持久化到磁盘上。
4. **Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。**
5. **Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的.**
6. **Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。** （Redis 6.0 引入了多线程 IO ）
7. **Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。**
8. **Memcached过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。**

## redis常见的数据结构有哪些？各自的应用场景

### string

基本类型，是安全的不会早从缓冲区溢出，一个redis字符串value最多可以是512M

常用命令？

```redis
set,get,strlen,exists,decr,incr,setex

expire key  60 # 数据在 60s 后过期
setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)
ttl key 
```

应用场景？

计数器

### list

ziplist或者linkedlist，但是在版本3.2之后，重新引入了一个 quicklist 的数据结构，列表的底层都由quicklist实现。易于插入和删除，但是随机访问比较困难。quicklist可以看做一个双向的ziplists.

#### 什么时候使用ziplist或linkedlist?

列表对象使用ziplist编码：

- 列表对象保存的所有字符串元素的长度都小于64字节；

- 列表对象保存的元素数量小于512个；

不能满足这两个条件的列表对象需要使用linkedlist编码。

 #### 常用命令？

```
rpush,lpop,lpush,rpop,lrange、llen

rpush myList value1 # 向 list 的头部（右边）添加元素
rpush myList value2 value3 # 向list的头部（最右边）添加多个元素
lpop myList # 将 list的尾部(最左边)元素取出
lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end
lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一

#栈的实现
rpush myList2 value1 value2 value3
rpop myList2 # 将 list的头部(最右边)元素取出
```

#### 应用场景？

发布于订阅或者说消息队列、慢查询，通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西

### hash

哈希对象的编码可以是ziplist或者hashtable。

#### 当哈希对象可以同时满足以下两个条件时，哈希对象使用ziplist编码：

- 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节；
- 哈希对象保存的键值对数量小于512个；

不能满足这两个条件的哈希对象需要使用hashtable编码。

#### 常用操作

```
127.0.0.1:6379> hset userInfoKey name "guide" description "dev" age "24"
OK
127.0.0.1:6379> hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。
(integer) 1
127.0.0.1:6379> hget userInfoKey name # 获取存储在哈希表中指定字段的值。
"guide"
127.0.0.1:6379> hget userInfoKey age
"24"
127.0.0.1:6379> hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值
1) "name"
2) "guide"
3) "description"
4) "dev"
5) "age"
6) "24"
127.0.0.1:6379> hkeys userInfoKey # 获取 key 列表
1) "name"
2) "description"
3) "age"
127.0.0.1:6379> hvals userInfoKey # 获取 value 列表
1) "guide"
2) "dev"
3) "24"
127.0.0.1:6379> hset userInfoKey name "GuideGeGe" # 修改某个字段对应的值
127.0.0.1:6379> hget userInfoKey name
"GuideGeGe"
```

应用场景？

系统中对象的存储

### set

集合对象的编码可以是intset或者hashtable。

Redis中的set是一个无序集合，集合元素没有先后顺序。当需要一个列表数据，又不需要出现重复数据的时候，set是一个很好的选择。

#### 当集合对象可以同时满足以下两个条件时，对象使用intset编码：

- 集合对象保存的所有元素都是整数值；
- 集合对象保存的元素数量不超过512个。

不能满足这两个条件的集合对象需要使用hashtable编码

intset编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合里面。

hashtable编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，每个字符串对象包含了一个集合元素，而字典的值则全部被设置为NULL。

常用命令？

```
sadd,spop,smembers,sismember,scard,sinterstore,sunion
127.0.0.1:6379> sadd mySet value1 value2 # 添加元素进去
(integer) 2
127.0.0.1:6379> sadd mySet value1 # 不允许有重复元素
(integer) 0
127.0.0.1:6379> smembers mySet # 查看 set 中所有的元素
1) "value1"
2) "value2"
127.0.0.1:6379> scard mySet # 查看 set 的长度
(integer) 2
127.0.0.1:6379> sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素
(integer) 1
127.0.0.1:6379> sadd mySet2 value2 value3
(integer) 2
127.0.0.1:6379> sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中
(integer) 1
127.0.0.1:6379> smembers mySet3
1) "value2"
```

#### 应用场景？

需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景

可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。

### zset

有序集合的编码可以是ziplist或者skiplist。

和set相比，增加了一个权重参数score，使得集合中的元素能够按照score进行有序排列，还可以通过score范围来获取元素的列表。有点象java中HashMap和Treeset的结合。

ziplist编码的压缩列表对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员（member），而第二个元素则保存元素的分值（score）。

#### 当有序集合对象可以同时满足以下两个条件时，对象使用ziplist编码：

- 有序集合保存的元素数量小于128个；

- 有序集合保存的所有元素成员的长度都小于64字节；

不能满足以上两个条件的有序集合对象将使用skiplist编码。

#### 常用命令

```
zadd,zcard,zscore,zrange,zrevrange,zrem 
127.0.0.1:6379> zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重
(integer) 1
127.0.0.1:6379> zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素
(integer) 2
127.0.0.1:6379> zcard myZset # 查看 sorted set 中的元素数量
(integer) 3
127.0.0.1:6379> zscore myZset value1 # 查看某个 value 的权重
"3"
127.0.0.1:6379> zrange  myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素
1) "value3"
2) "value2"
3) "value1"
127.0.0.1:6379> zrange  myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start  1 为 stop
1) "value3"
2) "value2"
127.0.0.1:6379> zrevrange  myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start  1 为 stop
1) "value1"
2) "value2"
```

#### 应用场景

 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。

## redis的内存回收

Redis在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制

## redis是单线程的，那是怎样监听客户端连接的呢？

**Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型** （Netty 的线程模型也基于 Reactor 模式，Reactor 模式不愧是高性能 IO 的基石），这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。

Redis 通过**IO 多路复用程序** 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型(读、写）注册到内核中并监听每个事件是否发生。这样的好处非常明显： **I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗**（和 NIO 中的 `Selector` 组件很像）。另外， Redis 服务器是一个事件驱动程序，服务器需要处理两类事件： 1. 文件事件; 2. 时间事件。时间事件不需要多花时间了解，我们接触最多的还是 **文件事件**（客户端进行读取写入等操作，涉及一系列网络通信）。

《Redis 设计与实现》有一段话是如是介绍文件事件的，我觉得写得挺不错。

> Redis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据 套接字目前执行的任务来为套接字关联不同的事件处理器。
>
> 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。
>
> **虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字**，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。

### 文件时间处理器主要包含哪几部分？

- 多个 socket（客户端连接）
- IO 多路复用程序（支持多个客户端连接的关键）
- 文件事件分派器（将 socket 关联到相应的事件处理器）
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/55DB5273B91740D0BF41E09726E37E0E/16378)

### Redis 没有使用多线程？为什么不使用多线程？

Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主处理之外的其他线程来“异步处理”。

大体上来说，**Redis 6.0 之前主要还是单线程处理。**

**那，Redis6.0 之前 为什么不使用多线程？**

我觉得主要原因有下面 3 个：

1. 单线程编程容易并且更容易维护；
2. Redis 的性能瓶颈不在 CPU ，主要在内存和网络；
3. 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

### Redis6.0 之后为何引入了多线程？

**Redis6.0 引入多线程主要是为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。

Redis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改 redis 配置文件 `redis.conf` ：

```
io-threads-do-reads yes
```

开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 `redis.conf` :

```
io-threads 4 #官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程
```

## Redis 给缓存数据设置过期时间有啥用？

因为内存是有限的，如果缓存中的所有数据都是一直保存的话，分分钟直接Out of memory。

Redis 自带了给缓存数据设置过期时间的功能，比如：

```
127.0.0.1:6379> exp key  60 # 数据在 60s 后过期
(integer) 1
127.0.0.1:6379> setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)
OK
127.0.0.1:6379> ttl key # 查看数据还有多久过期
(integer) 56
```

注意：**Redis中除了字符串类型有自己独有设置过期时间的命令 `setex` 外，其他方法都需要依靠 `expire` 命令来设置过期时间 。另外， `persist` 命令可以移除一个键的过期时间： **

**过期时间除了有助于缓解内存的消耗，还有什么其他用么？**

很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在1分钟内有效，用户登录的 token 可能只在 1 天内有效。

如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多

## Redis是如何判断数据是否过期的呢？

Redis 通过一个叫做过期字典（可以看作是hash表）来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个long long类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/6717686E84324253B41D207ADD71A001/16380)

过期字典是存储在redisDb这个结构里的：

```
typedef struct redisDb {
    ...
    
    dict *dict;     //数据库键空间,保存着数据库中所有键值对
    dict *expires   // 过期字典,保存着键的过期时间
    ...
} redisDb;
```

## 过期的数据的删除策略了解么？

如果假设你设置了一批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进行删除的呢？

常用的过期数据的删除策略就两个（重要！自己造缓存轮子的时候需要格外考虑的东西）：

1. **惰性删除** ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。
2. **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。
3. 定时删除：在设置键的过期时间的同时，创建一个定时器（timer），让定时器在键的过期时间来临时，立即执行对键的删除操作。

定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis 采用的是 **定期删除+惰性/懒汉式删除** 。

但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就Out of memory了。

怎么解决这个问题呢？答案就是： **Redis 内存淘汰机制。**

### Redis 内存淘汰机制了解么？

> 相关问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?
>
> 1.首先大概计算数据所占用的内存,然后可以在配置文件里面设置maxmemory(单位是byte字节)参数和参数maxmemory-policy(过期策略)
>
> 2.因为我们的应用保存热点数据，也就是对缓存的访问符合幂律分布，所以应该选择Allkeys-lru淘汰策略。存放热点数据，不能为数据设置过期时间，设置过期时间也会占用内存。

Redis 提供 6 种数据淘汰策略：

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

手写lru

```java
// 继承LinkedHashMap
    public class LRUCache<K, V> extends LinkedHashMap<K, V> {
        private final int MAX_CACHE_SIZE;

        public LRUCache(int cacheSize) {
            // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。

            super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
            MAX_CACHE_SIZE = cacheSize;
        }

        @Override
        protected boolean removeEldestEntry(Map.Entry eldest) {
            // 超过阈值时返回true，进行LRU淘汰
            return size() > MAX_CACHE_SIZE;
        }

    }
```



## redis事务的用法？

- DISCARD：取消事务，放弃执行事务块内的所有命令
- EXEC：执行所有事务块内的命令
- MULTI：标记一个事务块的开始
- UNWATCH：取消WATCH命令对所有key的监视
- WATCH key：监视一个或多个key
  - 类似于乐观锁，事务提交时，如果key的值已被别的客户端改变，比如某个list已被别的客户端push/pop过了，整个事务队列都不会被执行

使用 [MULTI](https://redis.io/commands/multi)命令后可以输入多个命令。Redis不会立即执行这些命令，而是将它们放到队列，当调用了[EXEC](https://redis.io/commands/exec)命令将执行所有命令。

### 为什么 Redis 不支持事务回滚？

1. 大多数事务失败是因为**语法错误或者类型错误**，这两种错误，在开发阶段都是可以预见的。
2. Redis 为了**性能方面**就忽略了事务回滚。

### 悲观锁

## Redis 持久化机制(怎么保证 Redis 挂掉之后再重启数据可以进行恢复)?

Redis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持两种不同的持久化操作。**Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）**。

### 什么是快照？

可以理解为将前一时刻的数据拍成一张照片保存下来。

### RDB是什么？

将内存中的数据集快照写入磁盘。是redis默认的持久化方式，默认的文件是dump.rdb。Fock的子进程会将数据写入到一个临时文件，待持久化完毕将这个临时文件替换成上次持久化好的文件。

#### RDB主要的触发机制有哪些？

| 类别     | 说明                                                         | 优点 |
| -------- | ------------------------------------------------------------ | ---- |
| save     | 执行一个同步操作，执行期间，redis不能处理其他命令，直到RDB结束。执行完成时候如果存在老的RDB文件，就把新的替代掉旧的。我们的客户端可能都是几万或者是几十万，这种方式显然不可取。 |      |
| Bgsave   | 是一个异步操作，以RDB文件的方式保存所有数据的快照。使用linux系统的fock()生产一个子进程将DB数据保存到磁盘，主进程继续为客户端提供服务，如果操作成功，可以通过客户端LASTSAVE检查操作结果。 |      |
| 自动触发 | 通过配置文件设置save second times，在指定时间内进行了至少指定次数的操作，则触发bgsave自动保存快照 |      |

#### RDB优点&缺点？

优点

1. 文件紧凑，全量备份，适合对大规模的数据恢复
2. 对数据的完整性和一致性要求不高
3. 最大化redis性能，fork子进程处理备份
4. 恢复大数据的时候速度比AOF快

缺点

1. 在一定时间间隔做一次备份，如果redis意外down掉，就是丢失最后一次快照后的所有修改，不适合做第一优先恢复方案 。
2. Fork的时候，内存的数据被克隆一份，大致2倍的膨胀性需要考虑，父进程修改数据子进程不会反应过来，所以在快照持久化期间内修改的数据不会被保存

#### 如何通过RDB恢复数据？

将dump.rdb 文件拷贝到redis的安装目录的bin目录下，重启redis服务即可。在实际开发中，一般会考虑到物理机硬盘损坏情况，选择备份dump.rdb 。

#### 开启写的时候，RDB为什么比AOF快？

RDB每次写都是直接写redis内存，在一定的时候将数据同步到磁盘。

AOF每次写不止要写redis内存，还要写如OS cache中，有一定 的时间开销，速度肯定比RDB慢。而且恢复的时候必须要按指令再执行一遍

#### RDB持久化机制的工作流程

（1）redis根据配置自己尝试去生成rdb快照文件
（2）fork一个子进程出来
（3）子进程尝试将数据dump到临时的rdb快照文件中
（4）完成rdb快照文件的生成之后，就替换之前的旧的快照文件

#### redis中RDB持久化时BGSAVE的过程中，如果有新的值插入，会不会持久化？

不会。RDB持久化的过程使用，为了节省内存，使用了copy on write 的策略，“写时复制“技术，在只有进程空间的各段的内容要发生
变化时，才会将父进程的内容复制一份给子进程，所以新写入数据时，子进程会单独复制一份写之前的数据，此时此段子进程与父进程是各自独立维护的

### 什么是AOF？

以日志形式来记录每个写操作，将Redis执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。

```
#开启
appendonly yes
```

#### AOF更新条件（触发机制|同步机制）？

```
appendfsync everysec
```

always：同步持久化，每次发生数据变化会立刻写入到磁盘中。性能较差当数据完整性比较好（慢，安全）
everysec：出厂默认推荐，每秒异步记录一次（默认值）
no：不同步，让操作系统决定何时进行同步

#### AOF重写触发机制？

```
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
#当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。一般都设置为3G，64M太小了。
```

#### 如何根据AOF恢复数据？

正常情况下，将appendonly.aof 文件拷贝到redis的安装目录的bin目录下，重启redis服务即可。但在实际开发中，可能因为某些原因导致appendonly.aof 文件格式异常，从而导致数据还原失败，可以通过命令redis-check-aof --fix appendonly.aof 进行修复 。
#### AOF载入原理
![01fa8078ee639e62995f641c264d46b1.png](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/8C62C3D277AE4CCCB2F13E333EEC76C2/17594)
#### AOF重写原理
<img src="https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/9A040B2B7834444FA630C4B3995BCC49/17596" alt="ca8f9909ef8f084266d4d3ea5aae1a6e.png" style="zoom:67%;" />

#### AOF重写入原理？

因为 AOF 的运作方式是不断地将命令追加到文件的末尾， 所以随着写入命令的不断增加， AOF 文件的体积也会变得越来越大。举个例子， 如果你对一个计数器调用了 100 次 INCR ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录（entry）。然而在实际上， 只使用一条 SET 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。为了处理这种情况， Redis 支持一种有趣的特性： 可以在不打断服务客户端的情况下， 对 AOF 文件进行重建（rebuild）。执行 BGREWRITEAOF 命令， Redis 将生成一个新的 AOF 文件， 这个文件包含重建当前数据集所需的最少命令。Redis 会fork出一条新进程，读取内存中的数据，并重新写到一个临时文件中。并没有读取旧文件，最后替换旧的aof文件。

#### AOF重写入如何保证新数据的完整

在子进程执行AOF重写期间，服务器进程需要执行以下三个工作：

1）执行客户端发来的命令。

2）将执行后的写命令追加到AOF缓冲区。

3）将执行后的写命令追加到AOF重写缓冲区。

这样一来可以保证：

- AOF缓冲区的内容会定期被写入和同步到AOF文件，对现有AOF文件的处理工作会如常进行。
- 从创建子进程开始，服务器执行的所有写命令都会被记录到AOF重写缓冲区里面。

当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接到该信号之后，会调用一个信号处理函数，并执行以下工作：

1）将AOF重写缓冲区中的所有内容写入到新AOF文件中，这时新AOF文件所保存的数据库状态将和服务器当前的数据库状态一致。

2）对新的AOF文件进行改名，原子地（atomic）覆盖现有的AOF文件，完成新旧两个AOF文件的替换。这个信号处理函数执行完毕之后，父进程就可以继续像往常一样接受命令请求了。

#### AOF的优缺点？

优点：

1. AOF可以带来更高的数据安全性，提供了3中同步策略。
2. 对文件写入采用append模式，在写入过程中不会寻址，写入性能高，冗机也不会破坏日志中已经写入的内容，而且可以通过redis-check-aof去纠正日志
3. 如果日志文件过大，redis会自动启用rewrite机制。即Redis不断将修改数据写入老的磁盘文件中，并且会创建一个临时文件，将内存中的数据写入，最后替换旧的AOF文件
4. AOF文件格式易于分析，非常适合做灾难性误删除的紧急恢复，比如不小心执行flushall，此时还没有rewrite，就可以立即copy aof文件，将最后一条flushall命令删除了，然后再将aof文件放回去，就可以通过恢复机制，自动恢复所有机制。

缺点：

1. 相同数据量，AOF文件大小通常要大于RDB，RDB在恢复大数据集时的速度要比AOF快
2. AOF开启后，支持写QPS会比RDB的写QPS低
3. 数据恢复的时候比较慢，做备份的时候不太方便

### 对于自己的服务，如何抉择两种持久化机制？

同时开启两种持久化方式：

（1）不要仅仅使用RDB，因为那样会导致你丢失很多数据 

（2）也不要仅仅使用AOF，因为那样有两个问题，第一，你通过AOF做冷备，没有RDB做冷备，来的恢复速度更快; 第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug

（3）综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复

### AOF的bug

### AOF和RDB同时存在，怎么恢复？

如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 **AOF** 来重新构建数据，因为 AOF 中的**数据更加完整**。

### AOF和RDB缺点和优点

RDB优点：
他会生成多个数据文件，每个数据文件分别都代表了某一时刻Redis里面的数据，这种方式，有没有觉得很适合做冷备，完整的数据运维设置定时任务，定时同步到远端的服务器，比如阿里的云服务，这样一旦线上挂了，你想恢复多少分钟之前的数据，就去远端拷贝一份之前的数据就好了。RDB对Redis的性能影响非常小，是因为在同步数据的时候他只是fork了一个子进程去做持久化的，而且他在数据恢复的时候速度比AOF来的快。

RDB缺点：
RDB都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。AOF则最多丢一秒的数据，数据完整性上高下立判。
还有就是RDB在生成数据快照的时候，如果文件很大，客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候他刚好在这个时候fork了一个子进程去生成一个大快照，哦豁，出大问题。

AOF优点：
上面提到了，RDB五分钟一次生成快照，但是AOF是一秒一次去通过一个后台的线程fsync操作，那最多丢这一秒的数据。
AOF在对日志文件进行操作的时候是以append-only的方式去写的，他只是追加的方式写数据，自然就少了很多磁盘寻址的开销了，写入性能惊人，文件也不容易破损。
AOF的日志是通过一个叫非常可读的方式记录的，这样的特性就适合做灾难性数据误删除的紧急恢复了，比如公司的实习生通过flushall清空了所有的数据，只要这个时候后台重写还没发生，你马上拷贝一份AOF日志文件，把最后一条flushall命令删了就完事了。

AOF缺点：
一样的数据，AOF文件比RDB还要大。
AOF开启后，Redis支持写的QPS会比RDB支持写的要低，他不是每秒都要去异步刷新一次日志嘛fsync，当然即使这样性能还是很高，我记得ElasticSearch也是这样的，异步刷新缓存区的数据去持久化，为啥这么做呢，不直接来一条怼一条呢，那我会告诉你这样性能可能低到没办法用的，大家可以思考下为啥哟。

## redis企业级备份方案

```shell
每小时copy一次备份，删除48小时前的数据

crontab -e 
0 0 0/1 * * sh /home/www/corn/redis_rdb_copy_hourly.sh

redis_rdb_copy_hourly.sh

#!/bin/sh 

cur_date=`date +%Y%m%d%k`
rm -rf /usr/local/redis/snapshotting/$cur_date
mkdir /usr/local/redis/snapshotting/$cur_date
cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date

del_date=`date -d -48hour +%Y%m%d%k`
rm -rf /usr/local/redis/snapshotting/$del_date

每天copy一次备份

crontab -e

0 0 * * * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh

redis_rdb_copy_daily.sh

#!/bin/sh 

cur_date=`date +%Y%m%d`
rm -rf /usr/local/redis/snapshotting/$cur_date
mkdir /usr/local/redis/snapshotting/$cur_date
cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date

del_date=`date -d -1month +%Y%m%d`
rm -rf /usr/local/redis/snapshotting/$del_date

```



## redis的主从结构？

一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的**读请求全部走从节点**。这样也可以很轻松实现水平扩容，**支撑读高并发**。

### **主从复制的作用**?

1. 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
2. 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。
3. 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。
4. 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。

### 如何建立redis的主从复制？

1. 配置文件，在从服务器的配置文件中加入：slaveof <masterip> <masterport>
2. 启动命令，redis-server启动命令后加入 --slaveof <masterip> <masterport>
3. 客户端命令，Redis服务器启动后，直接通过客户端执行命令：slaveof <masterip> <masterport>，则该Redis实例成为从节点。

### redis主从复制的实现原理是什么？

大体可以分为3个阶段，连接建立（准备）、数据同步、命令传播三个阶段。

连接建立阶段：

1. 保存主节点信息。从节点执行slaveof是异步命令，执行后直接发送命令的从节点返回ok。
2. 建立socket连接。从节点每秒1次调用定时函数replicationCorn()，如果发现有主节点可以连接，就会根据ip和port创建socket连接，创建成功，从节点会为socket建立一个专门的文件事件处理器，负责后续的复制工作，如RDB文件，命令传播等；主节点会为socket创建相应的客户端状态，并将从节点看做是主节点的一个客户端。
3. 发送ping命令。从节点成为主节点客户端后，首次发送ping命令，目的是检测socket是否可以以及主节点是否可以处理请求；如果超时或者没有响应，则断开重连。
4. 身份验证。主节点如果设置了auth认证，则从节点也要设置masterauth，否则就是断开，重连。
5. 发送从节点端口信息。身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。

数据同步阶段：

从结点数据的初始化。具体的执行方式是从结点发送psync命令（Redis2.8之前是发送sync命令），开始同步。这一步是主从复制的核心阶段，根据主从结点的状态不同，可以分为全量复制和部分复制。

命令传播阶段：

数据同步阶段完成后，主从结点进入命令传播阶段；在此阶段主结点将自己执行的写命令发送给从结点，从结点接收命令并执行，从而保证主从结点数据的一致性。除了发送写命令外，主从结点还维持着心跳检查机制：PING和PREPLCONF ACK。

#### 数据同步阶段中的全量复制和增量复制有什么区别？

在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；在Redis2.8及以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。后文介绍以Redis2.8及以后版本为例。

1. 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。
2. 部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。

##### 全量复制的过程？

1. 从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行部分复制；具体判断过程需要在讲述了部分复制原理后再介绍。
2. 主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令
3. 主节点的bgsave执行完成后，将RDB文件发送给从节点；**从节点首先清除自己的旧数据，然后载入接收的**RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态
4. 主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态
   1. client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败
5. 如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态

注意：从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令

###### 全量复制的无盘复制模式？

epl-diskless-sync no：作用于全量复制阶段，控制主节点是否使用diskless复制（无盘复制）。所谓diskless复制，是指在全量复制时，主节点不再先把数据写入RDB文件，而是直接写入slave的socket中，整个过程中不涉及硬盘；diskless复制在磁盘IO很慢而网速很快时更有优势。需要注意的是，截至Redis3.0，diskless复制处于实验阶段，默认是关闭的

##### 部分复制的过程？

1. 复制偏移量。主节点和从节点分别维护一个复制偏移量（offset），代表的是**主节点向从节点传递的字节数**；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。

2. 复制积压缓冲区backlog。复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。

   由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。

   从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：

   - 如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；
   - 如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。
   - 2\**second*\*write_size_per_second

3. 服务器运行ID。每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid。主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制：

   - 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；
   - 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。
   - 如果需要不更改run id重启redis，可以使用redis-cli debug reload命令

#### psync命令的执行过程？

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/8F08F4CE35D24B50AD4B8B91A1E22740/16387)

#### 命令传播阶段心跳机制

主->从：PING 10s

每隔指定的时间，**主节点会向从节点发送**PING命令，这个PING命令的作用，主要是为了让从节点进行超时判断。

从->主：REPLCONF ACK 1s 

在命令传播阶段，**从节点会向主节点发送**REPLCONF ACK命令，默认频率是每秒1次；命令格式为：REPLCONF ACK {offset}，其中offset指从节点保存的复制偏移量。REPLCONF ACK命令的作用包括：

1. 实时监测住主从节点网络状态
2. 检查命令丢失（对比offset）
3. 辅助保证从结点的数量和延迟
   1. ![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/BB92119E2D7F4685A7F68AE4CF781DC1/17607) 

### 主从复制可能带来的问题

#### 命令传播阶段读写分离遇到延迟不一致问题怎么办？

命令传播是异步的过程，即主结点发送写命令后并不会等待从结点的回复；实际上主从结点很难保持实时一致性。数据的不一致程度与主从结点的网络状况，主结点写命令的执行频率，以及主结点中的repl-disable-tcp-nodelay（控制住结点是否禁止从结点的TCP_NODELAY，默认no，会将主结点数据立马发送给从结点带宽增加延迟变小，改为yes时，TCP会对包进行合并从而减少带宽，但是会降低发送频率，从结点数据延迟增加，一致性降低。大多数情况下no）配置有关。

所以可能的优化措施有

1. 优化主从结点之间的网络环境
2. 监控主从结点延迟（通过offset）判断，如果延迟过大，通知服务不再从该节点读取数据。
3. 强制读主，高可用主库，用缓存提高读性能
4. 在cache里记录哪些记录发生过写请求，来路由读主还是读从

#### 读写分离带来的主从之间数据过期问题？

在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除（过期数据向从结点发送一条del命令）。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。

#### 复制超时引起的问题？

主从节点复制超时是导致复制中断的最重要的原因之一。

超时的判定：

主从复制超时判断的核心，在于repl-timeout参数，该参数规定了超时时间的阈值（默认60s），对于主节点和从节点同时有效；主从节点触发超时的条件分别如下：

（1）主节点：每秒1次调用复制定时函数replicationCron()，在其中判断当前时间距离上次收到各个从节点REPLCONF ACK的时间，是否超过了repl-timeout值，如果超过了则释放相应从节点的连接。

（2）从节点：从节点对超时的判断同样是在复制定时函数中判断，基本逻辑是：

- 如果当前处于连接建立阶段，且距离上次收到主节点的信息的时间已超过repl-timeout，则释放与主节点的连接；
- 如果当前处于数据同步阶段，且收到主节点的RDB文件的时间超时，则停止数据同步，释放连接；
- 如果当前处于命令传播阶段，且距离上次收到主节点的PING命令或数据的时间已超过repl-timeout值，则释放与主节点的连接。

超时引起的问题

1. 数据同步。RDB文件过大，导致从节点长时间接受不到数据，发生重连，全量复制，超时，重连......。应避免单机数据不要过大，适当调整repl-timeout值。
2. 命令传播。如果心跳检查的每秒检查时间和响应超时时间相差过小，当网络抖动时，很容易使从结点判定超时。
3. 慢查询导致阻塞。如果某个节点执行慢查询（对大数据的获取等）到制服务器阻塞，阻塞期间无法响应复制连接中对方节点的请求。

### 复制场景中的优化手段有什么？

1. 第一次建立复制。此时全量复制不可避免，但仍有几点需要注意：如果主节点的数据量较大，应该尽量避开流量的高峰期，避免造成阻塞；如果有多个从节点需要建立对主节点的复制，可以考虑将几个从节点错开，避免主节点带宽占用过大。此外，如果从节点过多，也可以调整主从复制的拓扑结构，由一主多从结构变为树状结构（中间的节点既是其主节点的从节点，也是其从节点的主节点）；但使用树状结构应该谨慎：虽然主节点的直接从节点减少，降低了主节点的负担，但是多层从节点的延迟增大，数据一致性变差；且结构复杂，维护相当困难。
2. 主结点重启。冗机重启，runid会发生变化，只能全量复制，此时应进行故障转移，将其中一个从结点升级为住结点。自行重启，redis提供了debug relod方式，可以使runid和offset都不受影响，避免全量复制，它会清空当前内存中的数据，重新从RDB文件中加载，这个过程会导致主节点的阻塞，因此也需要谨慎。
3. 从结点重启。从节点宕机重启后，其保存的主节点的runid会丢失，因此即使再次执行slaveof，也无法进行部分复制。
4. 网络中断。短暂丢包，会自行恢复（PRELCONF ACK）；丢失数据过多，超过了复制积压缓冲区所存储的范围，只能全量复制，可以适当的将缓冲区大小调大。

### Slave过期key处理

slave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。

### 主从复制中的哨兵是什么？

在复制的基础上，哨兵实现了自动化的故障恢复，不存储数据。缺陷：写操作无法负载均衡；存储能力受到单机的限制。在Redis 2.8版本开始引入。

```
sentinel monitor host6379 127.0.0.1 6380 1
```

#### 哨兵的作用？

- 监控。监控主从结点是否运行正常
- 自动故障转移。主结点异常时，将从结点升级为主结点，并让其他从结点改为复制新的主结点
- 配置提供者。如果故障转移发生了，通知client客户端新的master地址，哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作 
- 消息通知。将故障转移结果发送给客户端

#### 哨兵的原理？

1. 定时任务：每个哨兵节点维护了3个定时任务。
   1. 通过向主从节点发送info命令获取最新的主从结构；
   2. 通过发布订阅功能获取其他哨兵节点的信息；
   3. 通过向其他节点发送ping命令进行心跳检测，判断是否下线。
2. 主观下线（sdown）：在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线；与主观下线相对应的是客观下线。
3. 客观下线（odwon）：哨兵节点在对主节点进行主观下线后，会通过sentinel is-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。

**需要特别注意的是，客观下线是主节点才有的概念；如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。**

4. 选举领导者哨兵节点：当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。

监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是Raft算法；Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。

5. 故障转移：选举出的领导者哨兵，开始进行故障转移操作，该操作大体可以分为3个步骤：

- 在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。
- 更新主从状态：通过slaveof no one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。
- 修改从服务器的复制目标

#### 故障转移

- 选举领导者哨兵节点。选举使用的算法是Raft算法，先到先得。也是发送`is-master-down-add ip port 配置纪元 runid`命令，请求将自己设置为局部哨兵领导者。每个哨兵节点在一个配置纪元内只有一次投票权利，如果在给定的时间内没有选举出来，那么就会等待一定的时间后重新进行选举。只有超过半数以上的哨兵节点同意，该哨兵节点才能称为领导哨兵

- 在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。
- 更新主从状态：通过slaveof no one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。
- 修改从服务器的复制目标
- 将旧的主节点设置为新主节点的从节点

#### slave->master 选举算法

领头的哨兵节点回将所有下线的主节点的从节点加入到一个列表里面

1. 删除列表中已经下线或者断开连接的从节点
2. 删除最近5秒没有回复领头哨兵节点的info命令的从节点
3. 删除与主节点断开时间超过配置时间`down-after-milliseconds * 10`的从节点
4. 按照优先级排序，优先级相同按照偏移量排序，选出偏移量最大的，如果偏移量相同，按照runid排序，选出runid最小的

#### Redis 哨兵主备切换的数据丢失问题？

导致数据丢失的两种情况

1. 主备切换的过程，可能会导致数据丢失：由于master->slaver的复制是异步的，有部分数据还没有复制到slaver，master就挂了，这部分数据就丢失了
2. 脑裂导致的数据丢失：脑裂，也就是说，某个 master 所在机器突然**脱离了正常的网络**，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会**认为** master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的**脑裂**。此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。

#### 数据丢失的解决方案？

进行如下配置：

```
min-slaves-to-write 1
min-slaves-max-lag 10
```

 表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。

- 减少异步复制数据的丢失

有了 `min-slaves-max-lag` 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。

- 减少脑裂的数据丢失

如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据。

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/82F94952077149A6BA04D8250BC7787D/17599)

#### quorum和majority

每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还得得到majority哨兵的授权，才能正式执行切换

如果quorum < majority，比如5个哨兵，majority就是3，quorum设置为2，那么就3个哨兵授权就可以执行切换

但是如果quorum >= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换

#### configuration epoch

哨兵会对一套redis master+slave进行监控，有相应的监控的配置

执行切换的那个哨兵，会从要切换到的新master（salve->master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一的

如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号

#### configuraiton传播

哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前说的pub/sub消息机制

这里之前的version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的

其他的哨兵都是根据版本号的大小来更新自己的master配置的

#### 哨兵文件配置

```redis
sentinel monitor mymaster 127.0.0.1 6379 2 # 监控master集群名称，2是quorum
sentinel down-after-milliseconds mymaster 60000 # 超过多少毫秒跟一个redis实例断了连接，哨兵就可能认为这个redis实例挂了
sentinel failover-timeout mymaster 180000 # 执行故障转移的timeout超时时长
sentinel parallel-syncs mymaster 1 # 新的master别切换之后，同时有多少个slave被切换到去连接新master，重新做同步，数字越低，花费的时间越多
```

#### 哨兵节点下线

（1）停止sentinal进程

（2）SENTINEL RESET *，在所有sentinal上执行，清理所有的master状态

（3）SENTINEL MASTER mastername，在所有sentinal上执行，查看所有sentinal对数量是否达成了一致

#### 全过程	

（1）三个哨兵进程都认为master是sdown了

（2）超过quorum指定的哨兵进程都认为sdown之后，就变为odown

（3）哨兵1是被选举为要执行后续的主备切换的那个哨兵

（4）哨兵1去新的master（slave）获取了一个新的config version

（5）尝试执行failover

（6）投票选举出一个slave区切换成master，每隔哨兵都会执行一次投票

（7）让salve，slaveof noone，不让它去做任何节点的slave了; 把slave提拔成master; 旧的master认为不再是master了

（8）哨兵就自动认为之前的187:6379变成了slave了，19:6379变成了master了

（9）哨兵去探查了一下187:6379这个salve的状态，认为它sdown了

 

### 什么是redis集群？

集群，即Redis Cluster，是Redis 3.0开始引入的分布式存储方案。集群由多个节点(Node)组成，Redis的数据分布在这些节点中。集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护；从节点只进行主节点数据和状态信息的复制。在Redis集群中，槽的数量为16384。在redis cluster架构下，每个redis要放开两个端口号，比如一个是6379，另外一个就是加10000的端口号，比如16379，16379端口号是用来进行节点间通信的，也就是cluster bus的东西，集群总线。cluster bus的通信，用来进行故障检测，配置更新，故障转移授权，cluster bus用了另外一种二进制的协议，主要用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间

 

16379端口号是用来进行节点间通信的，也就是cluster bus的东西，集群总线。cluster bus的通信，用来进行故障检测，配置更新，故障转移授权

 

cluster bus用了另外一种二进制的协议，主要用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间 

#### 集群的作用？

1、数据分区：数据分区(或称数据分片)是集群最核心的功能。

集群将数据分散到多个节点，一方面突破了Redis单机内存大小的限制，存储容量大大增加；另一方面每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。

Redis单机内存大小受限问题，在介绍持久化和主从复制时都有提及；例如，如果单机内存太大，bgsave和bgrewriteaof的fork操作可能导致主进程阻塞，主从环境下主机切换时可能导致从节点长时间无法提供服务，全量复制阶段主节点的复制缓冲区可能溢出……。

2、高可用：集群支持主从复制和主节点的自动故障转移（与哨兵类似）；当任一节点发生故障时，集群仍然可以对外提供服务。

#### 集群搭建的方式？

1. 一个一个去执行配置，启动
2. 使用Ruby脚本搭建

#### 数据分区的方案有哪些？

数据分区有顺序分区、哈希分区等，其中哈希分区由于其天然的随机性，使用广泛；集群的分区方案便是哈希分区的一种。

哈希分区的基本思路是：对数据的特征值（如key）进行哈希，然后根据哈希值决定数据落在哪个节点。常见的哈希分区包括：哈希取余分区、一致性哈希分区、带虚拟节点的一致性哈希分区等。

- 哈希取余分区。哈希取余分区思路非常简单：计算key的hash值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。该方案最大的问题是，当新增或删减节点时，节点数量发生变化，系统中所有的数据都需要重新计算映射关系，引发大规模数据迁移。
- 一致性哈希分区。一致性哈希算法将整个哈希值空间组织成一个虚拟的圆环，范围为0-2^32-1；对于每个数据，根据key计算hash值，确定数据在环上的位置，然后从此位置沿环顺时针行走，找到的第一台服务器就是其应该映射到的服务器。一致性哈希分区的主要问题在于，当节点数量较少时，增加或删减节点，对单个节点的影响可能很大，造成数据的严重不平衡，性能出现瓶颈。
- 带虚拟节点的一致性哈希分区。该方案在一致性哈希分区的基础上，引入了虚拟节点的概念。**Redis**集群使用的便是该方案，其中的虚拟节点称为槽（slot）。槽是介于数据和实际节点之间的虚拟概念；每个实际节点包含一定数量的槽，每个槽包含哈希值在一定范围内的数据。引入槽以后，数据的映射关系由数据hash->实际节点，变成了数据hash->槽->实际节点。**在使用了槽的一致性哈希分区中，槽是数据管理和迁移的基本单位。槽解耦了数据和实际节点之间的关系，增加或删除节点对系统的影响很小。**数据通过CRC16计算hash。

#### redis cluster的hash slot算法

redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot，redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot，hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去，移动hash slot的成本是非常低的

#### 为什么槽数量是16384

> https://www.cnblogs.com/rjzheng/p/11430592.html

`CRC16`算法产生的hash值有16bit，该算法可以产生2^16-=65536个值。换句话说，值是分布在0~65535之间。那作者在做`mod`运算的时候，为什么不`mod`65536，而选择`mod`16384？

**1.如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。**

在消息头中，最占空间的是 myslots[CLUSTER_SLOTS/8]。当槽位为65536时，这块的大小是: 65536÷8=8kb因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽。 

**2.redis的集群主节点数量基本不可能超过1000个。**集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了

**3.槽位越小，节点少的情况下，压缩率高。**

Redis主节点的配置信息中，它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中，会对bitmap进行压缩，但是如果bitmap的填充率slots / N很高的话(N表示节点数)，bitmap的压缩率就很低。如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。

作者原话

1、普通心跳数据包携带节点的完整配置，该配置可以用旧配置以幂等方式替换，以便更新旧配置。这意味着它们包含原始形式的节点的槽配置，16k的槽配置需要使用2k内存空间，但是使用65k槽将使用8k的内存空间。

2、同时，由于其他设计折衷，Redis集群不可能扩展到超过1000个节点。

因此，16k是比较合适的，可以确保每个主设备有足够的槽，最大为1000个。redis的node配置信息通过位图存储传输的，传输前有一个压缩过程，压缩比跟槽个数和节点数有很大关系。槽数量／节点数, 当这个N越大，压缩比就越小。

#### 集群中的节点是怎样通信的？

在集群中，没有数据节点与非数据节点之分：所有的节点都存储数据，也都参与集群状态的维护。为此，集群中的每个节点，都提供了两个TCP端口。

- 普通端口：即我们在前面指定的端口(7000等)。普通端口主要用于为客户端提供服务（与单机节点类似）；但在节点间数据迁移时也会使用。 
- 集群端口：端口号是普通端口+10000（10000是固定值，无法改变），如7000节点的集群端口为17000。集群端口只用于节点之间的通信，如搭建集群、增减节点、故障转移等操作时节点间的通信；不要使用客户端连接集群接口。为了保证集群可以正常工作，在配置防火墙时，要同时开启普通端口和集群端口。

节点间通信，按照通信协议可以分为几种类型：单对单、广播、Gossip协议等。重点是广播和Gossip的对比。

广播是指向集群内所有节点发送消息；优点是集群的收敛速度快(集群收敛是指集群内所有节点获得的集群信息是一致的)，缺点是每条消息都要发送给所有节点，CPU、带宽等消耗较大。

Gossip协议的特点是：在节点数量有限的网络中，每个节点都“随机”的与部分节点通信（并不是真正的随机，而是根据特定的规则选择通信的节点），经过一番杂乱无章的通信，每个节点的状态很快会达到一致。Gossip协议的优点有负载(比广播)低、去中心化、容错性高(因为通信有冗余)等；缺点主要是集群的收敛速度慢。

#### Gossip协议

包括ping，pong，meet，fail，等等

- meet: 某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信

- ping: 每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据

  - 每个节点每秒会执行10次ping，每次会选择5个最久没有通信的其他节点，当然如果发现某个节点通信延时达到了cluster_node_timeout / 2，那么立即发送ping，避免数据交换延时过长，落后的时间太长了，比如说，两个节点之间都10分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题，所以cluster_node_timeout可以调节，如果调节比较大，那么会降低发送的频率，每次ping，一个是带上自己节点的信息，还有就是带上1/10其他节点的信息，发送出去，进行数据交换。

- pong: 返回ping和meet，包含自己的状态和其他信息，也可以用于信息广播和更新
- fail: 某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了
  - 当一个主节点A判断另一个主节点B已经进入FAIL状态时，节点A会向集群广播一条关于节点B的FAIL消息，所有收到这条消息的节点都会立即将节点B标记为已下线。



#### 访问的槽不在请求的机器上

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/F3C29BD22BE74793B36F6E690A3F355A/17653)

#### 如果槽正在迁移

![image](https://note.youdao.com/yws/public/resource/128bec5e2028fdd77a8da4db2231a1f6/xmlnote/CA15E93B3F784C81BE32E1424ABBD373/17657)

#### ASK错误和MOVED错误的区别

- MOVED错误代表槽的负责权已经从一个节点转移到了另一个节点：在客户端收到关于槽i的MOVED错误之后，客户端每次遇到关于槽i的命令请求时，都可以直接将命令请求发送至MOVED错误所指向的节点，因为该节点就是目前负责槽i的节点。
- ASK错误只是两个节点在迁移槽的过程中使用的一种临时措施：在客户端收到关于槽i的ASK错误之后，客户端只会在接下来的一次命令请求中将关于槽i的命令请求发送至ASK错误所指示的节点，但这种转向不会对客户端今后发送关于槽i的命令请求产生任何影响，客户端仍然会将关于槽i的命令请求发送至目前负责处理槽i的节点，除非ASK错误再次出现。

#### Redis cluster 的高可用与主备切换原理

从节点过滤

对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。

检查每个 slave node 与 master node 断开连接的时间，如果超过了 `cluster-node-timeout * cluster-slave-validity-factor` ，那么就**没有资格**切换成 `master` 。

从节点选举

每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。

所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node `（N/2 + 1）` 都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。

从节点执行主备切换，从节点切换为主节点。

与哨兵比较

整个流程跟哨兵相比，非常类似，所以说，Redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。

#### 集群故障转移

1）复制下线主节点的所有从节点里面，会有一个从节点被选中。

2）被选中的从节点会执行SLAVEOF no one命令，成为新的主节点。

3）新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己。

4）新的主节点向集群广播一条PONG消息，这条PONG消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点，并且这个主节点已经接管了原本由已下线节点负责处理的槽。

5）新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成

#### 选举新的主节点

1. 每个配置纪元内，所有主节点只有一次投票机会
2. 从节点发现主节点下线后，回向集群广播一条`CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST`消息，要求收到消息的有投票权的主节点向该从节点投票
3. 如果一个主节点具有投票权（它正在负责处理槽），并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，表示这个主节点支持从节点成为新的主节点
4. 每个参与选举的从节点都会接收CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，并根据自己收到了多少条这种消息来统计自己获得了多少主节点的支持。
5. 如果集群里有N个具有投票权的主节点，那么当一个从节点收集到大于等于N/2+1张支持票时，这个从节点就会当选为新的主节点。
6. 如果在一个配置纪元里面没有从节点能收集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行选举，直到选出新的主节点为止。

#### 集群判断节点宕机

如果一个节点认为另外一个节点宕机，那么就是pfail，主观宕机，如果多个节点都认为另外一个节点宕机了，那么就是fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown，在cluster-node-timeout内，某个节点一直没有返回pong，那么就被认为pfail，如果一个节点认为某个节点pfail了，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，那么就会变成fail。同时最先将主节点标记为下线的节点会广播该主节点的下线消息，所有收到消息的节点回将其标为下线。

#### 集群如何指定访问的节点

Hashtag

#### 多master下的写入是怎样进行的？

在redis cluster写入数据的时候，其实是你可以将请求发送到任意一个master上去执行，但是，每个master都会计算这个key对应的CRC16值，然后对16384个hashslot取模，找到key对应的hashslot，找到hashslot对应的master。如果对应的master就在自己本地的话，set mykey1 v1，mykey1这个key对应的hashslot就在自己本地，那么自己就处理掉了。但是如果计算出来的hashslot在其他master上，那么就会给客户端返回一个moved error，告诉你，你得到哪个master上去执行这条写入的命令

　　但是，每个master都会计算这个key对应的CRC16值，然后对16384个hashslot取模，找到key对应的hashslot，找到hashslot对应的master

　　如果对应的master就在自己本地的话，set mykey1 v1，mykey1这个key对应的hashslot就在自己本地，那么自己就处理掉了

　　但是如果计算出来的hashslot在其他master上，那么就会给客户端返回一个moved error，告诉你，你得到哪个master上去执行这条写入的命令

什么叫做多master的写入？

就是每条数据只能存在于一个master上，不同的master负责存储不同的数据，分布式的数据存储

#### redis cluster的配置

```
cluster-enabled <yes/no>

cluster-config-file <filename>：这是指定一个文件，供cluster模式下的redis实例将集群状态保存在那里，包括集群中其他机器的信息，比如节点的上线和下限，故障转移，不是我们去维护的，给它指定一个文件，让redis自己去维护的

cluster-node-timeout <milliseconds>：节点存活超时时长，超过一定时长，认为节点宕机，master宕机的话就会触发主备切换，slave宕机就不会提供服务
```

#### redis集群机器要求

一般要求最少3个master，每个master上面至少一个slave

#### 集群下怎样添加master节点

1. 手动启动一个新的redis实例
2. reshard一些数据过去，一部分hash slot从一些node上迁移到另外一些node上

#### 集群下怎样删除master节点

1. reshard数据到其他节点，一部分hash slot从一些node上迁移到另外一些node上
2. 确保node为空之后，才能执行remove操作

#### 集群下节点通信端口

每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如7001，那么用于节点间通信的就是17001端口



# redis相关问题

## Redis 和 Memcached 有啥区别，为啥选择用Redis作为你们的缓存中间件？

Redis 支持复杂的数据结构：
Redis 相比 Memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， Redis 会是不错的选择。
Redis 原生支持集群模式：
在 redis3.x 版本中，便能支持 Cluster 模式，而 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。
性能对比：
由于 Redis 只使用单核，而 Memcached 可以使用多核，所以平均每一个核上 Redis 在存储小数据时比 Memcached 性能更高。而在 100k 以上的数据中，Memcached 性能要高于 Redis，虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Remcached，还是稍有逊色。

## redis的高级功能？

Bitmap :
位图是支持按 bit 位来存储信息，可以用来实现 布隆过滤器（BloomFilter）；
HyperLogLog:
供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计 UV；
Geospatial:
可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。有没有想过用Redis来实现附近的人？或者计算最优地图路径？
这三个其实也可以算作一种数据结构，不知道还有多少朋友记得，我在梦开始的地方，Redis基础中提到过，你如果只知道五种基础类型那只能拿60分，如果你能讲出高级用法，那就觉得你有点东西。
pub/sub：
功能是订阅发布功能，可以用作简单的消息队列。
Pipeline：
可以批量执行一组指令，一次性返回全部结果，可以减少频繁的请求应答。
Lua：
Redis 支持提交 Lua 脚本来执行一系列的功能。

## redis的优点？

- 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。它的，数据存在内存中，类似于**HashMap**，**HashMap**的优势就是查找和操作的时间复杂度都是O(1)；
- 数据结构简单，对数据操作也简单，**Redis**中的数据结构是专门进行设计的；
- 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 **CPU**，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
- 使用多路I/O复用模型，非阻塞IO；
- 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，**Redis**直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

## Redis 的线程模型有了解么？

Redis 内部使用文件事件处理器 `file event handler` ，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。

## redis处理请求的全流程？

![image](http://note.youdao.com/yws/public/resource/53b088853ba2efc078c3e41f7996b610/xmlnote/115318FDF47C438D99A240A32643E06D/16393)客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 `AE_READABLE` 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给**连接应答处理器**。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 `AE_READABLE` 事件与命令请求处理器关联。

假设此时客户端发送了一个 `set key value` 请求，此时 Redis 中的 socket01 会产生 `AE_READABLE` 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 `AE_READABLE` 事件，由于前面 socket01 的 `AE_READABLE` 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 `key value` 并在自己内存中完成 `key value` 的设置。操作完成后，它会将 socket01 的 `AE_WRITABLE` 事件与命令回复处理器关联。

如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 `AE_WRITABLE` 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 `ok` ，之后解除 socket01 的 `AE_WRITABLE` 事件与命令回复处理器的关联。

## 为啥 Redis 单线程模型也能效率这么高？

- 纯内存操作
- 核心是基于非阻塞的 IO 多路复用机制
- C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快
- 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题

## 缓存雪崩简单介绍一下？解决方案？

> https://blog.csdn.net/tanwenfang/article/details/86478786

大量的key设置了相同的过期时间或者系统冗机，导致在缓存在同一时刻全部失效，这样请求直接访问数据库，造成瞬时DB请求量大、压力骤增，导致数据库冗机后，重启再次冗机，陷入死循环，引起雪崩。

**解决方案**

1. Redis 高可用，主从+哨兵，Redis cluster，主备切换避免全盘崩溃

2. 缓存时间设置随机值，防止同一时间大量的Key失效，```setRedis（Key，value，time + Math.random() * 10000）；```

3. 做二级缓存，或者双缓存策略。本地ehcache缓存+hystrix限流&降级，避免mysql打死

4. 缓存失效后，使用锁或者MQ来限流

   ```java
   String userJson = redisService.getString(key);
   		if (!StringUtils.isEmpty(userJson)) {
   			Users users = JSONObject.parseObject(userJson, Users.class);
   			return users;
   		}
   		Users user = null;
   		try {
   			lock.lock();
   			// 查询db
   			user = userMapper.getUser(id);
   			redisService.setSet(key, JSONObject.toJSONString(user));
   		} catch (Exception e) {
   		} finally {
   			lock.unlock(); // 释放锁
   		}
   //注意:加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这是过来1000个请求999个都在阻塞的。同样会导致用户等待超时，这是个治标不治本的方法
   ```

   

5. 设置过期标志更新缓存

6. 请求合并

7. 缓存不失效

- 事前：主从+哨兵、redis集群、双机房
- 事中：ehcache本地缓存、对redis访问的资源隔离、对源服务访问的限流以及资源隔离
- 事后：
  - redis数据可以恢复，做了备份，redis数据备份和恢复，redis重新启动起来
  - redis数据彻底丢失了，或者数据过旧，快速缓存预热，redis重新启动起来

## 缓存击穿介绍一下？解决方案？

缓存击穿，就是说某个 热点key ，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。

**解决方案**

- 若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。
- 若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。
- 若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。

## 缓存穿透介绍一下？解决方案？

key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库redis config

**解决方案**

1. 接口限流与熔断、降级，封掉恶意访问ip
2. 使用布隆过滤器，不存在直接返回
3. 缓存空值，设置短暂的过期时间（30s），这样下次相同的key访问的时候可以直接返回值
4. 使用互斥锁排队
5. 参数校验。不合法的参数直接代码Return

互斥锁

```java
public String get(key) {
      String value = redis.get(key);
      if (value == null) { //代表缓存值过期
          //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
      if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  //代表设置成功
               value = db.get(key);
                      redis.set(key, value, expire_secs);
                      redis.del(key_mutex);
              } else {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
                      sleep(50);
                      get(key);  //重试
              }
          } else {
              return value;      
          }
 }
```

## 更新缓存的模式有哪几种？

> https://www.jianshu.com/p/2936a5c65e6b

1. Cache aside Pattern

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，**先更新数据库，然后再删除缓存**。

2. Read/Write  through

![image](http://songwenjie.vip/blog/180511/FC3blLI8Da.png?imageslim)

- Read Through:Read Through 模式就是在查询操作中更新缓存，也就是说，当缓存失效的时候，Cache Aside 模式是由调用方负责把数据加载入缓存，而 Read Through 则用缓存服务自己来加载。
- Write Through:Write Through 模式和 Read Through 相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后由缓存自己更新数据库（这是一个同步操作）。

3. Write behind caching

Write Behind Caching 更新模式就是在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是直接操作内存速度快。因为异步，Write Behind Caching 更新模式还可以合并对同一个数据的多次操作到数据库，所以性能的提高是相当可观的。

但其带来的问题是，数据不是强一致性的，而且可能会丢失。另外，Write Behind Caching 更新模式实现逻辑比较复杂，因为它需要确认有哪些数据是被更新了的，哪些数据需要刷到持久层上。只有在缓存需要失效的时候，才会把它真正持久起来。

## fork耗时导致高并发请求延时

RDB和AOF的时候，其实会有生成RDB快照，AOF rewrite，耗费磁盘IO的过程，主进程会fork子进程，fork的时候，子进程是需要拷贝父进程的空间内存页表的，也是会耗费一定的时间的。一般来说，如果父进程内存有1个G的数据，那么fork可能会耗费在20ms左右，如果是10G~30G，那么就会耗费20 * 10，甚至20 * 30，也就是几百毫秒的时间，info stats中的latest_fork_usec，可以看到最近一次form的时长，redis单机QPS一般在几万，fork可能一下子就会拖慢几万条操作的请求时长，从几毫秒变成1秒

### 优化思路

fork耗时跟redis主进程的内存有关系，一般控制redis的内存在10GB以内

## AOF的阻塞问题

redis将数据写入AOF缓冲区，单独开一个现场做fsync操作，每秒一次，但是redis主线程会检查两次fsync的时间，如果距离上次fsync时间超过了2秒，那么写请求就会阻塞，everysec，最多丢失2秒的数据，一旦fsync超过2秒的延时，整个redis就被拖慢 

### 优化思路

优化硬盘写入速度，建议采用SSD，不要用普通的机械硬盘，SSD，大幅度提升磁盘读写的速度

## 主从复制延迟问题

主从复制可能会超时严重，这个时候需要良好的监控和报警机制，在info replication中，可以看到master和slave复制的offset，做一个差值就可以看到对应的延迟量，如果延迟过多，那么就进行报警

## 主从复制风暴问题

当主节点挂了重新恢复的过程中，如果一下子让多个slave从master去执行全量复制，一份大的rdb同时发送到多个slave，会导致网络带宽被严重占用，如果一个master真的要挂载多个slave，那尽量用树状结构，不要用星型结构

###  解决方案

如果一个master真的要挂载多个slave，那尽量用树状结构，不要用星型结构，如果延迟过多，那么就进行报警

## 如何保证缓存和数据库数据的一致性？

> https://blog.csdn.net/alohaheja/article/details/108274640
>
> https://blog.csdn.net/chang384915878/article/details/86756463

大致有四种方案

### 读请求写请求串行化执行。

串行化执行，保证数据一致性，但是会大幅降低系统吞吐量，不采用。

### 先更新数据库，再更新缓存。

**可能引起的问题**

1、两个请求同时请求更新，导致最后缓存的数据时脏数据。

```
A请求更新数据库
B请求更新数据库
B请求更新缓存
A请求更新缓存
# 导致最后缓存的数据时脏数据
```

2、缓存中的数据并不一定是直接从数据库中读取的，而是由多方数据联合计算的，这个计算过程本身就比较耗时。

### 先删除缓存，再更新数据库

**可能引起的问题**

1、为什么先删除缓存？

数据库更新成功，但是缓存删除失败，从而造成数据不一致

2、A请求更新，B请求查询，这种情况下，缓存中出现了脏数据。而且如果缓存没有过期时间，那么脏数据将一直存在。

```
A请求更新，所以先删除缓存
B请求查询，缓存已经被删除
B请求查询数据库，得到旧的值
B请求将旧的值返回并写入缓存
A请求将新的值写入数据库
```

解决：延时双删策略

```
先删除缓存
写入数据库
休眠1秒，再次删除缓存。这样就可以将在1秒内所造成的脏数据再次删除。
```

3、延时双删第二次的删除失败怎么办（用Cache Aside）

### Cache Aside Pattern

**可能引起的问题**

1、A请求查询，B请求更新，这种情况要发生，必须是B写入数据库的耗时小于A请求查询的耗时（步骤3耗时小于步骤2），才有可能使得步骤4优先发生于步骤5，但是读操作是远远快鱼写操作的，所以这种情况非常难发生

```
缓存刚好失效
请求A查询数据库，得一个旧值
请求B将新值写入数据库
请求B删除缓存
请求A将查到的旧值写入缓存
```

解决：

1. 设置缓存过期时间
2. 采用异步延时双删策略，保证读请求完成后，再次进行缓存删除操作

2、第二次删除缓存失败

解决：提供一个保障的重试机制

```
方案1：对业务代码造成大量入侵
1. 更新数据库数据
2. 缓存因为种种问题删除失败
3. 将需要删除的key发送至消息队列
4. 自己消费消息，获得需要删除的key
5. 继续重试删除操作，直到成功

方案2：启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。
1. 更新数据库数据
2. 数据库会将操作信息写入binlog日志当中
3. 订阅程序提取出所需要的数据以及key
4. 另起一段非业务代码，获得该信息
5. 尝试删除缓存操作，发现删除失败
6. 将这些信息发送至消息队列
7. 重新从消息队列中获得该数据，重试操作
```

3、**为什么是删除缓存，而不是更新缓存？**

原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于**比较复杂的缓存数据计算的场景**，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，**这个缓存到底会不会被频繁访问到？**



## Redis 的并发竞争问题是什么？如何解决这个问题？了解 Redis 事务的 CAS 方案吗？

某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。

你要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。每次要**写之前，先判断**一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。

## redis在博客系统中可以做什么？

1. 记录帖子的点赞数、评论数和点击数 (hash)。
2. 记录用户的帖子 ID 列表 (排序)，便于快速显示用户的帖子列表 (zset)。
3. 记录帖子的标题、摘要、作者和封面信息，用于列表页展示 (hash)。
4. 记录帖子的点赞用户 ID 列表，评论 ID 列表，用于显示和去重计数 (zset)。
5. 缓存近期热帖内容 (帖子内容空间占用比较大)，减少数据库压力 (hash)。
6. 记录帖子的相关文章 ID，根据内容推荐相关帖子 (list)。
7. 如果帖子 ID 是整数自增的，可以使用 Redis 来分配帖子 ID(计数器)。
8. 收藏集和帖子之间的关系 (zset)。
9. 记录热榜帖子 ID 列表，总热榜和分类热榜 (zset)。
10. 缓存用户行为历史，进行恶意行为过滤 (zset,hash)。
11. 数据推送去重Bloom filter
12. pv，uv统计

## redis实现打卡？

> https://www.cnblogs.com/liujiduo/p/10396020.html
>
> https://www.cnblogs.com/wuwuyong/p/11739495.html

### 场景需求

适用场景如签到送积分、签到领取奖励等，大致需求如下：

- 签到1天送1积分，连续签到2天送2积分，3天送3积分，3天以上均送3积分等。
- 如果连续签到中断，则重置计数，每月初重置计数。
- 当月签到满3天领取奖励1，满5天领取奖励2，满7天领取奖励3……等等。
- 显示用户某个月的签到次数和首次签到时间。
- 在日历控件上展示用户每月签到情况，可以切换年月显示……等等。

### 设计思路

对于用户签到数据，如果每条数据都用K/V的方式存储，当用户量大的时候内存开销是非常大的。而位图(BitMap)是由一组bit位组成的，每个bit位对应0和1两个状态，虽然内部还是采用String类型存储，但Redis提供了一些指令用于直接操作位图，可以把它看作是一个bit数组，数组的下标就是偏移量。它的优点是内存开销小、效率高且操作简单，很适合用于签到这类场景。

## 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？

使用 `keys` 指令可以扫出指定模式的 key 列表。但是要注意 keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 `scan` 指令，`scan` 指令可以无阻塞的提取出指定模式的 `key` 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 `keys` 指令长。

# 秒杀系统设计

# 上亿流量的商品详情页系统的多级缓存架构

采用三级缓存：nginx本地缓存+redis分布式缓存+tomcat堆缓存的多级缓存架构

时效性要求非常高的数据：库存

当然，我们就希望当库存变化的时候，尽可能更快将库存显示到页面上去，而不是说等了很长时间，库存才反应到页面上去,时效性要求不高的数据：商品的基本信息（名称、颜色、版本、规格参数，等等）,时效性要求不高的数据，就还好，比如说你现在改变了商品的名称，稍微晚个几分钟反应到商品页面上，也还能接受。

- 时效性要求高的数据，而且种类较少，采取相关的服务系统每次发生了变更的时候，直接采取数据库和redis缓存双写的方案，这样缓存的时效性最高
- 时效性不高的数据，而且种类繁多，来自多种不同的系统，采取MQ异步通知的方式，写一个数据生产服务，监听MQ消息，然后异步拉取服务的数据，更新tomcat jvm缓存+redis缓存

nginx+lua脚本做页面动态生成的工作，每次请求过来，优先从nginx本地缓存中提取各种数据，结合页面模板，生成需要的页面。如果nginx本地缓存过期了，那么就从nginx到redis中去拉取数据，更新到nginx本地。如果redis中也被LRU算法清理掉了，那么就从nginx走http接口到后端的服务中拉取数据，数据生产服务中，先在本地tomcat里的jvm堆缓存中找，ehcache，如果也被LRU清理掉了，那么就重新发送请求到源头的服务中去拉取数据，然后再次更新tomcat堆内存缓存+redis缓存，并返回数据给nginx，nginx缓存到本地

## 多级缓存架构中每一层的意义

- nginx本地缓存，抗的是热数据的高并发访问， 那么对这些热数据的大量访问，就直接走nginx就可以了，不需要走后续的各种网络开销了
- redis分布式大规模缓存，抗的是很高的离散访问，支撑海量的数据，高并发的访问，高可用的服务
- tomcat jvm堆内存缓存，主要是抗redis大规模灾难的，如果redis出现了大规模的宕机，导致nginx大量流量直接涌入数据生产服务，那么最后的tomcat堆内存缓存至少可以再抗一下，不至于让数据库直接裸奔

# 分布式锁

## 普通的分布式锁

第一个最普通的实现方式，就是在 redis 里使用 `setnx` 命令创建一个 key，这样就算加锁。

```
SET resource_name my_random_value NX PX 30000
```

释放锁就是删除 key ，但是一般可以用 `lua` 脚本删除，判断 value 一样才删除：

```redis
-- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

### 加锁的value可是固定值么

因为如果某个客户端获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能已经自动释放锁了，此时可能别的客户端已经获取到了这个锁，要是你这个时候直接删除 key 的话会有问题，因为如果是普通的 redis 单实例，那就是单点故障。或者是 redis 普通主从，那 redis 主从异步复制，如果主节点挂了（key 就没有了），key 还没同步到从节点，此时从节点切换为主节点，别人就可以 set key，从而拿到锁。

## 集群模式下分布式锁

1. 获取当前时间戳，单位是毫秒；
2. 跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；
3. 尝试在**大多数节点**上建立一个锁，比如 5 个节点就要求是 3 个节点 `n / 2 + 1`；
4. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
5. 要是锁建立失败了，那么就依次之前建立过的锁删除；
6. 只要别人建立了一把分布式锁，你就得**不断轮询去尝试获取锁**。

# redis配置

```
### maxmemory polocy 缓存清除策略
- noeviction: 不进行置换，表示即使内存达到上限也不进行置换，所有能引起内存增加的命令都会返回error
- allkeys-lru: 优先删除掉最近最不经常使用的key，用以保存新数据
- volatile-lru: 只从设置失效（expire set）的key中选择最近最不经常使用的key进行删除，用以保存新数据
- allkeys-random: 随机从all-keys中选择一些key进行删除，用以保存新数据
- volatile-random: 只从设置失效（expire set）的key中，选择一些key进行删除，用以保存新数据
- volatile-ttl: 只从设置失效（expire set）的key中，选出存活时间（TTL）最短的key进行删除，用以保存新数据
- 

- 1、redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程：
             daemonize no
 - 2、当redis以守护进程方式运行时，redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定：
             pidfile /var/run/redis.pid
- 3、指定redis监听端口，默认端口号为6379，作者在自己的一篇博文中解析了为什么选用6379作为默认端口，因为6379
             在手机按键上MERZ对应的号码，而MERZ取自意大利女歌手Alessia Merz的名字：
             port 6379
- 4、设置tcp的backlog，backlog是一个连接队列，backlog队列总和=未完成三次握手队列+已完成三次握手队列。在高
            并发环境下你需要一个高backlog值来避免慢客户端连接问题。注意Linux内核会将这个值减小到
            /proc/sys/net/core/somaxconn 的值，所以需要确认增大somaxconn和tcp_max_syn_backlog两个值来达到想要的
            效果：
            tcp-backlog 511
- 5、绑定的主机地址：
            bind 127.0.0.1
- 6、当客户端闲置多长时间后关闭连接，如果指定为0，表示永不关闭：
            timeout 300
- 7、设置检测客户端网络中断时间间隔，单位为秒，如果设置为0，则不检测，建议设置为60：
            tcp-keepalive 0
- 8、指定日志记录级别，redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose：
            loglevel verbose
- 9、日志记录方式，默认为标准输出，如果配置redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则
            日志将会发送给/dev/null：
            logfile stdout
- 10、设置数据库数量，默认值为16，默认当前数据库为0，可以使用select<dbid>命令在连接上指定数据库id：
            databases 16
- 11、指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合：
            save <seconds><changes>
            save 300 10：表示300秒内有10个更改就将数据同步到数据文件
- 12、指定存储至本地数据库时是否压缩数据，默认为yes，redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，
            但会导致数据库文件变得巨大：
            rdbcompression yes
- 13、指定本地数据库文件名，默认值为dump.rdb：
           dbfilename dump.rdb
- 14、指定本地数据库存放目录：
           dir ./
- 15、设置当本机为slave服务时，设置master服务的IP地址及端口，在redis启动时，它会自动从master进行数据同步：
           slaveof <masterip><masterport>
- 16、当master服务设置了密码保护时，slave服务连接master的密码：
           masterauth <master-password>
- 17、设置redis连接密码，如果配置了连接密码，客户端在连接redis时需要通过auth <password>命令提供密码，默认
           关闭：
           requirepass foobared
- 18、设置同一时间最大客户端连接数，默认无限制，redis可以同时打开的客户端连接数为redis进程可以打开的最大文件
           描述符数，如果设置maxclients 0，表示不作限制。当客 户端连接数到达限制时，redis会关闭新的连接并向客户端返
           回 max number of clients reached错误消息：
           maxclients 128
- 19、指定redis最大内存限制，redis在启动时会把数据加载到内存中，达到最大内存后，redis会先尝试清除已到期或即将
           到期的key，当次方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的
           vm机制， 会把key存放内存，value会存放在swap区：
           maxmemory <bytes>
- 20、设置缓存过期策略，有6种选择：（LRU算法最近最少使用）
           volatile-lru：使用LRU算法移除key，只对设置了过期时间的key；
           allkeys-lru：使用LRU算法移除key，作用对象所有key；
           volatile-random：在过期集合key中随机移除key，只对设置了过期时间的key;
           allkeys-random：随机移除key，作用对象为所有key；
           volarile-ttl：移除哪些ttl值最小即最近要过期的key；
           noeviction：永不过期，针对写操作，会返回错误信息。
           maxmemory-policy noeviction
- 21、指定是否在每次更新操作后进行日志记录，redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电
           时导致一段时间内数据丢失。因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内置
           存在于内存中。默认为no：
           appendonly no
- 22、指定更新日志文件名，默认为appendonly.aof：
           appendfilename appendonly.aof
- 23、指定更新日志条件，共有3个可选值：
           no：表示等操作系统进行数据缓存同步到磁盘（快）；
           always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）；
           everysec：表示每秒同步一次（折中，默认值）
           appendfsync everysec
- 24、指定是否启用虚拟内存机制，默认值为no，简单介绍一下，VM机制将数据分页存放，由redis将访问量较小的页即
           冷数据 swap到磁盘上，访问多的页面由磁盘自动换出到内存中：
           vm-enabled no
- 25、虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个redis实例共享：
           vm-swap-file /tmp/redis.swap
- 26、将所有大于vm-max-memory的数据存入虚拟内存，无论vm-max-memory设置多小，所有索引数据都是内存存储
           的（redis的索引数据就是keys），也就是说，当vm-max-memory设置为0的时候，其实是所有value都存在于磁盘。
           默认值为 0：
           vm-max-memory 0
- 27、redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，
           vm-page-size是根据存储的数据大小来设定的，作者建议如果储存很多小对象，page大小最好设置为32或者64bytes；
           如果存储很多大对象，则可以使用更大的page，如果不确定，就使用默认值：
           vm-page-size 32
- 28、设置swap文件中page数量，由于页表（一种表示页面空闲或使用的bitmap）是放在内存中的，在磁盘上每8个
           pages将消耗1byte的内存：
           vm-pages 134217728
- 29、设置访问swap文件的线程数，最好不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的，
           可能会造成长时间的延迟。默认值为4：
           vm-max-threads 4
- 30、设置在客户端应答时，是否把较小的包含并为一个包发送，默认为开启：
           glueoutputbuf yes
- 31、指定在超过一定数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法：
           hash-max-zipmap-entries 64
           hash-max-zipmap-value 512
- 32、指定是否激活重置hash，默认开启：
           activerehashing yes
- 33、指定包含其他配置文件，可以在同一主机上多个redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的
           特定配置文件：
           include /path/to/local.conf
```